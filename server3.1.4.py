import asyncio
import random
import time
import json
from typing import List, Optional, Dict, Any, Union, AsyncGenerator, Tuple, Callable, Set
import os
import traceback
from contextlib import asynccontextmanager
import sys
import platform
import logging
import logging.handlers
import socket # ‰øùÁïô socket ‰ª•‰æøÂú® __main__ ‰∏≠ËøõË°åÁÆÄÂçïÁöÑÁõ¥Êé•ËøêË°åÊèêÁ§∫
from asyncio import Queue, Lock, Future, Task, Event

from fastapi import FastAPI, Request, HTTPException
from fastapi.responses import JSONResponse, StreamingResponse, FileResponse
from fastapi import WebSocket, WebSocketDisconnect
from pydantic import BaseModel
from playwright.async_api import Page as AsyncPage, Browser as AsyncBrowser, Playwright as AsyncPlaywright, Error as PlaywrightAsyncError, expect as expect_async, BrowserContext as AsyncBrowserContext, Locator
from playwright.async_api import async_playwright
from urllib.parse import urljoin, urlparse
import uuid
import datetime
import aiohttp

# --- ÂÖ®Â±ÄÊ∑ªÂä†Ê†áËÆ∞Â∏∏Èáè ---
USER_INPUT_START_MARKER_SERVER = "__USER_INPUT_START__"
USER_INPUT_END_MARKER_SERVER = "__USER_INPUT_END__"

# --- ÂÖ®Â±ÄÊó•ÂøóÊéßÂà∂ÈÖçÁΩÆ ---
DEBUG_LOGS_ENABLED = os.environ.get('DEBUG_LOGS_ENABLED', 'false').lower() in ('true', '1', 'yes')
TRACE_LOGS_ENABLED = os.environ.get('TRACE_LOGS_ENABLED', 'false').lower() in ('true', '1', 'yes')

# --- Configuration ---
AI_STUDIO_URL_PATTERN = 'aistudio.google.com/'
RESPONSE_COMPLETION_TIMEOUT = 300000 # 5 minutes total timeout (in ms)
POLLING_INTERVAL = 300 # ms
POLLING_INTERVAL_STREAM = 180 # ms
SILENCE_TIMEOUT_MS = 40000 # ms
POST_SPINNER_CHECK_DELAY_MS = 500
FINAL_STATE_CHECK_TIMEOUT_MS = 1500
POST_COMPLETION_BUFFER = 700
CLEAR_CHAT_VERIFY_TIMEOUT_MS = 5000
CLEAR_CHAT_VERIFY_INTERVAL_MS = 400
CLICK_TIMEOUT_MS = 5000
CLIPBOARD_READ_TIMEOUT_MS = 5000
PSEUDO_STREAM_DELAY = 0.01
EDIT_MESSAGE_BUTTON_SELECTOR = 'ms-chat-turn:last-child .actions-container button.toggle-edit-button'
MESSAGE_TEXTAREA_SELECTOR = 'ms-chat-turn:last-child ms-text-chunk ms-autosize-textarea'
FINISH_EDIT_BUTTON_SELECTOR = 'ms-chat-turn:last-child .actions-container button.toggle-edit-button[aria-label="Stop editing"]'

AUTH_PROFILES_DIR = os.path.join(os.path.dirname(__file__), 'auth_profiles')
ACTIVE_AUTH_DIR = os.path.join(AUTH_PROFILES_DIR, 'active')
SAVED_AUTH_DIR = os.path.join(AUTH_PROFILES_DIR, 'saved')
LOG_DIR = os.path.join(os.path.dirname(__file__), 'logs')
APP_LOG_FILE_PATH = os.path.join(LOG_DIR, 'app.log')

# --- ÂÖ®Â±Ä‰ª£ÁêÜËÆæÁΩÆ ---
PROXY_SERVER_ENV = os.environ.get('HTTPS_PROXY') or os.environ.get('HTTP_PROXY')
NO_PROXY_ENV = os.environ.get('NO_PROXY')
AUTO_SAVE_AUTH = os.environ.get('AUTO_SAVE_AUTH', '').lower() in ('1', 'true', 'yes')
AUTH_SAVE_TIMEOUT = int(os.environ.get('AUTH_SAVE_TIMEOUT', '30'))

PLAYWRIGHT_PROXY_SETTINGS: Optional[Dict[str, str]] = None
if PROXY_SERVER_ENV:
    PLAYWRIGHT_PROXY_SETTINGS = {'server': PROXY_SERVER_ENV}
    if NO_PROXY_ENV:
        PLAYWRIGHT_PROXY_SETTINGS['bypass'] = NO_PROXY_ENV.replace(',', ';')

# --- Constants ---
MODEL_NAME = 'AI-Studio_Camoufox-Proxy'
CHAT_COMPLETION_ID_PREFIX = 'chatcmpl-'
MODELS_ENDPOINT_URL_CONTAINS = "MakerSuiteService/ListModels"
DEFAULT_FALLBACK_MODEL_ID = "no model list"

# --- Selectors ---
PROMPT_TEXTAREA_SELECTOR = 'ms-prompt-input-wrapper ms-autosize-textarea textarea'
INPUT_SELECTOR = PROMPT_TEXTAREA_SELECTOR
INPUT_SELECTOR2 = PROMPT_TEXTAREA_SELECTOR
SUBMIT_BUTTON_SELECTOR = 'button[aria-label="Run"].run-button'
RESPONSE_CONTAINER_SELECTOR = 'ms-chat-turn .chat-turn-container.model'
RESPONSE_TEXT_SELECTOR = 'ms-cmark-node.cmark-node'
# LOADING_SPINNER_SELECTOR = 'button[aria-label="Run"].run-button svg .stoppable-spinner'
ERROR_TOAST_SELECTOR = 'div.toast.warning, div.toast.error'
CLEAR_CHAT_BUTTON_SELECTOR = 'button[data-test-clear="outside"][aria-label="Clear chat"]'
CLEAR_CHAT_CONFIRM_BUTTON_SELECTOR = 'button.mdc-button:has-text("Continue")'
MORE_OPTIONS_BUTTON_SELECTOR = 'div.actions-container div ms-chat-turn-options div > button'
COPY_MARKDOWN_BUTTON_SELECTOR = 'div[class*="mat-menu"] div > button:nth-child(4)'
COPY_MARKDOWN_BUTTON_SELECTOR_ALT = 'div[role="menu"] button:has-text("Copy Markdown")'
MAX_OUTPUT_TOKENS_SELECTOR = 'input[aria-label="Maximum output tokens"]'
STOP_SEQUENCE_INPUT_SELECTOR = 'input[aria-label="Add stop token"]'
MAT_CHIP_REMOVE_BUTTON_SELECTOR = 'mat-chip-set mat-chip-row button[aria-label*="Remove"]'
TOP_P_INPUT_SELECTOR = 'div.settings-item-column:has(h3:text-is("Top P")) input[type="number"].slider-input'
TEMPERATURE_INPUT_SELECTOR = 'div[data-test-id="temperatureSliderContainer"] input[type="number"].slider-input'


# --- Global State ---
playwright_manager: Optional[AsyncPlaywright] = None
browser_instance: Optional[AsyncBrowser] = None
page_instance: Optional[AsyncPage] = None
is_playwright_ready = False
is_browser_connected = False
is_page_ready = False
is_initializing = False

global_model_list_raw_json: Optional[List[Any]] = None
parsed_model_list: List[Dict[str, Any]] = []
model_list_fetch_event = asyncio.Event()

current_ai_studio_model_id: Optional[str] = None
model_switching_lock: Optional[Lock] = None

excluded_model_ids: Set[str] = set()
EXCLUDED_MODELS_FILENAME = "excluded_models.txt"

request_queue: Optional[Queue] = None
processing_lock: Optional[Lock] = None
worker_task: Optional[Task] = None

page_params_cache: Dict[str, Any] = {}
params_cache_lock: Optional[Lock] = None

logger = logging.getLogger("AIStudioProxyServer")
log_ws_manager = None

# --- StreamToLogger, WebSocketConnectionManager, WebSocketLogHandler ---
class StreamToLogger:
    def __init__(self, logger_instance, log_level=logging.INFO):
        self.logger = logger_instance
        self.log_level = log_level
        self.linebuf = ''

    def write(self, buf):
        try:
            temp_linebuf = self.linebuf + buf
            self.linebuf = ''
            for line in temp_linebuf.splitlines(True):
                if line.endswith(('\n', '\r')):
                    self.logger.log(self.log_level, line.rstrip())
                else:
                    self.linebuf += line
        except Exception as e:
            print(f"StreamToLogger ÈîôËØØ: {e}", file=sys.__stderr__)

    def flush(self):
        try:
            if self.linebuf != '':
                self.logger.log(self.log_level, self.linebuf.rstrip())
            self.linebuf = ''
        except Exception as e:
            print(f"StreamToLogger Flush ÈîôËØØ: {e}", file=sys.__stderr__)

    def isatty(self):
        return False

class WebSocketConnectionManager:
    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}

    async def connect(self, client_id: str, websocket: WebSocket):
        await websocket.accept()
        self.active_connections[client_id] = websocket
        logger.info(f"WebSocket Êó•ÂøóÂÆ¢Êà∑Á´ØÂ∑≤ËøûÊé•: {client_id}")
        try:
            await websocket.send_text(json.dumps({
                "type": "connection_status",
                "status": "connected",
                "message": "Â∑≤ËøûÊé•Âà∞ÂÆûÊó∂Êó•ÂøóÊµÅ„ÄÇ",
                "timestamp": datetime.datetime.now().isoformat()
            }))
        except Exception as e:
            logger.warning(f"Âêë WebSocket ÂÆ¢Êà∑Á´Ø {client_id} ÂèëÈÄÅÊ¨¢ËøéÊ∂àÊÅØÂ§±Ë¥•: {e}")

    def disconnect(self, client_id: str):
        if client_id in self.active_connections:
            del self.active_connections[client_id]
            logger.info(f"WebSocket Êó•ÂøóÂÆ¢Êà∑Á´ØÂ∑≤Êñ≠ÂºÄ: {client_id}")

    async def broadcast(self, message: str):
        if not self.active_connections:
            return
        disconnected_clients = []
        active_conns_copy = list(self.active_connections.items())
        for client_id, connection in active_conns_copy:
            try:
                await connection.send_text(message)
            except WebSocketDisconnect:
                logger.info(f"[WS Broadcast] ÂÆ¢Êà∑Á´Ø {client_id} Âú®ÂπøÊí≠ÊúüÈó¥Êñ≠ÂºÄËøûÊé•„ÄÇ")
                disconnected_clients.append(client_id)
            except RuntimeError as e:
                 if "Connection is closed" in str(e):
                     logger.info(f"[WS Broadcast] ÂÆ¢Êà∑Á´Ø {client_id} ÁöÑËøûÊé•Â∑≤ÂÖ≥Èó≠„ÄÇ")
                     disconnected_clients.append(client_id)
                 else:
                     logger.error(f"ÂπøÊí≠Âà∞ WebSocket {client_id} Êó∂ÂèëÁîüËøêË°åÊó∂ÈîôËØØ: {e}")
                     disconnected_clients.append(client_id)
            except Exception as e:
                logger.error(f"ÂπøÊí≠Âà∞ WebSocket {client_id} Êó∂ÂèëÁîüÊú™Áü•ÈîôËØØ: {e}")
                disconnected_clients.append(client_id)
        if disconnected_clients:
             for client_id_to_remove in disconnected_clients:
                 self.disconnect(client_id_to_remove)

class WebSocketLogHandler(logging.Handler):
    def __init__(self, manager: WebSocketConnectionManager):
        super().__init__()
        self.manager = manager
        self.formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')

    def emit(self, record: logging.LogRecord):
        if self.manager and self.manager.active_connections:
            try:
                log_entry_str = self.format(record)
                try:
                     current_loop = asyncio.get_running_loop()
                     current_loop.create_task(self.manager.broadcast(log_entry_str))
                except RuntimeError:
                     pass
            except Exception as e:
                print(f"WebSocketLogHandler ÈîôËØØ: ÂπøÊí≠Êó•ÂøóÂ§±Ë¥• - {e}", file=sys.__stderr__)

# --- Êó•ÂøóËÆæÁΩÆÂáΩÊï∞ ---
def setup_server_logging(log_level_name: str = "INFO", redirect_print_str: str = "false"):
    global logger, log_ws_manager
    log_level = getattr(logging, log_level_name.upper(), logging.INFO)
    redirect_print = redirect_print_str.lower() in ('true', '1', 'yes')
    os.makedirs(LOG_DIR, exist_ok=True)
    os.makedirs(ACTIVE_AUTH_DIR, exist_ok=True)
    os.makedirs(SAVED_AUTH_DIR, exist_ok=True)
    file_log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - [%(name)s:%(funcName)s:%(lineno)d] - %(message)s')
    if logger.hasHandlers():
        logger.handlers.clear()
    logger.setLevel(log_level)
    logger.propagate = False
    if os.path.exists(APP_LOG_FILE_PATH):
        try:
            os.remove(APP_LOG_FILE_PATH)
        except OSError as e:
            print(f"Ë≠¶Âëä (setup_server_logging): Â∞ùËØïÁßªÈô§ÊóßÁöÑ app.log Êñá‰ª∂ '{APP_LOG_FILE_PATH}' Â§±Ë¥•: {e}„ÄÇÂ∞Ü‰æùËµñ mode='w' ËøõË°åÊà™Êñ≠„ÄÇ", file=sys.__stderr__)
    file_handler = logging.handlers.RotatingFileHandler(
        APP_LOG_FILE_PATH, maxBytes=5*1024*1024, backupCount=5, encoding='utf-8', mode='w'
    )
    file_handler.setFormatter(file_log_formatter)
    logger.addHandler(file_handler)
    if log_ws_manager is None:
        print("‰∏•ÈáçË≠¶Âëä (setup_server_logging): log_ws_manager Êú™ÂàùÂßãÂåñÔºÅWebSocket Êó•ÂøóÂäüËÉΩÂ∞Ü‰∏çÂèØÁî®„ÄÇ", file=sys.__stderr__)
    else:
        ws_handler = WebSocketLogHandler(log_ws_manager)
        ws_handler.setLevel(logging.INFO)
        logger.addHandler(ws_handler)
    console_server_log_formatter = logging.Formatter('%(asctime)s - %(levelname)s [SERVER] - %(message)s')
    console_handler = logging.StreamHandler(sys.stderr)
    console_handler.setFormatter(console_server_log_formatter)
    console_handler.setLevel(log_level)
    logger.addHandler(console_handler)
    original_stdout = sys.stdout
    original_stderr = sys.stderr
    if redirect_print:
        print("--- Ê≥®ÊÑèÔºöserver.py Ê≠£Âú®Â∞ÜÂÖ∂ print ËæìÂá∫ÈáçÂÆöÂêëÂà∞Êó•ÂøóÁ≥ªÁªü (Êñá‰ª∂„ÄÅWebSocket ÂíåÊéßÂà∂Âè∞ËÆ∞ÂΩïÂô®) ---", file=original_stderr)
        stdout_redirect_logger = logging.getLogger("AIStudioProxyServer.stdout")
        stdout_redirect_logger.setLevel(logging.INFO)
        stdout_redirect_logger.propagate = True
        sys.stdout = StreamToLogger(stdout_redirect_logger, logging.INFO)
        stderr_redirect_logger = logging.getLogger("AIStudioProxyServer.stderr")
        stderr_redirect_logger.setLevel(logging.ERROR)
        stderr_redirect_logger.propagate = True
        sys.stderr = StreamToLogger(stderr_redirect_logger, logging.ERROR)
    else:
        print("--- server.py ÁöÑ print ËæìÂá∫Êú™Ë¢´ÈáçÂÆöÂêëÂà∞Êó•ÂøóÁ≥ªÁªü (Â∞Ü‰ΩøÁî®ÂéüÂßã stdout/stderr) ---", file=original_stderr)
    logging.getLogger("uvicorn").setLevel(logging.WARNING)
    logging.getLogger("uvicorn.error").setLevel(logging.INFO)
    logging.getLogger("uvicorn.access").setLevel(logging.WARNING)
    logging.getLogger("websockets").setLevel(logging.WARNING)
    logging.getLogger("playwright").setLevel(logging.WARNING)
    logger.info("=" * 5 + " AIStudioProxyServer Êó•ÂøóÁ≥ªÁªüÂ∑≤Âú® lifespan ‰∏≠ÂàùÂßãÂåñ " + "=" * 5)
    logger.info(f"Êó•ÂøóÁ∫ßÂà´ËÆæÁΩÆ‰∏∫: {logging.getLevelName(log_level)}")
    logger.info(f"Êó•ÂøóÊñá‰ª∂Ë∑ØÂæÑ: {APP_LOG_FILE_PATH}")
    logger.info(f"ÊéßÂà∂Âè∞Êó•ÂøóÂ§ÑÁêÜÂô®Â∑≤Ê∑ªÂä†„ÄÇ")
    logger.info(f"Print ÈáçÂÆöÂêë (Áî± SERVER_REDIRECT_PRINT ÁéØÂ¢ÉÂèòÈáèÊéßÂà∂): {'ÂêØÁî®' if redirect_print else 'Á¶ÅÁî®'}")
    return original_stdout, original_stderr

def restore_original_streams(original_stdout, original_stderr):
    sys.stdout = original_stdout
    sys.stderr = original_stderr
    print("Â∑≤ÊÅ¢Â§ç server.py ÁöÑÂéüÂßã stdout Âíå stderr ÊµÅ„ÄÇ", file=sys.__stderr__)

# --- Pydantic Models ---
class FunctionCall(BaseModel):
    name: str
    arguments: str

class ToolCall(BaseModel):
    id: str
    type: str = "function"
    function: FunctionCall

class MessageContentItem(BaseModel):
    type: str
    text: Optional[str] = None

class Message(BaseModel):
    role: str
    content: Union[str, List[MessageContentItem], None] = None
    name: Optional[str] = None
    tool_calls: Optional[List[ToolCall]] = None
    tool_call_id: Optional[str] = None

class ChatCompletionRequest(BaseModel):
    messages: List[Message]
    model: Optional[str] = MODEL_NAME
    stream: Optional[bool] = False
    temperature: Optional[float] = None
    max_output_tokens: Optional[int] = None
    stop: Optional[Union[str, List[str]]] = None
    top_p: Optional[float] = None

# --- Custom Exception ---
class ClientDisconnectedError(Exception):
    pass

# --- Helper Functions ---
def prepare_combined_prompt(messages: List[Message], req_id: str) -> str:
    # Using logger instead of print
    logger.info(f"[{req_id}] (ÂáÜÂ§áÊèêÁ§∫) Ê≠£Âú®‰ªé {len(messages)} Êù°Ê∂àÊÅØÂáÜÂ§áÁªÑÂêàÊèêÁ§∫ (ÂåÖÊã¨ÂéÜÂè≤)„ÄÇ")
    combined_parts = []
    system_prompt_content: Optional[str] = None
    processed_system_message_indices: Set[int] = set()
    for i, msg in enumerate(messages):
        if msg.role == 'system':
            if isinstance(msg.content, str) and msg.content.strip():
                system_prompt_content = msg.content.strip()
                processed_system_message_indices.add(i)
                logger.info(f"[{req_id}] (ÂáÜÂ§áÊèêÁ§∫) Âú®Á¥¢Âºï {i} ÊâæÂà∞Âπ∂‰ΩøÁî®Á≥ªÁªüÊèêÁ§∫: '{system_prompt_content[:80]}...'")
                system_instr_prefix = "Á≥ªÁªüÊåá‰ª§:\n"
                combined_parts.append(f"{system_instr_prefix}{system_prompt_content}")
            else:
                logger.info(f"[{req_id}] (ÂáÜÂ§áÊèêÁ§∫) Âú®Á¥¢Âºï {i} ÂøΩÁï•ÈùûÂ≠óÁ¨¶‰∏≤ÊàñÁ©∫ÁöÑÁ≥ªÁªüÊ∂àÊÅØ„ÄÇ")
                processed_system_message_indices.add(i)
            break
    role_map_ui = {"user": "Áî®Êà∑", "assistant": "Âä©Êâã", "system": "Á≥ªÁªü", "tool": "Â∑•ÂÖ∑"}
    turn_separator = "\n---\n"
    for i, msg in enumerate(messages):
        if i in processed_system_message_indices:
            continue
        if msg.role == 'system':
            logger.info(f"[{req_id}] (ÂáÜÂ§áÊèêÁ§∫) Ë∑≥ËøáÂú®Á¥¢Âºï {i} ÁöÑÂêéÁª≠Á≥ªÁªüÊ∂àÊÅØ„ÄÇ")
            continue
        if combined_parts:
            combined_parts.append(turn_separator)
        role_prefix_ui = f"{role_map_ui.get(msg.role, msg.role.capitalize())}:\n"
        current_turn_parts = [role_prefix_ui]
        content_str = ""
        if isinstance(msg.content, str):
            content_str = msg.content.strip()
        elif isinstance(msg.content, list):
            text_parts = []
            for item_model in msg.content:
                if isinstance(item_model, dict):
                    item_type = item_model.get('type')
                    if item_type == 'text' and isinstance(item_model.get('text'), str):
                        text_parts.append(item_model['text'])
                    else:
                        logger.warning(f"[{req_id}] (ÂáÜÂ§áÊèêÁ§∫) Ë≠¶Âëä: Âú®Á¥¢Âºï {i} ÁöÑÊ∂àÊÅØ‰∏≠ÂøΩÁï•ÈùûÊñáÊú¨ÊàñÊú™Áü•Á±ªÂûãÁöÑ content item: Á±ªÂûã={item_type}")
                elif isinstance(item_model, MessageContentItem):
                    if item_model.type == 'text' and isinstance(item_model.text, str):
                        text_parts.append(item_model.text)
                    else:
                        logger.warning(f"[{req_id}] (ÂáÜÂ§áÊèêÁ§∫) Ë≠¶Âëä: Âú®Á¥¢Âºï {i} ÁöÑÊ∂àÊÅØ‰∏≠ÂøΩÁï•ÈùûÊñáÊú¨ÊàñÊú™Áü•Á±ªÂûãÁöÑ content item: Á±ªÂûã={item_model.type}")
            content_str = "\n".join(text_parts).strip()
        elif msg.content is None and msg.role == 'assistant' and hasattr(msg, 'tool_calls') and msg.tool_calls:
            pass
        elif msg.content is None and msg.role == 'tool':
             logger.warning(f"[{req_id}] (ÂáÜÂ§áÊèêÁ§∫) Ë≠¶Âëä: ËßíËâ≤ 'tool' Âú®Á¥¢Âºï {i} ÁöÑ content ‰∏∫ NoneÔºåËøôÈÄöÂ∏∏‰∏çÁ¨¶ÂêàÈ¢ÑÊúü„ÄÇ")
        else:
            logger.warning(f"[{req_id}] (ÂáÜÂ§áÊèêÁ§∫) Ë≠¶Âëä: ËßíËâ≤ {msg.role} Âú®Á¥¢Âºï {i} ÁöÑÂÜÖÂÆπÁ±ªÂûãÊÑèÂ§ñ ({type(msg.content)}) Êàñ‰∏∫ None„ÄÇÂ∞ÜÂ∞ùËØïËΩ¨Êç¢‰∏∫Á©∫Â≠óÁ¨¶‰∏≤„ÄÇ")
            content_str = str(msg.content or "").strip()
        if content_str:
            current_turn_parts.append(content_str)
        if msg.role == 'assistant' and hasattr(msg, 'tool_calls') and msg.tool_calls:
            if content_str:
                current_turn_parts.append("\n")
            tool_call_visualizations = []
            if msg.tool_calls:
                for tool_call in msg.tool_calls:
                    if isinstance(tool_call, dict) and tool_call.get('type') == 'function':
                        function_call = tool_call.get('function')
                        if isinstance(function_call, dict):
                            func_name = function_call.get('name')
                            func_args_str = function_call.get('arguments')
                            try:
                                parsed_args = json.loads(func_args_str if func_args_str else '{}')
                                formatted_args = json.dumps(parsed_args, indent=2, ensure_ascii=False)
                            except (json.JSONDecodeError, TypeError):
                                formatted_args = func_args_str if func_args_str is not None else "{}"
                            tool_call_visualizations.append(
                                f"ËØ∑Ê±ÇË∞ÉÁî®ÂáΩÊï∞: {func_name}\nÂèÇÊï∞:\n{formatted_args}"
                            )
            if tool_call_visualizations:
                current_turn_parts.append("\n".join(tool_call_visualizations))
        if msg.role == 'tool' and hasattr(msg, 'tool_call_id') and msg.tool_call_id:
            if hasattr(msg, 'name') and msg.name and content_str:
                pass
            elif not content_str:
                 logger.warning(f"[{req_id}] (ÂáÜÂ§áÊèêÁ§∫) Ë≠¶Âëä: ËßíËâ≤ 'tool' (ID: {msg.tool_call_id}, Name: {getattr(msg, 'name', 'N/A')}) Âú®Á¥¢Âºï {i} ÁöÑ content ‰∏∫Á©∫ÔºåËøôÈÄöÂ∏∏Ë°®Á§∫ÂáΩÊï∞ÊâßË°åÊó†Â≠óÁ¨¶‰∏≤ËæìÂá∫ÊàñÁªìÊûúÊú™Êèê‰æõ„ÄÇ")
        if len(current_turn_parts) > 1 or (msg.role == 'assistant' and hasattr(msg, 'tool_calls') and msg.tool_calls):
            combined_parts.append("".join(current_turn_parts))
        elif not combined_parts and not current_turn_parts:
            logger.info(f"[{req_id}] (ÂáÜÂ§áÊèêÁ§∫) Ë∑≥ËøáËßíËâ≤ {msg.role} Âú®Á¥¢Âºï {i} ÁöÑÁ©∫Ê∂àÊÅØ (‰∏îÊó†Â∑•ÂÖ∑Ë∞ÉÁî®)„ÄÇ")
        elif len(current_turn_parts) == 1 and not combined_parts:
             logger.info(f"[{req_id}] (ÂáÜÂ§áÊèêÁ§∫) Ë∑≥ËøáËßíËâ≤ {msg.role} Âú®Á¥¢Âºï {i} ÁöÑÁ©∫Ê∂àÊÅØ (Âè™ÊúâÂâçÁºÄ)„ÄÇ")
    final_prompt = "".join(combined_parts)
    if final_prompt:
        final_prompt += "\n"
    preview_text = final_prompt[:300].replace('\n', '\\n')
    logger.info(f"[{req_id}] (ÂáÜÂ§áÊèêÁ§∫) ÁªÑÂêàÊèêÁ§∫ÈïøÂ∫¶: {len(final_prompt)}„ÄÇÈ¢ÑËßà: '{preview_text}...'")
    return final_prompt

def validate_chat_request(messages: List[Message], req_id: str) -> Dict[str, Optional[str]]:
    if not messages:
        raise ValueError(f"[{req_id}] Êó†ÊïàËØ∑Ê±Ç: 'messages' Êï∞ÁªÑÁº∫Â§±Êàñ‰∏∫Á©∫„ÄÇ")
    if not any(msg.role != 'system' for msg in messages):
        raise ValueError(f"[{req_id}] Êó†ÊïàËØ∑Ê±Ç: Êú™ÊâæÂà∞Áî®Êà∑ÊàñÂä©ÊâãÊ∂àÊÅØ„ÄÇ")
    logger.info(f"[{req_id}] (Ê†°È™å) ÂØπ {len(messages)} Êù°Ê∂àÊÅØÁöÑÂü∫Êú¨Ê†°È™åÈÄöËøá„ÄÇ")
    return {}

async def get_raw_text_content(response_element: Locator, previous_text: str, req_id: str) -> str:
    raw_text = previous_text
    try:
        await response_element.wait_for(state='attached', timeout=1000)
        pre_element = response_element.locator('pre').last
        pre_found_and_visible = False
        try:
            await pre_element.wait_for(state='visible', timeout=250)
            pre_found_and_visible = True
        except PlaywrightAsyncError: pass
        if pre_found_and_visible:
            try:
                raw_text = await pre_element.inner_text(timeout=500)
            except PlaywrightAsyncError as pre_err:
                if DEBUG_LOGS_ENABLED:
                    error_message_first_line = pre_err.message.split('\n')[0]
                    logger.warning(f"[{req_id}] ‰ªéÂèØËßÅÁöÑ <pre> Ëé∑Âèñ innerText Â§±Ë¥•: {error_message_first_line}")
                try:
                     raw_text = await response_element.inner_text(timeout=1000)
                except PlaywrightAsyncError as e_parent:
                     if DEBUG_LOGS_ENABLED:
                         logger.warning(f"[{req_id}] Âú® <pre> Ëé∑ÂèñÂ§±Ë¥•ÂêéÔºå‰ªéÁà∂ÂÖÉÁ¥†Ëé∑Âèñ inner_text Â§±Ë¥•: {e_parent}„ÄÇËøîÂõûÂÖàÂâçÊñáÊú¨„ÄÇ")
                     raw_text = previous_text
        else:
            try:
                 raw_text = await response_element.inner_text(timeout=1500)
            except PlaywrightAsyncError as e_parent:
                 if DEBUG_LOGS_ENABLED:
                     logger.warning(f"[{req_id}] ‰ªéÁà∂ÂÖÉÁ¥†Ëé∑Âèñ inner_text Â§±Ë¥• (Êó† pre ÂÖÉÁ¥†): {e_parent}„ÄÇËøîÂõûÂÖàÂâçÊñáÊú¨„ÄÇ")
                 raw_text = previous_text
        if raw_text and isinstance(raw_text, str):
            replacements = {
                "": ""
            }
            cleaned_text = raw_text
            found_junk = False
            for junk, replacement in replacements.items():
                if junk in cleaned_text:
                    cleaned_text = cleaned_text.replace(junk, replacement)
                    found_junk = True
            if found_junk:
                cleaned_text = "\n".join([line.strip() for line in cleaned_text.splitlines() if line.strip()])
                if DEBUG_LOGS_ENABLED:
                     logger.debug(f"[{req_id}] (Ê∏ÖÁêÜ) Â∑≤ÁßªÈô§ÂìçÂ∫îÊñáÊú¨‰∏≠ÁöÑÂ∑≤Áü•UIÂÖÉÁ¥†„ÄÇ")
                raw_text = cleaned_text
        return raw_text
    except PlaywrightAsyncError:
        return previous_text
    except Exception as e_general:
         logger.warning(f"[{req_id}] getRawTextContent ‰∏≠ÂèëÁîüÊÑèÂ§ñÈîôËØØ: {e_general}„ÄÇËøîÂõûÂÖàÂâçÊñáÊú¨„ÄÇ")
         return previous_text

def generate_sse_chunk(delta: str, req_id: str, model: str) -> str:
    chunk = {
        "id": f"{CHAT_COMPLETION_ID_PREFIX}{req_id}-{int(time.time())}-{random.randint(100, 999)}",
        "object": "chat.completion.chunk", "created": int(time.time()), "model": model,
        "choices": [{"index": 0, "delta": {"content": delta}, "finish_reason": None}]
    }
    return f"data: {json.dumps(chunk)}\n\n"

def generate_sse_stop_chunk(req_id: str, model: str, reason: str = "stop") -> str:
    chunk = {
        "id": f"{CHAT_COMPLETION_ID_PREFIX}{req_id}-{int(time.time())}-{random.randint(100, 999)}",
        "object": "chat.completion.chunk", "created": int(time.time()), "model": model,
        "choices": [{"index": 0, "delta": {}, "finish_reason": reason}]
    }
    return f"data: {json.dumps(chunk)}\n\n"

def generate_sse_error_chunk(message: str, req_id: str, error_type: str = "server_error") -> str:
    error_payload = {"error": {"message": f"[{req_id}] {message}", "type": error_type}}
    return f"data: {json.dumps(error_payload)}\n\n"

async def _initialize_page_logic(browser: AsyncBrowser):
    logger.info("--- ÂàùÂßãÂåñÈ°µÈù¢ÈÄªËæë (ËøûÊé•Âà∞Áé∞ÊúâÊµèËßàÂô®) ---")
    temp_context: Optional[AsyncBrowserContext] = None
    storage_state_path_to_use: Optional[str] = None
    launch_mode = os.environ.get('LAUNCH_MODE', 'debug')
    logger.info(f"   Ê£ÄÊµãÂà∞ÂêØÂä®Ê®°Âºè: {launch_mode}")
    loop = asyncio.get_running_loop()
    if launch_mode == 'headless':
        auth_filename = os.environ.get('ACTIVE_AUTH_JSON_PATH')
        if auth_filename:
            constructed_path = auth_filename
            if os.path.exists(constructed_path):
                storage_state_path_to_use = constructed_path
                logger.info(f"   Êó†Â§¥Ê®°ÂºèÂ∞Ü‰ΩøÁî®ÁöÑËÆ§ËØÅÊñá‰ª∂: {constructed_path}")
            else:
                logger.error(f"Êó†Â§¥Ê®°ÂºèËÆ§ËØÅÊñá‰ª∂Êó†ÊïàÊàñ‰∏çÂ≠òÂú®: '{constructed_path}'")
                raise RuntimeError(f"Êó†Â§¥Ê®°ÂºèËÆ§ËØÅÊñá‰ª∂Êó†Êïà: '{constructed_path}'")
        else:
            logger.error("Êó†Â§¥Ê®°ÂºèÈúÄË¶Å ACTIVE_AUTH_JSON_PATH ÁéØÂ¢ÉÂèòÈáèÔºå‰ΩÜÊú™ËÆæÁΩÆÊàñ‰∏∫Á©∫„ÄÇ")
            raise RuntimeError("Êó†Â§¥Ê®°ÂºèÈúÄË¶Å ACTIVE_AUTH_JSON_PATH„ÄÇ")
    elif launch_mode == 'debug':
        logger.info(f"   Ë∞ÉËØïÊ®°Âºè: Â∞ùËØï‰ªéÁéØÂ¢ÉÂèòÈáè ACTIVE_AUTH_JSON_PATH Âä†ËΩΩËÆ§ËØÅÊñá‰ª∂...")
        auth_filepath_from_env = os.environ.get('ACTIVE_AUTH_JSON_PATH')
        if auth_filepath_from_env and os.path.exists(auth_filepath_from_env):
            storage_state_path_to_use = auth_filepath_from_env
            logger.info(f"   Ë∞ÉËØïÊ®°ÂºèÂ∞Ü‰ΩøÁî®ÁöÑËÆ§ËØÅÊñá‰ª∂ (Êù•Ëá™ÁéØÂ¢ÉÂèòÈáè): {storage_state_path_to_use}")
        elif auth_filepath_from_env:
            logger.warning(f"   Ë∞ÉËØïÊ®°Âºè‰∏ãÁéØÂ¢ÉÂèòÈáè ACTIVE_AUTH_JSON_PATH ÊåáÂêëÁöÑÊñá‰ª∂‰∏çÂ≠òÂú®: '{auth_filepath_from_env}'„ÄÇ‰∏çÂä†ËΩΩËÆ§ËØÅÊñá‰ª∂„ÄÇ")
        else:
            logger.info("   Ë∞ÉËØïÊ®°Âºè‰∏ãÊú™ÈÄöËøáÁéØÂ¢ÉÂèòÈáèÊèê‰æõËÆ§ËØÅÊñá‰ª∂„ÄÇÂ∞Ü‰ΩøÁî®ÊµèËßàÂô®ÂΩìÂâçÁä∂ÊÄÅ„ÄÇ")
    elif launch_mode == "direct_debug_no_browser":
        logger.info("   direct_debug_no_browser Ê®°ÂºèÔºö‰∏çÂä†ËΩΩ storage_stateÔºå‰∏çËøõË°åÊµèËßàÂô®Êìç‰Ωú„ÄÇ")
    else:
        logger.warning(f"   ‚ö†Ô∏è Ë≠¶Âëä: Êú™Áü•ÁöÑÂêØÂä®Ê®°Âºè '{launch_mode}'„ÄÇ‰∏çÂä†ËΩΩ storage_state„ÄÇ")
    try:
        logger.info("ÂàõÂª∫Êñ∞ÁöÑÊµèËßàÂô®‰∏ä‰∏ãÊñá...")
        context_options: Dict[str, Any] = {'viewport': {'width': 460, 'height': 800}}
        if storage_state_path_to_use:
            context_options['storage_state'] = storage_state_path_to_use
            logger.info(f"   (‰ΩøÁî® storage_state='{os.path.basename(storage_state_path_to_use)}')")
        else:
            logger.info("   (‰∏ç‰ΩøÁî® storage_state)")
        if PLAYWRIGHT_PROXY_SETTINGS:
            context_options['proxy'] = PLAYWRIGHT_PROXY_SETTINGS
            logger.info(f"   (ÊµèËßàÂô®‰∏ä‰∏ãÊñáÂ∞Ü‰ΩøÁî®‰ª£ÁêÜ: {PLAYWRIGHT_PROXY_SETTINGS['server']})")
        else:
            logger.info("   (ÊµèËßàÂô®‰∏ä‰∏ãÊñá‰∏ç‰ΩøÁî®ÊòæÂºè‰ª£ÁêÜÈÖçÁΩÆ)")
        temp_context = await browser.new_context(**context_options)
        found_page: Optional[AsyncPage] = None
        pages = temp_context.pages
        target_url_base = f"https://{AI_STUDIO_URL_PATTERN}"
        target_full_url = f"{target_url_base}prompts/new_chat"
        login_url_pattern = 'accounts.google.com'
        current_url = ""
        for p_iter in pages:
            try:
                page_url_to_check = p_iter.url
                if not p_iter.is_closed() and target_url_base in page_url_to_check and "/prompts/" in page_url_to_check:
                    found_page = p_iter
                    current_url = page_url_to_check
                    logger.info(f"   ÊâæÂà∞Â∑≤ÊâìÂºÄÁöÑ AI Studio È°µÈù¢: {current_url}")
                    if found_page:
                        logger.info(f"   ‰∏∫Â∑≤Â≠òÂú®ÁöÑÈ°µÈù¢ {found_page.url} Ê∑ªÂä†Ê®°ÂûãÂàóË°®ÂìçÂ∫îÁõëÂê¨Âô®„ÄÇ")
                        found_page.on("response", _handle_model_list_response)
                    break
            except PlaywrightAsyncError as pw_err_url:
                logger.warning(f"   Ê£ÄÊü•È°µÈù¢ URL Êó∂Âá∫Áé∞ Playwright ÈîôËØØ: {pw_err_url}")
            except AttributeError as attr_err_url:
                logger.warning(f"   Ê£ÄÊü•È°µÈù¢ URL Êó∂Âá∫Áé∞Â±ûÊÄßÈîôËØØ: {attr_err_url}")
            except Exception as e_url_check:
                logger.warning(f"   Ê£ÄÊü•È°µÈù¢ URL Êó∂Âá∫Áé∞ÂÖ∂‰ªñÊú™È¢ÑÊúüÈîôËØØ: {e_url_check} (Á±ªÂûã: {type(e_url_check).__name__})")
        if not found_page:
            logger.info(f"-> Êú™ÊâæÂà∞ÂêàÈÄÇÁöÑÁé∞ÊúâÈ°µÈù¢ÔºåÊ≠£Âú®ÊâìÂºÄÊñ∞È°µÈù¢Âπ∂ÂØºËà™Âà∞ {target_full_url}...")
            found_page = await temp_context.new_page()
            if found_page:
                logger.info(f"   ‰∏∫Êñ∞ÂàõÂª∫ÁöÑÈ°µÈù¢Ê∑ªÂä†Ê®°ÂûãÂàóË°®ÂìçÂ∫îÁõëÂê¨Âô® (ÂØºËà™Ââç)„ÄÇ")
                found_page.on("response", _handle_model_list_response)
            try:
                await found_page.goto(target_full_url, wait_until="domcontentloaded", timeout=90000)
                current_url = found_page.url
                logger.info(f"-> Êñ∞È°µÈù¢ÂØºËà™Â∞ùËØïÂÆåÊàê„ÄÇÂΩìÂâç URL: {current_url}")
            except Exception as new_page_nav_err:
                await save_error_snapshot("init_new_page_nav_fail")
                error_str = str(new_page_nav_err)
                if "NS_ERROR_NET_INTERRUPT" in error_str:
                    logger.error("\n" + "="*30 + " ÁΩëÁªúÂØºËà™ÈîôËØØÊèêÁ§∫ " + "="*30)
                    logger.error(f"‚ùå ÂØºËà™Âà∞ '{target_full_url}' Â§±Ë¥•ÔºåÂá∫Áé∞ÁΩëÁªú‰∏≠Êñ≠ÈîôËØØ (NS_ERROR_NET_INTERRUPT)„ÄÇ")
                    logger.error("   ËøôÈÄöÂ∏∏Ë°®Á§∫ÊµèËßàÂô®Âú®Â∞ùËØïÂä†ËΩΩÈ°µÈù¢Êó∂ËøûÊé•Ë¢´ÊÑèÂ§ñÊñ≠ÂºÄ„ÄÇ")
                    logger.error("   ÂèØËÉΩÁöÑÂéüÂõ†ÂèäÊéíÊü•Âª∫ËÆÆ:")
                    logger.error("     1. ÁΩëÁªúËøûÊé•: ËØ∑Ê£ÄÊü•‰Ω†ÁöÑÊú¨Âú∞ÁΩëÁªúËøûÊé•ÊòØÂê¶Á®≥ÂÆöÔºåÂπ∂Â∞ùËØïÂú®ÊôÆÈÄöÊµèËßàÂô®‰∏≠ËÆøÈóÆÁõÆÊ†áÁΩëÂùÄ„ÄÇ")
                    logger.error("     2. AI Studio ÊúçÂä°: Á°ÆËÆ§ aistudio.google.com ÊúçÂä°Êú¨Ë∫´ÊòØÂê¶ÂèØÁî®„ÄÇ")
                    logger.error("     3. Èò≤ÁÅ´Â¢ô/‰ª£ÁêÜ/VPN: Ê£ÄÊü•Êú¨Âú∞Èò≤ÁÅ´Â¢ô„ÄÅÊùÄÊØíËΩØ‰ª∂„ÄÅ‰ª£ÁêÜÊàñ VPN ËÆæÁΩÆ„ÄÇ")
                    logger.error("     4. Camoufox ÊúçÂä°: Á°ÆËÆ§ launch_camoufox.py ËÑöÊú¨ÊòØÂê¶Ê≠£Â∏∏ËøêË°å„ÄÇ")
                    logger.error("     5. Á≥ªÁªüËµÑÊ∫êÈóÆÈ¢ò: Á°Æ‰øùÁ≥ªÁªüÊúâË∂≥Â§üÁöÑÂÜÖÂ≠òÂíå CPU ËµÑÊ∫ê„ÄÇ")
                    logger.error("="*74 + "\n")
                raise RuntimeError(f"ÂØºËà™Êñ∞È°µÈù¢Â§±Ë¥•: {new_page_nav_err}") from new_page_nav_err
        if login_url_pattern in current_url:
            if launch_mode == 'headless':
                logger.error("Êó†Â§¥Ê®°Âºè‰∏ãÊ£ÄÊµãÂà∞ÈáçÂÆöÂêëËá≥ÁôªÂΩïÈ°µÈù¢ÔºåËÆ§ËØÅÂèØËÉΩÂ∑≤Â§±Êïà„ÄÇËØ∑Êõ¥Êñ∞ËÆ§ËØÅÊñá‰ª∂„ÄÇ")
                raise RuntimeError("Êó†Â§¥Ê®°ÂºèËÆ§ËØÅÂ§±Ë¥•ÔºåÈúÄË¶ÅÊõ¥Êñ∞ËÆ§ËØÅÊñá‰ª∂„ÄÇ")
            else:
                print(f"\n{'='*20} ÈúÄË¶ÅÊìç‰Ωú {'='*20}", flush=True)
                login_prompt = "   Ê£ÄÊµãÂà∞ÂèØËÉΩÈúÄË¶ÅÁôªÂΩï„ÄÇÂ¶ÇÊûúÊµèËßàÂô®ÊòæÁ§∫ÁôªÂΩïÈ°µÈù¢ÔºåËØ∑Âú®ÊµèËßàÂô®Á™óÂè£‰∏≠ÂÆåÊàê Google ÁôªÂΩïÔºåÁÑ∂ÂêéÂú®Ê≠§Â§ÑÊåâ Enter ÈîÆÁªßÁª≠..."
                print(USER_INPUT_START_MARKER_SERVER, flush=True)
                await loop.run_in_executor(None, input, login_prompt)
                print(USER_INPUT_END_MARKER_SERVER, flush=True)
                logger.info("   Áî®Êà∑Â∑≤Êìç‰ΩúÔºåÊ≠£Âú®Ê£ÄÊü•ÁôªÂΩïÁä∂ÊÄÅ...")
                try:
                    await found_page.wait_for_url(f"**/{AI_STUDIO_URL_PATTERN}**", timeout=180000)
                    current_url = found_page.url
                    if login_url_pattern in current_url:
                        logger.error("ÊâãÂä®ÁôªÂΩïÂ∞ùËØïÂêéÔºåÈ°µÈù¢‰ºº‰πé‰ªçÂÅúÁïôÂú®ÁôªÂΩïÈ°µÈù¢„ÄÇ")
                        raise RuntimeError("ÊâãÂä®ÁôªÂΩïÂ∞ùËØïÂêé‰ªçÂú®ÁôªÂΩïÈ°µÈù¢„ÄÇ")
                    logger.info("   ‚úÖ ÁôªÂΩïÊàêÂäüÔºÅËØ∑‰∏çË¶ÅÊìç‰ΩúÊµèËßàÂô®Á™óÂè£ÔºåÁ≠âÂæÖÂêéÁª≠ÊèêÁ§∫„ÄÇ")
                    print("\n" + "="*50, flush=True)
                    print("   „ÄêÁî®Êà∑‰∫§‰∫í„ÄëÈúÄË¶ÅÊÇ®ÁöÑËæìÂÖ•!", flush=True)
                    save_auth_prompt = "   ÊòØÂê¶Ë¶ÅÂ∞ÜÂΩìÂâçÁöÑÊµèËßàÂô®ËÆ§ËØÅÁä∂ÊÄÅ‰øùÂ≠òÂà∞Êñá‰ª∂Ôºü (y/N): "
                    should_save_auth_choice = ''
                    if AUTO_SAVE_AUTH and launch_mode == 'debug':
                        logger.info("   Ëá™Âä®‰øùÂ≠òËÆ§ËØÅÊ®°ÂºèÂ∑≤ÂêØÁî®ÔºåÂ∞ÜËá™Âä®‰øùÂ≠òËÆ§ËØÅÁä∂ÊÄÅ...")
                        should_save_auth_choice = 'y'
                    else:
                        print(USER_INPUT_START_MARKER_SERVER, flush=True)
                        try:
                            auth_save_input_future = loop.run_in_executor(None, input, save_auth_prompt)
                            should_save_auth_choice = await asyncio.wait_for(auth_save_input_future, timeout=AUTH_SAVE_TIMEOUT)
                        except asyncio.TimeoutError:
                            print(f"   ËæìÂÖ•Á≠âÂæÖË∂ÖÊó∂({AUTH_SAVE_TIMEOUT}Áßí)„ÄÇÈªòËÆ§‰∏ç‰øùÂ≠òËÆ§ËØÅÁä∂ÊÄÅ„ÄÇ", flush=True)
                            should_save_auth_choice = 'n'
                        finally:
                            print(USER_INPUT_END_MARKER_SERVER, flush=True)
                    if should_save_auth_choice.strip().lower() == 'y':
                        os.makedirs(SAVED_AUTH_DIR, exist_ok=True)
                        default_auth_filename = f"auth_state_{int(time.time())}.json"
                        print(USER_INPUT_START_MARKER_SERVER, flush=True)
                        filename_prompt_str = f"   ËØ∑ËæìÂÖ•‰øùÂ≠òÁöÑÊñá‰ª∂Âêç (ÈªòËÆ§‰∏∫: {default_auth_filename}): "
                        chosen_auth_filename = ''
                        try:
                            filename_input_future = loop.run_in_executor(None, input, filename_prompt_str)
                            chosen_auth_filename = await asyncio.wait_for(filename_input_future, timeout=AUTH_SAVE_TIMEOUT)
                        except asyncio.TimeoutError:
                            print(f"   ËæìÂÖ•Êñá‰ª∂ÂêçÁ≠âÂæÖË∂ÖÊó∂({AUTH_SAVE_TIMEOUT}Áßí)„ÄÇÂ∞Ü‰ΩøÁî®ÈªòËÆ§Êñá‰ª∂Âêç: {default_auth_filename}", flush=True)
                        finally:
                            print(USER_INPUT_END_MARKER_SERVER, flush=True)
                        final_auth_filename = chosen_auth_filename.strip() or default_auth_filename
                        if not final_auth_filename.endswith(".json"):
                            final_auth_filename += ".json"
                        auth_save_path = os.path.join(SAVED_AUTH_DIR, final_auth_filename)
                        try:
                            await temp_context.storage_state(path=auth_save_path)
                            print(f"   ‚úÖ ËÆ§ËØÅÁä∂ÊÄÅÂ∑≤ÊàêÂäü‰øùÂ≠òÂà∞: {auth_save_path}", flush=True)
                        except Exception as save_state_err:
                            logger.error(f"   ‚ùå ‰øùÂ≠òËÆ§ËØÅÁä∂ÊÄÅÂ§±Ë¥•: {save_state_err}", exc_info=True)
                            print(f"   ‚ùå ‰øùÂ≠òËÆ§ËØÅÁä∂ÊÄÅÂ§±Ë¥•: {save_state_err}", flush=True)
                    else:
                        print("   Â•ΩÁöÑÔºå‰∏ç‰øùÂ≠òËÆ§ËØÅÁä∂ÊÄÅ„ÄÇ", flush=True)
                    print("="*50 + "\n", flush=True)
                except Exception as wait_login_err:
                    await save_error_snapshot("init_login_wait_fail")
                    logger.error(f"ÁôªÂΩïÊèêÁ§∫ÂêéÊú™ËÉΩÊ£ÄÊµãÂà∞ AI Studio URL Êàñ‰øùÂ≠òÁä∂ÊÄÅÊó∂Âá∫Èîô: {wait_login_err}", exc_info=True)
                    raise RuntimeError(f"ÁôªÂΩïÊèêÁ§∫ÂêéÊú™ËÉΩÊ£ÄÊµãÂà∞ AI Studio URL: {wait_login_err}") from wait_login_err
        elif target_url_base not in current_url or "/prompts/" not in current_url:
            await save_error_snapshot("init_unexpected_page")
            logger.error(f"ÂàùÂßãÂØºËà™ÂêéÈ°µÈù¢ URL ÊÑèÂ§ñ: {current_url}„ÄÇÊúüÊúõÂåÖÂê´ '{target_url_base}' Âíå '/prompts/'„ÄÇ")
            raise RuntimeError(f"ÂàùÂßãÂØºËà™ÂêéÂá∫Áé∞ÊÑèÂ§ñÈ°µÈù¢: {current_url}„ÄÇ")
        logger.info(f"-> Á°ÆËÆ§ÂΩìÂâç‰Ωç‰∫é AI Studio ÂØπËØùÈ°µÈù¢: {current_url}")
        await found_page.bring_to_front()
        try:
            input_wrapper_locator = found_page.locator('ms-prompt-input-wrapper')
            await expect_async(input_wrapper_locator).to_be_visible(timeout=35000)
            await expect_async(found_page.locator(INPUT_SELECTOR)).to_be_visible(timeout=10000)
            logger.info("-> ‚úÖ Ê†∏ÂøÉËæìÂÖ•Âå∫ÂüüÂèØËßÅ„ÄÇ")
            model_name_locator = found_page.locator('mat-select[data-test-ms-model-selector] div.model-option-content span.gmat-body-medium')
            try:
                model_name_on_page = await model_name_locator.first.inner_text(timeout=5000)
                logger.info(f"-> ü§ñ È°µÈù¢Ê£ÄÊµãÂà∞ÁöÑÂΩìÂâçÊ®°Âûã: {model_name_on_page}")
            except PlaywrightAsyncError as e:
                logger.error(f"Ëé∑ÂèñÊ®°ÂûãÂêçÁß∞Êó∂Âá∫Èîô (model_name_locator): {e}")
                raise
            result_page_instance = found_page
            result_page_ready = True
            logger.info(f"‚úÖ È°µÈù¢ÈÄªËæëÂàùÂßãÂåñÊàêÂäü„ÄÇ")
            return result_page_instance, result_page_ready
        except Exception as input_visible_err:
             await save_error_snapshot("init_fail_input_timeout")
             logger.error(f"È°µÈù¢ÂàùÂßãÂåñÂ§±Ë¥•ÔºöÊ†∏ÂøÉËæìÂÖ•Âå∫ÂüüÊú™Âú®È¢ÑÊúüÊó∂Èó¥ÂÜÖÂèò‰∏∫ÂèØËßÅ„ÄÇÊúÄÂêéÁöÑ URL ÊòØ {found_page.url}", exc_info=True)
             raise RuntimeError(f"È°µÈù¢ÂàùÂßãÂåñÂ§±Ë¥•ÔºöÊ†∏ÂøÉËæìÂÖ•Âå∫ÂüüÊú™Âú®È¢ÑÊúüÊó∂Èó¥ÂÜÖÂèò‰∏∫ÂèØËßÅ„ÄÇÊúÄÂêéÁöÑ URL ÊòØ {found_page.url}") from input_visible_err
    except Exception as e_init_page:
        logger.critical(f"‚ùå È°µÈù¢ÈÄªËæëÂàùÂßãÂåñÊúüÈó¥ÂèëÁîü‰∏•ÈáçÊÑèÂ§ñÈîôËØØ: {e_init_page}", exc_info=True)
        if temp_context:
            try:
                logger.info(f"   Â∞ùËØïÂÖ≥Èó≠‰∏¥Êó∂ÁöÑÊµèËßàÂô®‰∏ä‰∏ãÊñá due to initialization error.")
                await temp_context.close()
                logger.info("   ‚úÖ ‰∏¥Êó∂ÊµèËßàÂô®‰∏ä‰∏ãÊñáÂ∑≤ÂÖ≥Èó≠„ÄÇ")
            except Exception as close_err:
                 logger.warning(f"   ‚ö†Ô∏è ÂÖ≥Èó≠‰∏¥Êó∂ÊµèËßàÂô®‰∏ä‰∏ãÊñáÊó∂Âá∫Èîô: {close_err}")
        await save_error_snapshot("init_unexpected_error")
        raise RuntimeError(f"È°µÈù¢ÂàùÂßãÂåñÊÑèÂ§ñÈîôËØØ: {e_init_page}") from e_init_page

async def _close_page_logic():
    global page_instance, is_page_ready
    logger.info("--- ËøêË°åÈ°µÈù¢ÈÄªËæëÂÖ≥Èó≠ --- ")
    if page_instance and not page_instance.is_closed():
        try:
            await page_instance.close()
            logger.info("   ‚úÖ È°µÈù¢Â∑≤ÂÖ≥Èó≠")
        except PlaywrightAsyncError as pw_err:
            logger.warning(f"   ‚ö†Ô∏è ÂÖ≥Èó≠È°µÈù¢Êó∂Âá∫Áé∞PlaywrightÈîôËØØ: {pw_err}")
        except asyncio.TimeoutError as timeout_err:
            logger.warning(f"   ‚ö†Ô∏è ÂÖ≥Èó≠È°µÈù¢Êó∂Ë∂ÖÊó∂: {timeout_err}")
        except Exception as other_err:
            logger.error(f"   ‚ö†Ô∏è ÂÖ≥Èó≠È°µÈù¢Êó∂Âá∫Áé∞ÊÑèÂ§ñÈîôËØØ: {other_err} (Á±ªÂûã: {type(other_err).__name__})", exc_info=True)
    page_instance = None
    is_page_ready = False
    logger.info("È°µÈù¢ÈÄªËæëÁä∂ÊÄÅÂ∑≤ÈáçÁΩÆ„ÄÇ")
    return None, False

async def _handle_model_list_response(response: Any):
    global global_model_list_raw_json, parsed_model_list, model_list_fetch_event, logger, MODELS_ENDPOINT_URL_CONTAINS, DEBUG_LOGS_ENABLED, excluded_model_ids
    if MODELS_ENDPOINT_URL_CONTAINS in response.url and response.ok:
        logger.info(f"ÊçïËé∑Âà∞ÊΩúÂú®ÁöÑÊ®°ÂûãÂàóË°®ÂìçÂ∫îÊù•Ëá™: {response.url} (Áä∂ÊÄÅ: {response.status})")
        try:
            data = await response.json()
            models_array_container = None
            if isinstance(data, list) and data:
                if isinstance(data[0], list) and data[0] and isinstance(data[0][0], list):
                    logger.info("Ê£ÄÊµãÂà∞‰∏âÂ±ÇÂàóË°®ÁªìÊûÑ data[0][0] is list. models_array_container ËÆæÁΩÆ‰∏∫ data[0]„ÄÇ")
                    models_array_container = data[0]
                elif isinstance(data[0], list) and data[0] and isinstance(data[0][0], str):
                    logger.info("Ê£ÄÊµãÂà∞‰∏§Â±ÇÂàóË°®ÁªìÊûÑ data[0][0] is str. models_array_container ËÆæÁΩÆ‰∏∫ data„ÄÇ")
                    models_array_container = data
                elif isinstance(data[0], dict):
                    logger.info("Ê£ÄÊµãÂà∞Ê†πÂàóË°®ÔºåÂÖÉÁ¥†‰∏∫Â≠óÂÖ∏„ÄÇÁõ¥Êé•‰ΩøÁî® data ‰Ωú‰∏∫ models_array_container„ÄÇ")
                    models_array_container = data
                else:
                    logger.warning(f"Êú™Áü•ÁöÑÂàóË°®ÂµåÂ•óÁªìÊûÑ„ÄÇdata[0] Á±ªÂûã: {type(data[0]) if data else 'N/A'}„ÄÇdata[0] È¢ÑËßà: {str(data[0])[:200] if data else 'N/A'}")
            elif isinstance(data, dict):
                if 'data' in data and isinstance(data['data'], list):
                    models_array_container = data['data']
                elif 'models' in data and isinstance(data['models'], list):
                    models_array_container = data['models']
                else:
                    for key, value in data.items():
                        if isinstance(value, list) and len(value) > 0 and isinstance(value[0], (dict, list)):
                            models_array_container = value
                            logger.info(f"Ê®°ÂûãÂàóË°®Êï∞ÊçÆÂú® '{key}' ÈîÆ‰∏ãÈÄöËøáÂêØÂèëÂºèÊêúÁ¥¢ÊâæÂà∞„ÄÇ")
                            break
                    if models_array_container is None:
                        logger.warning("Âú®Â≠óÂÖ∏ÂìçÂ∫î‰∏≠Êú™ËÉΩËá™Âä®ÂÆö‰ΩçÊ®°ÂûãÂàóË°®Êï∞ÁªÑ„ÄÇ")
                        if not model_list_fetch_event.is_set(): model_list_fetch_event.set()
                        return
            else:
                logger.warning(f"Êé•Êî∂Âà∞ÁöÑÊ®°ÂûãÂàóË°®Êï∞ÊçÆÊó¢‰∏çÊòØÂàóË°®‰πü‰∏çÊòØÂ≠óÂÖ∏: {type(data)}")
                if not model_list_fetch_event.is_set(): model_list_fetch_event.set()
                return
            if models_array_container is not None:
                new_parsed_list = []
                for entry_in_container in models_array_container:
                    model_fields_list = None
                    if isinstance(entry_in_container, dict):
                        potential_id = entry_in_container.get('id', entry_in_container.get('model_id', entry_in_container.get('modelId')))
                        if potential_id: model_fields_list = entry_in_container
                        else: model_fields_list = list(entry_in_container.values())
                    elif isinstance(entry_in_container, list):
                        model_fields_list = entry_in_container
                    else:
                        logger.debug(f"Skipping entry of unknown type: {type(entry_in_container)}")
                        continue
                    if not model_fields_list:
                        logger.debug("Skipping entry because model_fields_list is empty or None.")
                        continue
                    model_id_path_str = None
                    display_name_candidate = ""
                    description_candidate = "N/A"
                    default_max_output_tokens_val = None
                    default_top_p_val = None
                    default_temperature_val = 1.0
                    supported_max_output_tokens_val = None
                    current_model_id_for_log = "UnknownModelYet"
                    try:
                        if isinstance(model_fields_list, list):
                            if not (len(model_fields_list) > 0 and isinstance(model_fields_list[0], (str, int, float))):
                                logger.debug(f"Skipping list-based model_fields due to invalid first element: {str(model_fields_list)[:100]}")
                                continue
                            model_id_path_str = str(model_fields_list[0])
                            current_model_id_for_log = model_id_path_str.split('/')[-1] if model_id_path_str and '/' in model_id_path_str else model_id_path_str
                            display_name_candidate = str(model_fields_list[3]) if len(model_fields_list) > 3 else ""
                            description_candidate = str(model_fields_list[4]) if len(model_fields_list) > 4 else "N/A"
                            if len(model_fields_list) > 6 and model_fields_list[6] is not None:
                                try:
                                    val_int = int(model_fields_list[6])
                                    default_max_output_tokens_val = val_int
                                    supported_max_output_tokens_val = val_int
                                except (ValueError, TypeError):
                                    logger.warning(f"Ê®°Âûã {current_model_id_for_log}: Êó†Ê≥ïÂ∞ÜÂàóË°®Á¥¢Âºï6ÁöÑÂÄº '{model_fields_list[6]}' Ëß£Êûê‰∏∫ max_output_tokens„ÄÇ")
                            if len(model_fields_list) > 9 and model_fields_list[9] is not None:
                                try:
                                    raw_top_p = float(model_fields_list[9])
                                    if not (0.0 <= raw_top_p <= 1.0):
                                        logger.warning(f"Ê®°Âûã {current_model_id_for_log}: ÂéüÂßã top_pÂÄº {raw_top_p} (Êù•Ëá™ÂàóË°®Á¥¢Âºï9) Ë∂ÖÂá∫ [0,1] ËåÉÂõ¥ÔºåÂ∞ÜË£ÅÂâ™„ÄÇ")
                                        default_top_p_val = max(0.0, min(1.0, raw_top_p))
                                    else:
                                        default_top_p_val = raw_top_p
                                except (ValueError, TypeError):
                                    logger.warning(f"Ê®°Âûã {current_model_id_for_log}: Êó†Ê≥ïÂ∞ÜÂàóË°®Á¥¢Âºï9ÁöÑÂÄº '{model_fields_list[9]}' Ëß£Êûê‰∏∫ top_p„ÄÇ")
                        elif isinstance(model_fields_list, dict):
                            model_id_path_str = str(model_fields_list.get('id', model_fields_list.get('model_id', model_fields_list.get('modelId'))))
                            current_model_id_for_log = model_id_path_str.split('/')[-1] if model_id_path_str and '/' in model_id_path_str else model_id_path_str
                            display_name_candidate = str(model_fields_list.get('displayName', model_fields_list.get('display_name', model_fields_list.get('name', ''))))
                            description_candidate = str(model_fields_list.get('description', "N/A"))
                            mot_parsed = model_fields_list.get('maxOutputTokens', model_fields_list.get('defaultMaxOutputTokens', model_fields_list.get('outputTokenLimit')))
                            if mot_parsed is not None:
                                try:
                                    val_int = int(mot_parsed)
                                    default_max_output_tokens_val = val_int
                                    supported_max_output_tokens_val = val_int
                                except (ValueError, TypeError):
                                     logger.warning(f"Ê®°Âûã {current_model_id_for_log}: Êó†Ê≥ïÂ∞ÜÂ≠óÂÖ∏ÂÄº '{mot_parsed}' Ëß£Êûê‰∏∫ max_output_tokens„ÄÇ")
                            top_p_parsed = model_fields_list.get('topP', model_fields_list.get('defaultTopP'))
                            if top_p_parsed is not None:
                                try:
                                    raw_top_p = float(top_p_parsed)
                                    if not (0.0 <= raw_top_p <= 1.0):
                                        logger.warning(f"Ê®°Âûã {current_model_id_for_log}: ÂéüÂßã top_pÂÄº {raw_top_p} (Êù•Ëá™Â≠óÂÖ∏) Ë∂ÖÂá∫ [0,1] ËåÉÂõ¥ÔºåÂ∞ÜË£ÅÂâ™„ÄÇ")
                                        default_top_p_val = max(0.0, min(1.0, raw_top_p))
                                    else:
                                        default_top_p_val = raw_top_p
                                except (ValueError, TypeError):
                                    logger.warning(f"Ê®°Âûã {current_model_id_for_log}: Êó†Ê≥ïÂ∞ÜÂ≠óÂÖ∏ÂÄº '{top_p_parsed}' Ëß£Êûê‰∏∫ top_p„ÄÇ")
                            temp_parsed = model_fields_list.get('temperature', model_fields_list.get('defaultTemperature'))
                            if temp_parsed is not None:
                                try: default_temperature_val = float(temp_parsed)
                                except (ValueError, TypeError):
                                    logger.warning(f"Ê®°Âûã {current_model_id_for_log}: Êó†Ê≥ïÂ∞ÜÂ≠óÂÖ∏ÂÄº '{temp_parsed}' Ëß£Êûê‰∏∫ temperature„ÄÇ")
                        else:
                            logger.debug(f"Skipping entry because model_fields_list is not list or dict: {type(model_fields_list)}")
                            continue
                    except Exception as e_parse_fields:
                        logger.error(f"Ëß£ÊûêÊ®°ÂûãÂ≠óÊÆµÊó∂Âá∫Èîô for entry {str(entry_in_container)[:100]}: {e_parse_fields}")
                        continue
                    if model_id_path_str and model_id_path_str.lower() != "none":
                        simple_model_id_str = model_id_path_str.split('/')[-1] if '/' in model_id_path_str else model_id_path_str
                        if simple_model_id_str in excluded_model_ids:
                            logger.info(f"Ê®°Âûã '{simple_model_id_str}' Âú®ÊéíÈô§ÂàóË°® excluded_model_ids ‰∏≠ÔºåÂ∑≤Ë∑≥Ëøá„ÄÇ")
                            continue
                        final_display_name_str = display_name_candidate if display_name_candidate else simple_model_id_str.replace("-", " ").title()
                        model_entry_dict = {
                            "id": simple_model_id_str, "object": "model", "created": int(time.time()),
                            "owned_by": "ai_studio", "display_name": final_display_name_str,
                            "description": description_candidate, "raw_model_path": model_id_path_str,
                            "default_temperature": default_temperature_val,
                            "default_max_output_tokens": default_max_output_tokens_val,
                            "supported_max_output_tokens": supported_max_output_tokens_val,
                            "default_top_p": default_top_p_val
                        }
                        new_parsed_list.append(model_entry_dict)
                    else:
                        logger.debug(f"Skipping entry due to invalid model_id_path: {model_id_path_str} from entry {str(entry_in_container)[:100]}")
                if new_parsed_list:
                    parsed_model_list = sorted(new_parsed_list, key=lambda m: m.get('display_name', '').lower())
                    global_model_list_raw_json = json.dumps({"data": parsed_model_list, "object": "list"})
                    if DEBUG_LOGS_ENABLED:
                        log_output = f"ÊàêÂäüËß£ÊûêÂíåÊõ¥Êñ∞Ê®°ÂûãÂàóË°®„ÄÇÊÄªÂÖ±Ëß£ÊûêÊ®°ÂûãÊï∞: {len(parsed_model_list)}.\n"
                        for i, item in enumerate(parsed_model_list[:min(3, len(parsed_model_list))]):
                            log_output += f"  Model {i+1}: ID={item.get('id')}, Name={item.get('display_name')}, Temp={item.get('default_temperature')}, MaxTokDef={item.get('default_max_output_tokens')}, MaxTokSup={item.get('supported_max_output_tokens')}, TopP={item.get('default_top_p')}\n"
                        logger.info(log_output)
                    if not model_list_fetch_event.is_set(): model_list_fetch_event.set()
                elif not parsed_model_list:
                    logger.warning("Ëß£ÊûêÂêéÊ®°ÂûãÂàóË°®‰ªçÁÑ∂‰∏∫Á©∫„ÄÇ")
                    if not model_list_fetch_event.is_set(): model_list_fetch_event.set()
            else:
                logger.warning("models_array_container ‰∏∫ NoneÔºåÊó†Ê≥ïËß£ÊûêÊ®°ÂûãÂàóË°®„ÄÇ")
                if not model_list_fetch_event.is_set(): model_list_fetch_event.set()
        except json.JSONDecodeError as json_err:
            logger.error(f"Ëß£ÊûêÊ®°ÂûãÂàóË°®JSONÂ§±Ë¥•: {json_err}. ÂìçÂ∫î (Ââç500Â≠ó): {await response.text()[:500]}")
        except Exception as e_handle_list_resp:
            logger.exception(f"Â§ÑÁêÜÊ®°ÂûãÂàóË°®ÂìçÂ∫îÊó∂ÂèëÁîüÊú™Áü•ÈîôËØØ: {e_handle_list_resp}")
        finally:
            if not model_list_fetch_event.is_set():
                logger.info("Â§ÑÁêÜÊ®°ÂûãÂàóË°®ÂìçÂ∫îÁªìÊùüÔºåÂº∫Âà∂ËÆæÁΩÆ model_list_fetch_event„ÄÇ")
                model_list_fetch_event.set()

async def signal_camoufox_shutdown():
    logger.info("   Â∞ùËØïÂèëÈÄÅÂÖ≥Èó≠‰ø°Âè∑Âà∞ Camoufox ÊúçÂä°Âô® (Ê≠§ÂäüËÉΩÂèØËÉΩÂ∑≤Áî±Áà∂ËøõÁ®ãÂ§ÑÁêÜ)...")
    ws_endpoint = os.environ.get('CAMOUFOX_WS_ENDPOINT')
    if not ws_endpoint:
        logger.warning("   ‚ö†Ô∏è Êó†Ê≥ïÂèëÈÄÅÂÖ≥Èó≠‰ø°Âè∑ÔºöÊú™ÊâæÂà∞ CAMOUFOX_WS_ENDPOINT ÁéØÂ¢ÉÂèòÈáè„ÄÇ")
        return
    if not browser_instance or not browser_instance.is_connected():
        logger.warning("   ‚ö†Ô∏è ÊµèËßàÂô®ÂÆû‰æãÂ∑≤Êñ≠ÂºÄÊàñÊú™ÂàùÂßãÂåñÔºåË∑≥ËøáÂÖ≥Èó≠‰ø°Âè∑ÂèëÈÄÅ„ÄÇ")
        return
    try:
        await asyncio.sleep(0.2)
        logger.info("   ‚úÖ (Ê®°Êãü) ÂÖ≥Èó≠‰ø°Âè∑Â∑≤Â§ÑÁêÜ„ÄÇ")
    except Exception as e:
        logger.error(f"   ‚ö†Ô∏è ÂèëÈÄÅÂÖ≥Èó≠‰ø°Âè∑ËøáÁ®ã‰∏≠ÊçïËé∑ÂºÇÂ∏∏: {e}", exc_info=True)

# --- Lifespan Context Manager ---
@asynccontextmanager
async def lifespan(app_param: FastAPI):
    global playwright_manager, browser_instance, page_instance, worker_task
    global is_playwright_ready, is_browser_connected, is_page_ready, is_initializing
    global logger, log_ws_manager, model_list_fetch_event, current_ai_studio_model_id, excluded_model_ids
    global request_queue, processing_lock, model_switching_lock, page_params_cache, params_cache_lock
    true_original_stdout, true_original_stderr = sys.stdout, sys.stderr
    initial_stdout_before_redirect, initial_stderr_before_redirect = sys.stdout, sys.stderr
    if log_ws_manager is None:
        log_ws_manager = WebSocketConnectionManager()
    log_level_env = os.environ.get('SERVER_LOG_LEVEL', 'INFO')
    redirect_print_env = os.environ.get('SERVER_REDIRECT_PRINT', 'false')
    initial_stdout_before_redirect, initial_stderr_before_redirect = setup_server_logging(
        log_level_name=log_level_env,
        redirect_print_str=redirect_print_env
    )
    request_queue = asyncio.Queue()
    processing_lock = asyncio.Lock()
    model_switching_lock = asyncio.Lock()
    model_list_fetch_event = asyncio.Event()
    params_cache_lock = asyncio.Lock()
    if PLAYWRIGHT_PROXY_SETTINGS:
        logger.info(f"--- ‰ª£ÁêÜÈÖçÁΩÆÊ£ÄÊµãÂà∞ (Áî± server.py ÁöÑ lifespan ËÆ∞ÂΩï) ---")
        logger.info(f"   Â∞Ü‰ΩøÁî®‰ª£ÁêÜÊúçÂä°Âô®: {PLAYWRIGHT_PROXY_SETTINGS['server']}")
        if 'bypass' in PLAYWRIGHT_PROXY_SETTINGS:
            logger.info(f"   ÁªïËøá‰ª£ÁêÜÁöÑ‰∏ªÊú∫: {PLAYWRIGHT_PROXY_SETTINGS['bypass']}")
        logger.info(f"-----------------------")
    else:
        logger.info("--- Êú™Ê£ÄÊµãÂà∞ HTTP_PROXY Êàñ HTTPS_PROXY ÁéØÂ¢ÉÂèòÈáèÔºå‰∏ç‰ΩøÁî®‰ª£ÁêÜ (Áî± server.py ÁöÑ lifespan ËÆ∞ÂΩï) ---")
    load_excluded_models(EXCLUDED_MODELS_FILENAME)
    is_initializing = True
    logger.info("\n" + "="*60 + "\n          üöÄ AI Studio Proxy Server (FastAPI App Lifespan) üöÄ\n" + "="*60)
    logger.info(f"FastAPI Â∫îÁî®ÁîüÂëΩÂë®Êúü: ÂêØÂä®‰∏≠...")
    try:
        logger.info(f"   ÂêØÂä® Playwright...")
        playwright_manager = await async_playwright().start()
        is_playwright_ready = True
        logger.info(f"   ‚úÖ Playwright Â∑≤ÂêØÂä®„ÄÇ")
        ws_endpoint = os.environ.get('CAMOUFOX_WS_ENDPOINT')
        launch_mode = os.environ.get('LAUNCH_MODE', 'unknown')
        if not ws_endpoint:
            if launch_mode == "direct_debug_no_browser":
                logger.warning("CAMOUFOX_WS_ENDPOINT Êú™ËÆæÁΩÆÔºå‰ΩÜ LAUNCH_MODE Ë°®Êòé‰∏çÈúÄË¶ÅÊµèËßàÂô®„ÄÇË∑≥ËøáÊµèËßàÂô®ËøûÊé•„ÄÇ")
                is_browser_connected = False
                is_page_ready = False
                model_list_fetch_event.set()
            else:
                logger.error("Êú™ÊâæÂà∞ CAMOUFOX_WS_ENDPOINT ÁéØÂ¢ÉÂèòÈáè„ÄÇPlaywright Â∞ÜÊó†Ê≥ïËøûÊé•Âà∞ÊµèËßàÂô®„ÄÇ")
                raise ValueError("CAMOUFOX_WS_ENDPOINT ÁéØÂ¢ÉÂèòÈáèÁº∫Â§±„ÄÇ")
        else:
            logger.info(f"   ËøûÊé•Âà∞ Camoufox ÊúçÂä°Âô® (ÊµèËßàÂô® WebSocket Á´ØÁÇπ) ‰∫é: {ws_endpoint}")
            try:
                browser_instance = await playwright_manager.firefox.connect(ws_endpoint, timeout=30000)
                is_browser_connected = True
                logger.info(f"   ‚úÖ Â∑≤ËøûÊé•Âà∞ÊµèËßàÂô®ÂÆû‰æã: ÁâàÊú¨ {browser_instance.version}")
                temp_page_instance, temp_is_page_ready = await _initialize_page_logic(browser_instance)
                if temp_page_instance and temp_is_page_ready:
                    page_instance = temp_page_instance
                    is_page_ready = temp_is_page_ready
                    await _handle_initial_model_state_and_storage(page_instance)
                else:
                    is_page_ready = False
                    if not model_list_fetch_event.is_set(): model_list_fetch_event.set()
            except Exception as connect_err:
                logger.error(f"Êú™ËÉΩËøûÊé•Âà∞ Camoufox ÊúçÂä°Âô® (ÊµèËßàÂô®) ÊàñÂàùÂßãÂåñÈ°µÈù¢Â§±Ë¥•: {connect_err}", exc_info=True)
                if launch_mode != "direct_debug_no_browser":
                    raise RuntimeError(f"Êú™ËÉΩËøûÊé•Âà∞ Camoufox ÊàñÂàùÂßãÂåñÈ°µÈù¢: {connect_err}") from connect_err
                else:
                    is_browser_connected = False
                    is_page_ready = False
                    if not model_list_fetch_event.is_set(): model_list_fetch_event.set()
        if is_page_ready and is_browser_connected and not model_list_fetch_event.is_set():
            logger.info("Á≠âÂæÖÊ®°ÂûãÂàóË°®ÊçïËé∑ (ÊúÄÂ§öÁ≠âÂæÖ15Áßí)...")
            try:
                await asyncio.wait_for(model_list_fetch_event.wait(), timeout=15.0)
                if model_list_fetch_event.is_set():
                    logger.info("Ê®°ÂûãÂàóË°®‰∫ã‰ª∂Â∑≤Ëß¶Âèë„ÄÇ")
                else:
                    logger.warning("Ê®°ÂûãÂàóË°®‰∫ã‰ª∂Á≠âÂæÖÂêé‰ªçÊú™ËÆæÁΩÆ„ÄÇ")
            except asyncio.TimeoutError:
                logger.warning("Á≠âÂæÖÊ®°ÂûãÂàóË°®ÊçïËé∑Ë∂ÖÊó∂„ÄÇÂ∞Ü‰ΩøÁî®ÈªòËÆ§ÊàñÁ©∫ÂàóË°®„ÄÇ")
            finally:
                if not model_list_fetch_event.is_set():
                    model_list_fetch_event.set()
        elif not (is_page_ready and is_browser_connected):
             if not model_list_fetch_event.is_set(): model_list_fetch_event.set()
        if (is_page_ready and is_browser_connected) or launch_mode == "direct_debug_no_browser":
             logger.info(f"   ÂêØÂä®ËØ∑Ê±ÇÂ§ÑÁêÜ Worker...")
             worker_task = asyncio.create_task(queue_worker())
             logger.info(f"   ‚úÖ ËØ∑Ê±ÇÂ§ÑÁêÜ Worker Â∑≤ÂêØÂä®„ÄÇ")
        elif launch_mode == "direct_debug_no_browser":
            logger.warning("ÊµèËßàÂô®ÂíåÈ°µÈù¢Êú™Â∞±Áª™ (direct_debug_no_browser Ê®°Âºè)ÔºåËØ∑Ê±ÇÂ§ÑÁêÜ Worker Êú™ÂêØÂä®„ÄÇAPI ÂèØËÉΩÂäüËÉΩÂèóÈôê„ÄÇ")
        else:
             logger.error("È°µÈù¢ÊàñÊµèËßàÂô®ÂàùÂßãÂåñÂ§±Ë¥•ÔºåÊó†Ê≥ïÂêØÂä® Worker„ÄÇ")
             if not model_list_fetch_event.is_set(): model_list_fetch_event.set()
             raise RuntimeError("È°µÈù¢ÊàñÊµèËßàÂô®ÂàùÂßãÂåñÂ§±Ë¥•ÔºåÊó†Ê≥ïÂêØÂä® Worker„ÄÇ")
        logger.info(f"‚úÖ FastAPI Â∫îÁî®ÁîüÂëΩÂë®Êúü: ÂêØÂä®ÂÆåÊàê„ÄÇÊúçÂä°Â∑≤Â∞±Áª™„ÄÇ")
        is_initializing = False
        yield
    except Exception as startup_err:
        logger.critical(f"‚ùå FastAPI Â∫îÁî®ÁîüÂëΩÂë®Êúü: ÂêØÂä®ÊúüÈó¥ÂèëÁîü‰∏•ÈáçÈîôËØØ: {startup_err}", exc_info=True)
        if not model_list_fetch_event.is_set(): model_list_fetch_event.set()
        if worker_task and not worker_task.done(): worker_task.cancel()
        if browser_instance and browser_instance.is_connected():
            try: await browser_instance.close()
            except: pass
        if playwright_manager:
            try: await playwright_manager.stop()
            except: pass
        raise RuntimeError(f"Â∫îÁî®Á®ãÂ∫èÂêØÂä®Â§±Ë¥•: {startup_err}") from startup_err
    finally:
        is_initializing = False
        logger.info(f"\nFastAPI Â∫îÁî®ÁîüÂëΩÂë®Êúü: ÂÖ≥Èó≠‰∏≠...")
        if worker_task and not worker_task.done():
             logger.info(f"   Ê≠£Âú®ÂèñÊ∂àËØ∑Ê±ÇÂ§ÑÁêÜ Worker...")
             worker_task.cancel()
             try:
                 await asyncio.wait_for(worker_task, timeout=5.0)
                 logger.info(f"   ‚úÖ ËØ∑Ê±ÇÂ§ÑÁêÜ Worker Â∑≤ÂÅúÊ≠¢/ÂèñÊ∂à„ÄÇ")
             except asyncio.TimeoutError: logger.warning(f"   ‚ö†Ô∏è Worker Á≠âÂæÖË∂ÖÊó∂„ÄÇ")
             except asyncio.CancelledError: logger.info(f"   ‚úÖ ËØ∑Ê±ÇÂ§ÑÁêÜ Worker Â∑≤Á°ÆËÆ§ÂèñÊ∂à„ÄÇ")
             except Exception as wt_err: logger.error(f"   ‚ùå Á≠âÂæÖ Worker ÂÅúÊ≠¢Êó∂Âá∫Èîô: {wt_err}", exc_info=True)
        if page_instance and not page_instance.is_closed():
            try:
                logger.info("Lifespan Ê∏ÖÁêÜÔºöÁßªÈô§Ê®°ÂûãÂàóË°®ÂìçÂ∫îÁõëÂê¨Âô®„ÄÇ")
                page_instance.remove_listener("response", _handle_model_list_response)
            except Exception as e:
                logger.debug(f"Lifespan Ê∏ÖÁêÜÔºöÁßªÈô§ÁõëÂê¨Âô®Êó∂ÂèëÁîüÈùû‰∏•ÈáçÈîôËØØÊàñÁõëÂê¨Âô®Êú¨‰∏çÂ≠òÂú®: {e}")
        if page_instance:
            await _close_page_logic()
        if browser_instance:
            logger.info(f"   Ê≠£Âú®ÂÖ≥Èó≠‰∏éÊµèËßàÂô®ÂÆû‰æãÁöÑËøûÊé•...")
            try:
                if browser_instance.is_connected():
                    await browser_instance.close()
                    logger.info(f"   ‚úÖ ÊµèËßàÂô®ËøûÊé•Â∑≤ÂÖ≥Èó≠„ÄÇ")
                else: logger.info(f"   ‚ÑπÔ∏è ÊµèËßàÂô®ÂÖàÂâçÂ∑≤Êñ≠ÂºÄËøûÊé•„ÄÇ")
            except Exception as close_err: logger.error(f"   ‚ùå ÂÖ≥Èó≠ÊµèËßàÂô®ËøûÊé•Êó∂Âá∫Èîô: {close_err}", exc_info=True)
            finally: browser_instance = None; is_browser_connected = False; is_page_ready = False
        if playwright_manager:
            logger.info(f"   ÂÅúÊ≠¢ Playwright...")
            try:
                await playwright_manager.stop()
                logger.info(f"   ‚úÖ Playwright Â∑≤ÂÅúÊ≠¢„ÄÇ")
            except Exception as stop_err: logger.error(f"   ‚ùå ÂÅúÊ≠¢ Playwright Êó∂Âá∫Èîô: {stop_err}", exc_info=True)
            finally: playwright_manager = None; is_playwright_ready = False
        restore_original_streams(initial_stdout_before_redirect, initial_stderr_before_redirect)
        restore_original_streams(true_original_stdout, true_original_stderr)
        logger.info(f"‚úÖ FastAPI Â∫îÁî®ÁîüÂëΩÂë®Êúü: ÂÖ≥Èó≠ÂÆåÊàê„ÄÇ")

# --- FastAPI App ÂÆö‰πâ ---
app = FastAPI(
    title="AI Studio Proxy Server (ÈõÜÊàêÊ®°Âºè)",
    description="ÈÄöËøá Playwright‰∏é AI Studio ‰∫§‰∫íÁöÑ‰ª£ÁêÜÊúçÂä°Âô®„ÄÇ",
    version="0.6.0-integrated",
    lifespan=lifespan
)

# --- API Endpoints ---
@app.get("/", response_class=FileResponse)
async def read_index():
    index_html_path = os.path.join(os.path.dirname(__file__), "index.html")
    if not os.path.exists(index_html_path):
        logger.error(f"index.html not found at {index_html_path}")
        raise HTTPException(status_code=404, detail="index.html not found")
    return FileResponse(index_html_path)

@app.get("/webui.css")
async def get_css():
    css_path = os.path.join(os.path.dirname(__file__), "webui.css")
    if not os.path.exists(css_path):
        logger.error(f"webui.css not found at {css_path}")
        raise HTTPException(status_code=404, detail="webui.css not found")
    return FileResponse(css_path, media_type="text/css")

@app.get("/webui.js")
async def get_js():
    js_path = os.path.join(os.path.dirname(__file__), "webui.js")
    if not os.path.exists(js_path):
        logger.error(f"webui.js not found at {js_path}")
        raise HTTPException(status_code=404, detail="webui.js not found")
    return FileResponse(js_path, media_type="application/javascript")

@app.get("/api/info")
async def get_api_info(request: Request):
    server_port = request.url.port
    if not server_port and hasattr(request.app.state, 'server_port'):
        server_port = request.app.state.server_port
    if not server_port:
        server_port = os.environ.get('SERVER_PORT_INFO', '8000')
    host = request.headers.get('host') or f"127.0.0.1:{server_port}"
    scheme = request.headers.get('x-forwarded-proto', 'http')
    base_url = f"{scheme}://{host}"
    api_base = f"{base_url}/v1"
    effective_model_name = current_ai_studio_model_id if current_ai_studio_model_id else MODEL_NAME
    return JSONResponse(content={
        "model_name": effective_model_name,
        "api_base_url": api_base,
        "server_base_url": base_url,
        "api_key_required": False,
        "message": "API Key is not required."
    })

@app.get("/health")
async def health_check():
    is_worker_running = bool(worker_task and not worker_task.done())
    launch_mode = os.environ.get('LAUNCH_MODE', 'unknown')
    browser_page_critical = launch_mode != "direct_debug_no_browser"
    core_ready_conditions = [not is_initializing, is_playwright_ready]
    if browser_page_critical:
        core_ready_conditions.extend([is_browser_connected, is_page_ready])
    is_core_ready = all(core_ready_conditions)
    status_val = "OK" if is_core_ready and is_worker_running else "Error"
    q_size = request_queue.qsize() if request_queue else -1
    status_message_parts = []
    if is_initializing: status_message_parts.append("ÂàùÂßãÂåñËøõË°å‰∏≠")
    if not is_playwright_ready: status_message_parts.append("Playwright Êú™Â∞±Áª™")
    if browser_page_critical:
        if not is_browser_connected: status_message_parts.append("ÊµèËßàÂô®Êú™ËøûÊé•")
        if not is_page_ready: status_message_parts.append("È°µÈù¢Êú™Â∞±Áª™")
    if not is_worker_running: status_message_parts.append("Worker Êú™ËøêË°å")
    status = {
        "status": status_val,
        "message": "",
        "details": {
            "playwrightReady": is_playwright_ready,
            "browserConnected": is_browser_connected,
            "pageReady": is_page_ready,
            "initializing": is_initializing,
            "workerRunning": is_worker_running,
            "queueLength": q_size,
            "launchMode": launch_mode,
            "browserAndPageCritical": browser_page_critical
        }
    }
    if status_val == "OK":
        status["message"] = f"ÊúçÂä°ËøêË°å‰∏≠;ÈòüÂàóÈïøÂ∫¶: {q_size}„ÄÇ"
        return JSONResponse(content=status, status_code=200)
    else:
        status["message"] = f"ÊúçÂä°‰∏çÂèØÁî®;ÈóÆÈ¢ò: {(', '.join(status_message_parts) if status_message_parts else 'Êú™Áü•ÂéüÂõ†')}. ÈòüÂàóÈïøÂ∫¶: {q_size}."
        return JSONResponse(content=status, status_code=503)

@app.get("/v1/models")
async def list_models():
    logger.info("[API] Êî∂Âà∞ /v1/models ËØ∑Ê±Ç„ÄÇ")
    if not model_list_fetch_event.is_set() and page_instance and not page_instance.is_closed():
        logger.info("/v1/models: Ê®°ÂûãÂàóË°®‰∫ã‰ª∂Êú™ËÆæÁΩÆÊàñÂàóË°®‰∏∫Á©∫ÔºåÂ∞ùËØïÈ°µÈù¢Âà∑Êñ∞‰ª•Ëß¶ÂèëÊçïËé∑...")
        try:
            listener_attached = False
            if hasattr(page_instance, '_events') and "response" in page_instance._events:
                for handler_slot_or_func in page_instance._events["response"]:
                    actual_handler = getattr(handler_slot_or_func, 'handler', handler_slot_or_func)
                    if actual_handler == _handle_model_list_response:
                        listener_attached = True
                        break
            if not listener_attached:
                logger.info("/v1/models: ÂìçÂ∫îÁõëÂê¨Âô®‰ºº‰πé‰∏çÂ≠òÂú®ÊàñÂ∑≤Ë¢´ÁßªÈô§ÔºåÂ∞ùËØïÈáçÊñ∞Ê∑ªÂä†„ÄÇ")
                page_instance.on("response", _handle_model_list_response)
            await page_instance.reload(wait_until="domcontentloaded", timeout=20000)
            logger.info(f"È°µÈù¢Â∑≤Âà∑Êñ∞„ÄÇÁ≠âÂæÖÊ®°ÂûãÂàóË°®‰∫ã‰ª∂ (ÊúÄÂ§ö10Áßí)...")
            await asyncio.wait_for(model_list_fetch_event.wait(), timeout=10.0)
        except asyncio.TimeoutError:
            logger.warning("/v1/models: Âà∑Êñ∞ÂêéÁ≠âÂæÖÊ®°ÂûãÂàóË°®‰∫ã‰ª∂Ë∂ÖÊó∂„ÄÇ")
        except PlaywrightAsyncError as reload_err:
            logger.error(f"/v1/models: Âà∑Êñ∞È°µÈù¢Â§±Ë¥•: {reload_err}")
        except Exception as e:
            logger.error(f"/v1/models: Â∞ùËØïËß¶ÂèëÊ®°ÂûãÂàóË°®ÊçïËé∑Êó∂ÂèëÁîüÈîôËØØ: {e}")
        finally:
            if not model_list_fetch_event.is_set():
                logger.info("/v1/models: Â∞ùËØïÊçïËé∑ÂêéÔºåÂº∫Âà∂ËÆæÁΩÆÊ®°ÂûãÂàóË°®‰∫ã‰ª∂„ÄÇ")
                model_list_fetch_event.set()
    if parsed_model_list:
        final_model_list = [m for m in parsed_model_list if m.get("id") not in excluded_model_ids]
        logger.info(f"ËøîÂõûËøáÊª§ÂêéÁöÑ {len(final_model_list)} ‰∏™Ê®°Âûã (ÂéüÁºìÂ≠ò {len(parsed_model_list)} ‰∏™)„ÄÇÊéíÈô§ÁöÑÊúâ: {excluded_model_ids.intersection(set(m.get('id') for m in parsed_model_list))}")
        return {"object": "list", "data": final_model_list}
    else:
        logger.warning("Ê®°ÂûãÂàóË°®‰∏∫Á©∫ÊàñÊú™ÊàêÂäüËé∑Âèñ„ÄÇËøîÂõûÈªòËÆ§ÂêéÂ§áÊ®°Âûã„ÄÇ")
        fallback_model_obj = {
            "id": DEFAULT_FALLBACK_MODEL_ID,
            "object": "model",
            "created": int(time.time()),
            "owned_by": "camoufox-proxy-fallback",
            "display_name": DEFAULT_FALLBACK_MODEL_ID.replace("-", " ").title(),
            "description": "Default fallback model.",
            "raw_model_path": f"models/{DEFAULT_FALLBACK_MODEL_ID}"
        }
        return {"object": "list", "data": [fallback_model_obj]}

# --- Helper: Detect Error ---
async def detect_and_extract_page_error(page: AsyncPage, req_id: str) -> Optional[str]:
    error_toast_locator = page.locator(ERROR_TOAST_SELECTOR).last
    try:
        await error_toast_locator.wait_for(state='visible', timeout=500)
        message_locator = error_toast_locator.locator('span.content-text')
        error_message = await message_locator.text_content(timeout=500)
        if error_message:
             logger.error(f"[{req_id}]    Ê£ÄÊµãÂà∞Âπ∂ÊèêÂèñÈîôËØØÊ∂àÊÅØ: {error_message}")
             return error_message.strip()
        else:
             logger.warning(f"[{req_id}]    Ê£ÄÊµãÂà∞ÈîôËØØÊèêÁ§∫Ê°ÜÔºå‰ΩÜÊó†Ê≥ïÊèêÂèñÊ∂àÊÅØ„ÄÇ")
             return "Ê£ÄÊµãÂà∞ÈîôËØØÊèêÁ§∫Ê°ÜÔºå‰ΩÜÊó†Ê≥ïÊèêÂèñÁâπÂÆöÊ∂àÊÅØ„ÄÇ"
    except PlaywrightAsyncError: return None
    except Exception as e:
        logger.warning(f"[{req_id}]    Ê£ÄÊü•È°µÈù¢ÈîôËØØÊó∂Âá∫Èîô: {e}")
        return None

# --- Snapshot Helper ---
async def save_error_snapshot(error_name: str = 'error'):
    name_parts = error_name.split('_')
    req_id = name_parts[-1] if len(name_parts) > 1 and len(name_parts[-1]) == 7 else None
    base_error_name = error_name if not req_id else '_'.join(name_parts[:-1])
    log_prefix = f"[{req_id}]" if req_id else "[Êó†ËØ∑Ê±ÇID]"
    page_to_snapshot = page_instance
    if not browser_instance or not browser_instance.is_connected() or not page_to_snapshot or page_to_snapshot.is_closed():
        logger.warning(f"{log_prefix} Êó†Ê≥ï‰øùÂ≠òÂø´ÁÖß ({base_error_name})ÔºåÊµèËßàÂô®/È°µÈù¢‰∏çÂèØÁî®„ÄÇ")
        return
    logger.info(f"{log_prefix} Â∞ùËØï‰øùÂ≠òÈîôËØØÂø´ÁÖß ({base_error_name})...")
    timestamp = int(time.time() * 1000)
    error_dir = os.path.join(os.path.dirname(__file__), 'errors_py')
    try:
        os.makedirs(error_dir, exist_ok=True)
        filename_suffix = f"{req_id}_{timestamp}" if req_id else f"{timestamp}"
        filename_base = f"{base_error_name}_{filename_suffix}"
        screenshot_path = os.path.join(error_dir, f"{filename_base}.png")
        html_path = os.path.join(error_dir, f"{filename_base}.html")
        try:
            await page_to_snapshot.screenshot(path=screenshot_path, full_page=True, timeout=15000)
            logger.info(f"{log_prefix}   Âø´ÁÖßÂ∑≤‰øùÂ≠òÂà∞: {screenshot_path}")
        except Exception as ss_err:
            logger.error(f"{log_prefix}   ‰øùÂ≠òÂ±èÂπïÊà™ÂõæÂ§±Ë¥• ({base_error_name}): {ss_err}")
        try:
            content = await page_to_snapshot.content()
            f = None
            try:
                f = open(html_path, 'w', encoding='utf-8')
                f.write(content)
                logger.info(f"{log_prefix}   HTML Â∑≤‰øùÂ≠òÂà∞: {html_path}")
            except Exception as write_err:
                logger.error(f"{log_prefix}   ‰øùÂ≠ò HTML Â§±Ë¥• ({base_error_name}): {write_err}")
            finally:
                if f:
                    try:
                        f.close()
                        logger.debug(f"{log_prefix}   HTML Êñá‰ª∂Â∑≤Ê≠£Á°ÆÂÖ≥Èó≠")
                    except Exception as close_err:
                        logger.error(f"{log_prefix}   ÂÖ≥Èó≠ HTML Êñá‰ª∂Êó∂Âá∫Èîô: {close_err}")
        except Exception as html_err:
            logger.error(f"{log_prefix}   Ëé∑ÂèñÈ°µÈù¢ÂÜÖÂÆπÂ§±Ë¥• ({base_error_name}): {html_err}")
    except Exception as dir_err:
        logger.error(f"{log_prefix}   ÂàõÂª∫ÈîôËØØÁõÆÂΩïÊàñ‰øùÂ≠òÂø´ÁÖßÊó∂ÂèëÁîüÂÖ∂‰ªñÈîôËØØ ({base_error_name}): {dir_err}")

# --- Get response via Edit Button ---
async def get_response_via_edit_button(
    page: AsyncPage,
    req_id: str,
    check_client_disconnected: Callable
) -> Optional[str]:
    logger.info(f"[{req_id}] (Helper) Â∞ùËØïÈÄöËøáÁºñËæëÊåâÈíÆËé∑ÂèñÂìçÂ∫î...")
    last_message_container = page.locator('ms-chat-turn').last
    edit_button = last_message_container.get_by_label("Edit")
    finish_edit_button = last_message_container.get_by_label("Stop editing")
    autosize_textarea_locator = last_message_container.locator('ms-autosize-textarea')
    actual_textarea_locator = autosize_textarea_locator.locator('textarea')
    try:
        logger.info(f"[{req_id}]   - Â∞ùËØïÊÇ¨ÂÅúÊúÄÂêé‰∏ÄÊù°Ê∂àÊÅØ‰ª•ÊòæÁ§∫ 'Edit' ÊåâÈíÆ...")
        try:
            # ÂØπÊ∂àÊÅØÂÆπÂô®ÊâßË°åÊÇ¨ÂÅúÊìç‰Ωú
            await last_message_container.hover(timeout=CLICK_TIMEOUT_MS / 2) # ‰ΩøÁî®‰∏ÄÂçäÁöÑÁÇπÂáªË∂ÖÊó∂‰Ωú‰∏∫ÊÇ¨ÂÅúË∂ÖÊó∂
            await asyncio.sleep(0.3) # Á≠âÂæÖÊÇ¨ÂÅúÊïàÊûúÁîüÊïà
            check_client_disconnected("ÁºñËæëÂìçÂ∫î - ÊÇ¨ÂÅúÂêé: ")
        except Exception as hover_err:
            logger.warning(f"[{req_id}]   - (get_response_via_edit_button) ÊÇ¨ÂÅúÊúÄÂêé‰∏ÄÊù°Ê∂àÊÅØÂ§±Ë¥• (ÂøΩÁï•): {type(hover_err).__name__}")
            # Âç≥‰ΩøÊÇ¨ÂÅúÂ§±Ë¥•Ôºå‰πüÁªßÁª≠Â∞ùËØïÂêéÁª≠Êìç‰ΩúÔºåPlaywrightÁöÑexpect_asyncÂèØËÉΩ‰ºöÂ§ÑÁêÜ
        
        logger.info(f"[{req_id}]   - ÂÆö‰ΩçÂπ∂ÁÇπÂáª 'Edit' ÊåâÈíÆ...")
        try:
            await expect_async(edit_button).to_be_visible(timeout=CLICK_TIMEOUT_MS)
            check_client_disconnected("ÁºñËæëÂìçÂ∫î - 'Edit' ÊåâÈíÆÂèØËßÅÂêé: ")
            await edit_button.click(timeout=CLICK_TIMEOUT_MS)
            logger.info(f"[{req_id}]   - 'Edit' ÊåâÈíÆÂ∑≤ÁÇπÂáª„ÄÇ")
        except Exception as edit_btn_err:
            logger.error(f"[{req_id}]   - 'Edit' ÊåâÈíÆ‰∏çÂèØËßÅÊàñÁÇπÂáªÂ§±Ë¥•: {edit_btn_err}")
            await save_error_snapshot(f"edit_response_edit_button_failed_{req_id}")
            return None
        check_client_disconnected("ÁºñËæëÂìçÂ∫î - ÁÇπÂáª 'Edit' ÊåâÈíÆÂêé: ")
        await asyncio.sleep(0.3)
        check_client_disconnected("ÁºñËæëÂìçÂ∫î - ÁÇπÂáª 'Edit' ÊåâÈíÆÂêéÂª∂Êó∂Âêé: ")
        logger.info(f"[{req_id}]   - ‰ªéÊñáÊú¨Âå∫ÂüüËé∑ÂèñÂÜÖÂÆπ...")
        response_content = None
        textarea_failed = False
        try:
            await expect_async(autosize_textarea_locator).to_be_visible(timeout=CLICK_TIMEOUT_MS)
            check_client_disconnected("ÁºñËæëÂìçÂ∫î - autosize-textarea ÂèØËßÅÂêé: ")
            try:
                data_value_content = await autosize_textarea_locator.get_attribute("data-value")
                check_client_disconnected("ÁºñËæëÂìçÂ∫î - get_attribute data-value Âêé: ")
                if data_value_content is not None:
                    response_content = str(data_value_content)
                    logger.info(f"[{req_id}]   - ‰ªé data-value Ëé∑ÂèñÂÜÖÂÆπÊàêÂäü„ÄÇ")
            except Exception as data_val_err:
                logger.warning(f"[{req_id}]   - Ëé∑Âèñ data-value Â§±Ë¥•: {data_val_err}")
                check_client_disconnected("ÁºñËæëÂìçÂ∫î - get_attribute data-value ÈîôËØØÂêé: ")
            if response_content is None:
                logger.info(f"[{req_id}]   - data-value Ëé∑ÂèñÂ§±Ë¥•Êàñ‰∏∫NoneÔºåÂ∞ùËØï‰ªéÂÜÖÈÉ® textarea Ëé∑Âèñ input_value...")
                try:
                    await expect_async(actual_textarea_locator).to_be_visible(timeout=CLICK_TIMEOUT_MS/2)
                    input_val_content = await actual_textarea_locator.input_value(timeout=CLICK_TIMEOUT_MS/2)
                    check_client_disconnected("ÁºñËæëÂìçÂ∫î - input_value Âêé: ")
                    if input_val_content is not None:
                        response_content = str(input_val_content)
                        logger.info(f"[{req_id}]   - ‰ªé input_value Ëé∑ÂèñÂÜÖÂÆπÊàêÂäü„ÄÇ")
                except Exception as input_val_err:
                     logger.warning(f"[{req_id}]   - Ëé∑Âèñ input_value ‰πüÂ§±Ë¥•: {input_val_err}")
                     check_client_disconnected("ÁºñËæëÂìçÂ∫î - input_value ÈîôËØØÂêé: ")
            if response_content is not None:
                response_content = response_content.strip()
                content_preview = response_content[:100].replace('\\n', '\\\\n')
                logger.info(f"[{req_id}]   - ‚úÖ ÊúÄÁªàËé∑ÂèñÂÜÖÂÆπ (ÈïøÂ∫¶={len(response_content)}): '{content_preview}...'")
            else:
                logger.warning(f"[{req_id}]   - ÊâÄÊúâÊñπÊ≥ï (data-value, input_value) ÂÜÖÂÆπËé∑ÂèñÂùáÂ§±Ë¥•ÊàñËøîÂõû None„ÄÇ")
                textarea_failed = True
        except Exception as textarea_err:
            logger.error(f"[{req_id}]   - ÂÆö‰ΩçÊàñÂ§ÑÁêÜÊñáÊú¨Âå∫ÂüüÊó∂Â§±Ë¥•: {textarea_err}")
            textarea_failed = True
            response_content = None
            check_client_disconnected("ÁºñËæëÂìçÂ∫î - Ëé∑ÂèñÊñáÊú¨Âå∫ÂüüÈîôËØØÂêé: ")
        if not textarea_failed:
            logger.info(f"[{req_id}]   - ÂÆö‰ΩçÂπ∂ÁÇπÂáª 'Stop editing' ÊåâÈíÆ...")
            try:
                await expect_async(finish_edit_button).to_be_visible(timeout=CLICK_TIMEOUT_MS)
                check_client_disconnected("ÁºñËæëÂìçÂ∫î - 'Stop editing' ÊåâÈíÆÂèØËßÅÂêé: ")
                await finish_edit_button.click(timeout=CLICK_TIMEOUT_MS)
                logger.info(f"[{req_id}]   - 'Stop editing' ÊåâÈíÆÂ∑≤ÁÇπÂáª„ÄÇ")
            except Exception as finish_btn_err:
                logger.warning(f"[{req_id}]   - 'Stop editing' ÊåâÈíÆ‰∏çÂèØËßÅÊàñÁÇπÂáªÂ§±Ë¥•: {finish_btn_err}")
                await save_error_snapshot(f"edit_response_finish_button_failed_{req_id}")
            check_client_disconnected("ÁºñËæëÂìçÂ∫î - ÁÇπÂáª 'Stop editing' Âêé: ")
            await asyncio.sleep(0.2)
            check_client_disconnected("ÁºñËæëÂìçÂ∫î - ÁÇπÂáª 'Stop editing' ÂêéÂª∂Êó∂Âêé: ")
        else:
             logger.info(f"[{req_id}]   - Ë∑≥ËøáÁÇπÂáª 'Stop editing' ÊåâÈíÆÔºåÂõ†‰∏∫ÊñáÊú¨Âå∫ÂüüËØªÂèñÂ§±Ë¥•„ÄÇ")
        return response_content
    except ClientDisconnectedError:
        logger.info(f"[{req_id}] (Helper Edit) ÂÆ¢Êà∑Á´ØÊñ≠ÂºÄËøûÊé•„ÄÇ")
        raise
    except Exception as e:
        logger.exception(f"[{req_id}] ÈÄöËøáÁºñËæëÊåâÈíÆËé∑ÂèñÂìçÂ∫îËøáÁ®ã‰∏≠ÂèëÁîüÊÑèÂ§ñÈîôËØØ")
        await save_error_snapshot(f"edit_response_unexpected_error_{req_id}")
        return None

# --- Get response via Copy Button ---
async def get_response_via_copy_button(
    page: AsyncPage,
    req_id: str,
    check_client_disconnected: Callable
) -> Optional[str]:
    logger.info(f"[{req_id}] (Helper) Â∞ùËØïÈÄöËøáÂ§çÂà∂ÊåâÈíÆËé∑ÂèñÂìçÂ∫î...")
    last_message_container = page.locator('ms-chat-turn').last
    more_options_button = last_message_container.get_by_label("Open options")
    copy_markdown_button = page.get_by_role("menuitem", name="Copy markdown")
    try:
        logger.info(f"[{req_id}]   - Â∞ùËØïÊÇ¨ÂÅúÊúÄÂêé‰∏ÄÊù°Ê∂àÊÅØ‰ª•ÊòæÁ§∫ÈÄâÈ°π...")
        await last_message_container.hover(timeout=CLICK_TIMEOUT_MS)
        check_client_disconnected("Â§çÂà∂ÂìçÂ∫î - ÊÇ¨ÂÅúÂêé: ")
        await asyncio.sleep(0.5)
        check_client_disconnected("Â§çÂà∂ÂìçÂ∫î - ÊÇ¨ÂÅúÂêéÂª∂Êó∂Âêé: ")
        logger.info(f"[{req_id}]   - Â∑≤ÊÇ¨ÂÅú„ÄÇ")
        logger.info(f"[{req_id}]   - ÂÆö‰ΩçÂπ∂ÁÇπÂáª 'Êõ¥Â§öÈÄâÈ°π' ÊåâÈíÆ...")
        try:
            await expect_async(more_options_button).to_be_visible(timeout=CLICK_TIMEOUT_MS)
            check_client_disconnected("Â§çÂà∂ÂìçÂ∫î - Êõ¥Â§öÈÄâÈ°πÊåâÈíÆÂèØËßÅÂêé: ")
            await more_options_button.click(timeout=CLICK_TIMEOUT_MS)
            logger.info(f"[{req_id}]   - 'Êõ¥Â§öÈÄâÈ°π' Â∑≤ÁÇπÂáª (ÈÄöËøá get_by_label)„ÄÇ")
        except Exception as more_opts_err:
            logger.error(f"[{req_id}]   - 'Êõ¥Â§öÈÄâÈ°π' ÊåâÈíÆ (ÈÄöËøá get_by_label) ‰∏çÂèØËßÅÊàñÁÇπÂáªÂ§±Ë¥•: {more_opts_err}")
            await save_error_snapshot(f"copy_response_more_options_failed_{req_id}")
            return None
        check_client_disconnected("Â§çÂà∂ÂìçÂ∫î - ÁÇπÂáªÊõ¥Â§öÈÄâÈ°πÂêé: ")
        await asyncio.sleep(0.5)
        check_client_disconnected("Â§çÂà∂ÂìçÂ∫î - ÁÇπÂáªÊõ¥Â§öÈÄâÈ°πÂêéÂª∂Êó∂Âêé: ")
        logger.info(f"[{req_id}]   - ÂÆö‰ΩçÂπ∂ÁÇπÂáª 'Â§çÂà∂ Markdown' ÊåâÈíÆ...")
        copy_success = False
        try:
            await expect_async(copy_markdown_button).to_be_visible(timeout=CLICK_TIMEOUT_MS)
            check_client_disconnected("Â§çÂà∂ÂìçÂ∫î - Â§çÂà∂ÊåâÈíÆÂèØËßÅÂêé: ")
            await copy_markdown_button.click(timeout=CLICK_TIMEOUT_MS, force=True)
            copy_success = True
            logger.info(f"[{req_id}]   - Â∑≤ÁÇπÂáª 'Â§çÂà∂ Markdown' (ÈÄöËøá get_by_role)„ÄÇ")
        except Exception as copy_err:
            logger.error(f"[{req_id}]   - 'Â§çÂà∂ Markdown' ÊåâÈíÆ (ÈÄöËøá get_by_role) ÁÇπÂáªÂ§±Ë¥•: {copy_err}")
            await save_error_snapshot(f"copy_response_copy_button_failed_{req_id}")
            return None
        if not copy_success:
             logger.error(f"[{req_id}]   - Êú™ËÉΩÁÇπÂáª 'Â§çÂà∂ Markdown' ÊåâÈíÆ„ÄÇ")
             return None
        check_client_disconnected("Â§çÂà∂ÂìçÂ∫î - ÁÇπÂáªÂ§çÂà∂ÊåâÈíÆÂêé: ")
        await asyncio.sleep(0.5)
        check_client_disconnected("Â§çÂà∂ÂìçÂ∫î - ÁÇπÂáªÂ§çÂà∂ÊåâÈíÆÂêéÂª∂Êó∂Âêé: ")
        logger.info(f"[{req_id}]   - Ê≠£Âú®ËØªÂèñÂâ™Ë¥¥ÊùøÂÜÖÂÆπ...")
        try:
            clipboard_content = await page.evaluate('navigator.clipboard.readText()')
            check_client_disconnected("Â§çÂà∂ÂìçÂ∫î - ËØªÂèñÂâ™Ë¥¥ÊùøÂêé: ")
            if clipboard_content:
                content_preview = clipboard_content[:100].replace('\n', '\\\\n')
                logger.info(f"[{req_id}]   - ‚úÖ ÊàêÂäüËé∑ÂèñÂâ™Ë¥¥ÊùøÂÜÖÂÆπ (ÈïøÂ∫¶={len(clipboard_content)}): '{content_preview}...'")
                return clipboard_content
            else:
                logger.error(f"[{req_id}]   - Ââ™Ë¥¥ÊùøÂÜÖÂÆπ‰∏∫Á©∫„ÄÇ")
                return None
        except Exception as clipboard_err:
            if "clipboard-read" in str(clipboard_err):
                 logger.error(f"[{req_id}]   - ËØªÂèñÂâ™Ë¥¥ÊùøÂ§±Ë¥•: ÂèØËÉΩÊòØÊùÉÈôêÈóÆÈ¢ò„ÄÇÈîôËØØ: {clipboard_err}")
            else:
                 logger.error(f"[{req_id}]   - ËØªÂèñÂâ™Ë¥¥ÊùøÂ§±Ë¥•: {clipboard_err}")
            await save_error_snapshot(f"copy_response_clipboard_read_failed_{req_id}")
            return None
    except ClientDisconnectedError:
        logger.info(f"[{req_id}] (Helper Copy) ÂÆ¢Êà∑Á´ØÊñ≠ÂºÄËøûÊé•„ÄÇ")
        raise
    except Exception as e:
        logger.exception(f"[{req_id}] Â§çÂà∂ÂìçÂ∫îËøáÁ®ã‰∏≠ÂèëÁîüÊÑèÂ§ñÈîôËØØ")
        await save_error_snapshot(f"copy_response_unexpected_error_{req_id}")
        return None

# --- Wait for Response Completion ---
async def _wait_for_response_completion(
    page: AsyncPage,
    req_id: str,
    response_element: Locator,
    interruptible_wait_for: Callable,
    check_client_disconnected: Callable,
    interruptible_sleep: Callable
) -> bool:
    logger.info(f"[{req_id}] (Helper Wait) ÂºÄÂßãÁ≠âÂæÖÂìçÂ∫îÂÆåÊàê... (Ë∂ÖÊó∂: {RESPONSE_COMPLETION_TIMEOUT}ms)")
    start_time_ns = time.time()
    # spinner_locator = page.locator(LOADING_SPINNER_SELECTOR) # SPINNER REMOVED
    input_field = page.locator(INPUT_SELECTOR)
    input_field2 = page.locator(INPUT_SELECTOR2)
    submit_button = page.locator(SUBMIT_BUTTON_SELECTOR)
    edit_button = page.locator(EDIT_MESSAGE_BUTTON_SELECTOR)
    while time.time() - start_time_ns < RESPONSE_COMPLETION_TIMEOUT / 1000:
        check_client_disconnected("Á≠âÂæÖÂÆåÊàêÂæ™ÁéØÂºÄÂßã: ")

        # observed_spinner_hidden = False # SPINNER REMOVED
        observed_input_empty = False
        observed_button_disabled = False
        current_state_check_error = None

        try:

            # 2. Ê£ÄÊü•ËæìÂÖ•Ê°ÜÊòØÂê¶‰∏∫Á©∫
            try:
                autosize_wrapper_locator = page.locator('ms-prompt-input-wrapper ms-autosize-textarea')
                current_data_value = await autosize_wrapper_locator.get_attribute("data-value", timeout=FINAL_STATE_CHECK_TIMEOUT_MS)
                # Êó†ËÆ∫È°µÈù¢URLÂ¶Ç‰ΩïÔºåÂè™Ë¶ÅËæìÂÖ•Ê°ÜÁöÑ data-value ÊòØÁ©∫Â≠óÁ¨¶‰∏≤ ""
                # ÊàñËÄÖ "Start typing a prompt"ÔºåÈÉΩËßÜ‰∏∫Á©∫ÔºàÂç≥Â∑≤Ê∏ÖÁ©∫Ôºâ„ÄÇ
                if current_data_value == "" or current_data_value == "Start typing a prompt":
                     observed_input_empty = True
                else:
                     observed_input_empty = False
                     current_state_check_error = current_state_check_error or AssertionError(f"Input data-value ('{current_data_value}') not an expected empty state.")
            except (PlaywrightAsyncError, asyncio.TimeoutError, AssertionError) as e:
                  observed_input_empty = False
                  current_state_check_error = current_state_check_error or e
            check_client_disconnected("Á≠âÂæÖÂÆåÊàê - ËæìÂÖ•Ê°ÜÊ£ÄÊü•Âêé: ")

            # 3. Ê£ÄÊü•Êèê‰∫§ÊåâÈíÆÊòØÂê¶Á¶ÅÁî®
            try:
                 await expect_async(submit_button).to_be_disabled(timeout=FINAL_STATE_CHECK_TIMEOUT_MS)
                 observed_button_disabled = True
            except (PlaywrightAsyncError, asyncio.TimeoutError, AssertionError) as e:
                 observed_button_disabled = False
                 current_state_check_error = current_state_check_error or e
            check_client_disconnected("Á≠âÂæÖÂÆåÊàê - Êèê‰∫§ÊåâÈíÆÊ£ÄÊü•Âêé: ")

        except ClientDisconnectedError: raise
        except Exception as unexpected_state_err:
             logger.exception(f"[{req_id}] (Helper Wait) Áä∂ÊÄÅÊ£ÄÊü•‰∏≠ÂèëÁîüÊÑèÂ§ñÈîôËØØ")
             await save_error_snapshot(f"wait_completion_state_check_unexpected_{req_id}")
             await asyncio.sleep(POLLING_INTERVAL_STREAM / 1000)
             continue

        # ‰∏ªË¶ÅÂÆåÊàêÊù°‰ª∂ÔºöËæìÂÖ•Ê°ÜÁ©∫ ‰∏î ÊåâÈíÆÁ¶ÅÁî®
        if observed_input_empty and observed_button_disabled:
            logger.info(f"[{req_id}] (Helper Wait) Ê£ÄÊµãÂà∞‰∏ªË¶ÅÂÆåÊàêÁä∂ÊÄÅ (ËæìÂÖ•Ê°ÜÁ©∫ & ÊåâÈíÆÁ¶ÅÁî®)„ÄÇÂºÄÂßãÊ£ÄÊü•ÁºñËæëÊåâÈíÆ...")
            
            # if observed_spinner_hidden: # Â¶ÇÊûú spinner Á°ÆÂÆûÈöêËóè‰∫ÜÔºåÂèØ‰ª•‰øùÁïôËøô‰∏™Âª∂Ëøü # SPINNER REMOVED
            #     await asyncio.sleep(POST_SPINNER_CHECK_DELAY_MS / 1000) # SPINNER REMOVED
            #     check_client_disconnected("Á≠âÂæÖÂÆåÊàê - SpinnerÊ∂àÂ§±‰∏î‰∏ªË¶ÅÊù°‰ª∂Êª°Ë∂≥ÂêéÂª∂Êó∂Âêé: ") # SPINNER REMOVED

            edit_button_check_start = time.time()
            edit_button_visible = False
            # ÁßªÈô§ last_focus_attempt_time ÂíåÁõ∏ÂÖ≥ÈÄªËæë
            while time.time() - edit_button_check_start < SILENCE_TIMEOUT_MS / 1000:
                check_client_disconnected("Á≠âÂæÖÂÆåÊàê - ÁºñËæëÊåâÈíÆÊ£ÄÊü•Âæ™ÁéØ: ")
                
                # Âú®Ê£ÄÊü•ÂèØËßÅÊÄß‰πãÂâçÔºåÂ∞ùËØïÊÇ¨ÂÅúÂú®ÊúÄÂêé‰∏ÄÊù°Ê∂àÊÅØ‰∏ä‰ª•Ëß¶ÂèëÊåâÈíÆÊòæÁ§∫
                last_message_turn = page.locator('ms-chat-turn').last
                try:
                    if DEBUG_LOGS_ENABLED:
                        logger.debug(f"[{req_id}] (Helper Wait)   - Â∞ùËØïÊÇ¨ÂÅúÂú®ÊúÄÂêé‰∏ÄÊù°Ê∂àÊÅØ‰∏ä...")
                    await last_message_turn.hover(timeout=1000) # Â¢ûÂä†ÊÇ¨ÂÅúÊìç‰Ωú
                    await asyncio.sleep(0.2) # Áü≠ÊöÇÁ≠âÂæÖÊÇ¨ÂÅúÊïàÊûúÁîüÊïà
                except (PlaywrightAsyncError, asyncio.TimeoutError) as hover_err:
                    if DEBUG_LOGS_ENABLED:
                        logger.debug(f"[{req_id}] (Helper Wait)   - ÊÇ¨ÂÅúÊúÄÂêé‰∏ÄÊù°Ê∂àÊÅØÂ§±Ë¥• (ÂøΩÁï•): {type(hover_err).__name__}")
                except ClientDisconnectedError: raise
                except Exception as unexpected_hover_err:
                    logger.warning(f"[{req_id}] (Helper Wait)   - ÊÇ¨ÂÅúÊúÄÂêé‰∏ÄÊù°Ê∂àÊÅØÊó∂ÂèëÁîüÊÑèÂ§ñÈîôËØØ (ÂøΩÁï•): {unexpected_hover_err}")
                check_client_disconnected("Á≠âÂæÖÂÆåÊàê - ÁºñËæëÊåâÈíÆÂæ™ÁéØÊÇ¨ÂÅúÂêé: ")

                try:
                    is_visible = False
                    try:
                        is_visible = await edit_button.is_visible(timeout=500)
                    except asyncio.TimeoutError:
                        is_visible = False
                    except PlaywrightAsyncError as pw_vis_err:
                        logger.warning(f"[{req_id}] (Helper Wait)   - is_visible Ê£ÄÊü•PlaywrightÈîôËØØ(ÂøΩÁï•): {pw_vis_err}")
                        is_visible = False
                    check_client_disconnected("Á≠âÂæÖÂÆåÊàê - ÁºñËæëÊåâÈíÆ is_visible Ê£ÄÊü•Âêé: ")
                    if is_visible:
                        logger.info(f"[{req_id}] (Helper Wait) ‚úÖ ÁºñËæëÊåâÈíÆÂ∑≤Âá∫Áé∞ (is_visible)ÔºåÁ°ÆËÆ§ÂìçÂ∫îÂÆåÊàê„ÄÇ")
                        edit_button_visible = True
                        return True # ÂìçÂ∫îÂÆåÊàê
                    else:
                          if DEBUG_LOGS_ENABLED and (time.time() - edit_button_check_start) > 1.0:
                               logger.debug(f"[{req_id}] (Helper Wait)   - ÁºñËæëÊåâÈíÆÂ∞ö‰∏çÂèØËßÅ... (is_visible returned False or timed out)")
                except ClientDisconnectedError: raise
                except Exception as unexpected_btn_err:
                     logger.warning(f"[{req_id}] (Helper Wait)   - Ê£ÄÊü•ÁºñËæëÊåâÈíÆÊó∂ÊÑèÂ§ñÈîôËØØ: {unexpected_btn_err}")
                await asyncio.sleep(POLLING_INTERVAL_STREAM / 1000)
            
            if not edit_button_visible:
                logger.warning(f"[{req_id}] (Helper Wait) ‰∏ªË¶ÅÂÆåÊàêÁä∂ÊÄÅÊª°Ë∂≥ÂêéÔºåÁºñËæëÊåâÈíÆÊú™Âú® {SILENCE_TIMEOUT_MS}ms ÂÜÖÂá∫Áé∞„ÄÇÂà§ÂÆö‰∏∫Ë∂ÖÊó∂„ÄÇ")
                await save_error_snapshot(f"wait_completion_edit_button_timeout_after_primary_{req_id}")
                return False # ÁâπÂÆöË∂ÖÊó∂Ôºå‰ΩÜÊØîÊï¥‰ΩìË∂ÖÊó∂Âø´
        else: # ‰∏ªË¶ÅÊù°‰ª∂ (ËæìÂÖ•Ê°ÜÁ©∫ÂíåÊåâÈíÆÁ¶ÅÁî®) Êú™Êª°Ë∂≥
            if DEBUG_LOGS_ENABLED:
                reasons = []
                if not observed_input_empty: reasons.append("Input not empty")
                if not observed_button_disabled: reasons.append("Button not disabled")
                # Spinner Áä∂ÊÄÅÂú®ËøôÈáå‰ªÖ‰æõÂèÇËÄÉ
                error_info = f" (Last Check Error in iter: {type(current_state_check_error).__name__})" if current_state_check_error else ""
                logger.debug(f"[{req_id}] (Helper Wait) ‰∏ªË¶ÅÂÆåÊàêÁä∂ÊÄÅÊú™Êª°Ë∂≥ ({', '.join(reasons)}{error_info}). ÁªßÁª≠ËΩÆËØ¢...")
            await asyncio.sleep(POLLING_INTERVAL_STREAM / 1000)
            continue # ÁªßÁª≠ËΩÆËØ¢

    logger.error(f"[{req_id}] (Helper Wait) Á≠âÂæÖÂìçÂ∫îÂÆåÊàêË∂ÖÊó∂ ({RESPONSE_COMPLETION_TIMEOUT}ms)„ÄÇ")
    await save_error_snapshot(f"wait_completion_overall_timeout_{req_id}")
    return False

# --- Get Final Response Content ---
async def _get_final_response_content(
    page: AsyncPage,
    req_id: str,
    check_client_disconnected: Callable
) -> Optional[str]:
    logger.info(f"[{req_id}] (Helper GetContent) ÂºÄÂßãËé∑ÂèñÊúÄÁªàÂìçÂ∫îÂÜÖÂÆπ...")
    response_content = await get_response_via_edit_button(
        page, req_id, check_client_disconnected
    )
    if response_content is not None:
        logger.info(f"[{req_id}] (Helper GetContent) ‚úÖ ÊàêÂäüÈÄöËøáÁºñËæëÊåâÈíÆËé∑ÂèñÂÜÖÂÆπ„ÄÇ")
        return response_content
    logger.warning(f"[{req_id}] (Helper GetContent) ÁºñËæëÊåâÈíÆÊñπÊ≥ïÂ§±Ë¥•ÊàñËøîÂõûÁ©∫ÔºåÂõûÈÄÄÂà∞Â§çÂà∂ÊåâÈíÆÊñπÊ≥ï...")
    response_content = await get_response_via_copy_button(
        page, req_id, check_client_disconnected
    )
    if response_content is not None:
        logger.info(f"[{req_id}] (Helper GetContent) ‚úÖ ÊàêÂäüÈÄöËøáÂ§çÂà∂ÊåâÈíÆËé∑ÂèñÂÜÖÂÆπ„ÄÇ")
        return response_content
    logger.error(f"[{req_id}] (Helper GetContent) ÊâÄÊúâËé∑ÂèñÂìçÂ∫îÂÜÖÂÆπÁöÑÊñπÊ≥ïÂùáÂ§±Ë¥•„ÄÇ")
    await save_error_snapshot(f"get_content_all_methods_failed_{req_id}")
    return None

# --- Queue Worker ---
async def queue_worker():
    logger.info("--- ÈòüÂàó Worker Â∑≤ÂêØÂä® ---")
    was_last_request_streaming = False
    last_request_completion_time = 0
    while True:
        request_item = None; result_future = None; req_id = "UNKNOWN"; completion_event = None
        try:
            queue_size = request_queue.qsize()
            if queue_size > 0:
                checked_count = 0
                items_to_requeue = []
                processed_ids = set()
                while checked_count < queue_size and checked_count < 10:
                    try:
                        item = request_queue.get_nowait()
                        item_req_id = item.get("req_id", "unknown")
                        if item_req_id in processed_ids:
                             items_to_requeue.append(item)
                             continue
                        processed_ids.add(item_req_id)
                        if not item.get("cancelled", False):
                            item_http_request = item.get("http_request")
                            if item_http_request:
                                try:
                                    if await item_http_request.is_disconnected():
                                        logger.info(f"[{item_req_id}] (Worker Queue Check) Ê£ÄÊµãÂà∞ÂÆ¢Êà∑Á´ØÂ∑≤Êñ≠ÂºÄÔºåÊ†áËÆ∞‰∏∫ÂèñÊ∂à„ÄÇ")
                                        item["cancelled"] = True
                                        item_future = item.get("result_future")
                                        if item_future and not item_future.done():
                                            item_future.set_exception(HTTPException(status_code=499, detail=f"[{item_req_id}] Client disconnected while queued."))
                                except Exception as check_err:
                                    logger.error(f"[{item_req_id}] (Worker Queue Check) Error checking disconnect: {check_err}")
                        items_to_requeue.append(item)
                        checked_count += 1
                    except asyncio.QueueEmpty:
                        break
                for item in items_to_requeue:
                    await request_queue.put(item)
            request_item = await request_queue.get()
            req_id = request_item["req_id"]
            request_data = request_item["request_data"]
            http_request = request_item["http_request"]
            result_future = request_item["result_future"]
            if request_item.get("cancelled", False):
                logger.info(f"[{req_id}] (Worker) ËØ∑Ê±ÇÂ∑≤ÂèñÊ∂àÔºåË∑≥Ëøá„ÄÇ")
                if not result_future.done(): result_future.set_exception(HTTPException(status_code=499, detail=f"[{req_id}] ËØ∑Ê±ÇÂ∑≤Ë¢´Áî®Êà∑ÂèñÊ∂à"))
                request_queue.task_done(); continue
            is_streaming_request = request_data.stream
            logger.info(f"[{req_id}] (Worker) ÂèñÂá∫ËØ∑Ê±Ç„ÄÇÊ®°Âºè: {'ÊµÅÂºè' if is_streaming_request else 'ÈùûÊµÅÂºè'}")
            current_time = time.time()
            if was_last_request_streaming and is_streaming_request and (current_time - last_request_completion_time < 1.0):
                delay_time = max(0.5, 1.0 - (current_time - last_request_completion_time))
                logger.info(f"[{req_id}] (Worker) ËøûÁª≠ÊµÅÂºèËØ∑Ê±ÇÔºåÊ∑ªÂä† {delay_time:.2f}s Âª∂Ëøü...")
                await asyncio.sleep(delay_time)
            if await http_request.is_disconnected():
                 logger.info(f"[{req_id}] (Worker) ÂÆ¢Êà∑Á´ØÂú®Á≠âÂæÖÈîÅÊó∂Êñ≠ÂºÄ„ÄÇÂèñÊ∂à„ÄÇ")
                 if not result_future.done(): result_future.set_exception(HTTPException(status_code=499, detail=f"[{req_id}] ÂÆ¢Êà∑Á´ØÂÖ≥Èó≠‰∫ÜËØ∑Ê±Ç"))
                 request_queue.task_done(); continue
            logger.info(f"[{req_id}] (Worker) Á≠âÂæÖÂ§ÑÁêÜÈîÅ...")
            async with processing_lock:
                logger.info(f"[{req_id}] (Worker) Â∑≤Ëé∑ÂèñÂ§ÑÁêÜÈîÅ„ÄÇÂºÄÂßãÊ†∏ÂøÉÂ§ÑÁêÜ...")
                if await http_request.is_disconnected():
                     logger.info(f"[{req_id}] (Worker) ÂÆ¢Êà∑Á´ØÂú®Ëé∑ÂèñÈîÅÂêéÊñ≠ÂºÄ„ÄÇÂèñÊ∂à„ÄÇ")
                     if not result_future.done(): result_future.set_exception(HTTPException(status_code=499, detail=f"[{req_id}] ÂÆ¢Êà∑Á´ØÂÖ≥Èó≠‰∫ÜËØ∑Ê±Ç"))
                elif result_future.done():
                     logger.info(f"[{req_id}] (Worker) Future Âú®Â§ÑÁêÜÂâçÂ∑≤ÂÆåÊàê/ÂèñÊ∂à„ÄÇË∑≥Ëøá„ÄÇ")
                else:
                    completion_event = await _process_request_refactored(
                        req_id, request_data, http_request, result_future
                    )
                    if completion_event:
                         logger.info(f"[{req_id}] (Worker) Á≠âÂæÖÊµÅÂºèÁîüÊàêÂô®ÂÆåÊàê‰ø°Âè∑...")
                         try:
                              await asyncio.wait_for(completion_event.wait(), timeout=RESPONSE_COMPLETION_TIMEOUT/1000 + 60)
                              logger.info(f"[{req_id}] (Worker) ‚úÖ ÊµÅÂºèÁîüÊàêÂô®ÂÆåÊàê‰ø°Âè∑Êî∂Âà∞„ÄÇ")
                         except asyncio.TimeoutError:
                              logger.warning(f"[{req_id}] (Worker) ‚ö†Ô∏è Á≠âÂæÖÊµÅÂºèÁîüÊàêÂô®ÂÆåÊàê‰ø°Âè∑Ë∂ÖÊó∂„ÄÇ")
                              if not result_future.done(): result_future.set_exception(HTTPException(status_code=504, detail=f"[{req_id}] Stream generation timed out waiting for completion signal."))
                         except Exception as ev_wait_err:
                              logger.error(f"[{req_id}] (Worker) ‚ùå Á≠âÂæÖÊµÅÂºèÂÆåÊàê‰∫ã‰ª∂Êó∂Âá∫Èîô: {ev_wait_err}")
                              if not result_future.done(): result_future.set_exception(HTTPException(status_code=500, detail=f"[{req_id}] Error waiting for stream completion: {ev_wait_err}"))
            logger.info(f"[{req_id}] (Worker) ÈáäÊîæÂ§ÑÁêÜÈîÅ„ÄÇ")
            was_last_request_streaming = is_streaming_request
            last_request_completion_time = time.time()
        except asyncio.CancelledError:
            logger.info("--- ÈòüÂàó Worker Ë¢´ÂèñÊ∂à ---")
            if result_future and not result_future.done(): result_future.cancel("Worker cancelled")
            break
        except Exception as e:
            logger.error(f"[{req_id}] (Worker) ‚ùå Â§ÑÁêÜËØ∑Ê±ÇÊó∂ÂèëÁîüÊÑèÂ§ñÈîôËØØ: {e}", exc_info=True)
            if result_future and not result_future.done():
                result_future.set_exception(HTTPException(status_code=500, detail=f"[{req_id}] ÊúçÂä°Âô®ÂÜÖÈÉ®ÈîôËØØ: {e}"))
            await save_error_snapshot(f"worker_loop_error_{req_id}")
        finally:
             if request_item: request_queue.task_done()
    logger.info("--- ÈòüÂàó Worker Â∑≤ÂÅúÊ≠¢ ---")

# --- Helper function to use external helper service ---
async def use_helper_get_response(helper_endpoint, helper_sapisid) -> AsyncGenerator[str, None]:
    headers = {
        'Cookie': f'SAPISID={helper_sapisid}',
        'Accept': 'text/event-stream'
    }
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(helper_endpoint, headers=headers) as response:
                if response.status != 200:
                    logger.error(f"Helper Error: HTTP {response.status}")
                    yield "[ERROR]" # Indicate error to caller
                    return # Stop generation

                async for line in response.content:
                    decoded_line = line.decode('utf-8').strip()
                    if decoded_line and not decoded_line.startswith(':'):
                        if decoded_line.startswith('data:'):
                            data = decoded_line[5:].strip()
                            if data:
                                yield data
                        else: # Should not happen with SSE, but yield anyway
                            yield decoded_line
    except aiohttp.ClientError as e:
        logger.error(f"Error connecting to helper server: {e}")
        raise # Re-raise to be caught by caller
    except Exception as e:
        logger.error(f"Unexpected error in use_helper_get_response: {e}")
        raise # Re-raise

# --- Core Request Processing Logic ---
async def _process_request_refactored(
    req_id: str,
    request: ChatCompletionRequest,
    http_request: Request,
    result_future: Future
) -> Optional[Event]:
    model_actually_switched_in_current_api_call = False
    logger.info(f"[{req_id}] (Refactored Process) ÂºÄÂßãÂ§ÑÁêÜËØ∑Ê±Ç...")
    logger.info(f"[{req_id}]   ËØ∑Ê±ÇÂèÇÊï∞ - Model: {request.model}, Stream: {request.stream}")
    logger.info(f"[{req_id}]   ËØ∑Ê±ÇÂèÇÊï∞ - Temperature: {request.temperature}")
    logger.info(f"[{req_id}]   ËØ∑Ê±ÇÂèÇÊï∞ - Max Output Tokens: {request.max_output_tokens}")
    logger.info(f"[{req_id}]   ËØ∑Ê±ÇÂèÇÊï∞ - Stop Sequences: {request.stop}")
    logger.info(f"[{req_id}]   ËØ∑Ê±ÇÂèÇÊï∞ - Top P: {request.top_p}")
    is_streaming = request.stream
    page: Optional[AsyncPage] = page_instance
    completion_event: Optional[Event] = None
    requested_model = request.model
    model_id_to_use = None
    needs_model_switching = False
    if requested_model and requested_model != MODEL_NAME:
        requested_model_parts = requested_model.split('/')
        requested_model_id = requested_model_parts[-1] if len(requested_model_parts) > 1 else requested_model
        logger.info(f"[{req_id}] ËØ∑Ê±Ç‰ΩøÁî®Ê®°Âûã: {requested_model_id}")
        if parsed_model_list:
            valid_model_ids = [m.get("id") for m in parsed_model_list]
            if requested_model_id not in valid_model_ids:
                logger.error(f"[{req_id}] ‚ùå Êó†ÊïàÁöÑÊ®°ÂûãID: {requested_model_id}„ÄÇÂèØÁî®Ê®°Âûã: {valid_model_ids}")
                raise HTTPException(status_code=400, detail=f"[{req_id}] Invalid model '{requested_model_id}'. Available models: {', '.join(valid_model_ids)}")
        model_id_to_use = requested_model_id
        global current_ai_studio_model_id
        if current_ai_studio_model_id != model_id_to_use:
            needs_model_switching = True
            logger.info(f"[{req_id}] ÈúÄË¶ÅÂàáÊç¢Ê®°Âûã: ÂΩìÂâç={current_ai_studio_model_id} -> ÁõÆÊ†á={model_id_to_use}")
        else:
            logger.info(f"[{req_id}] ËØ∑Ê±ÇÊ®°Âûã‰∏éÂΩìÂâçÊ®°ÂûãÁõ∏Âêå ({model_id_to_use})ÔºåÊó†ÈúÄÂàáÊç¢")
    else:
        logger.info(f"[{req_id}] Êú™ÊåáÂÆöÂÖ∑‰ΩìÊ®°ÂûãÊàñ‰ΩøÁî®‰ª£ÁêÜÊ®°ÂûãÂêçÁß∞ÔºåÂ∞Ü‰ΩøÁî®ÂΩìÂâçÊ®°Âûã: {current_ai_studio_model_id or 'Êú™Áü•'}")
    client_disconnected_event = Event()
    disconnect_check_task = None
    input_field_locator = page.locator(INPUT_SELECTOR) if page else None # Handle page=None
    submit_button_locator = page.locator(SUBMIT_BUTTON_SELECTOR) if page else None # Handle page=None

    async def check_disconnect_periodically():
        while not client_disconnected_event.is_set():
            try:
                if await http_request.is_disconnected():
                    logger.info(f"[{req_id}] (Disco Check Task) ÂÆ¢Êà∑Á´ØÊñ≠ÂºÄ„ÄÇËÆæÁΩÆ‰∫ã‰ª∂Âπ∂Â∞ùËØïÂÅúÊ≠¢„ÄÇ")
                    client_disconnected_event.set()
                    try:
                        if submit_button_locator and await submit_button_locator.is_enabled(timeout=1500):
                             if input_field_locator and await input_field_locator.input_value(timeout=1500) == '':
                                 logger.info(f"[{req_id}] (Disco Check Task)   ÁÇπÂáªÂÅúÊ≠¢...")
                                 await submit_button_locator.click(timeout=3000, force=True)
                    except Exception as click_err: logger.warning(f"[{req_id}] (Disco Check Task) ÂÅúÊ≠¢ÊåâÈíÆÁÇπÂáªÂ§±Ë¥•: {click_err}")
                    if not result_future.done(): result_future.set_exception(HTTPException(status_code=499, detail=f"[{req_id}] ÂÆ¢Êà∑Á´ØÂú®Â§ÑÁêÜÊúüÈó¥ÂÖ≥Èó≠‰∫ÜËØ∑Ê±Ç"))
                    break
                await asyncio.sleep(1.0)
            except asyncio.CancelledError: break
            except Exception as e:
                logger.error(f"[{req_id}] (Disco Check Task) ÈîôËØØ: {e}")
                client_disconnected_event.set()
                if not result_future.done(): result_future.set_exception(HTTPException(status_code=500, detail=f"[{req_id}] Internal disconnect checker error: {e}"))
                break
    disconnect_check_task = asyncio.create_task(check_disconnect_periodically())
    def check_client_disconnected(msg_prefix=""):
        if client_disconnected_event.is_set():
            logger.info(f"[{req_id}] {msg_prefix}Ê£ÄÊµãÂà∞ÂÆ¢Êà∑Á´ØÊñ≠ÂºÄËøûÊé•‰∫ã‰ª∂„ÄÇ")
            raise ClientDisconnectedError(f"[{req_id}] Client disconnected event set.")
        return False
    try:
        if not page or page.is_closed() or not is_page_ready:
            raise HTTPException(status_code=503, detail=f"[{req_id}] AI Studio È°µÈù¢‰∏¢Â§±ÊàñÊú™Â∞±Áª™„ÄÇ", headers={"Retry-After": "30"})
        check_client_disconnected("Initial Page Check: ")
        if needs_model_switching and model_id_to_use:
            async with model_switching_lock:
                model_before_switch_attempt = current_ai_studio_model_id
                if current_ai_studio_model_id != model_id_to_use:
                    logger.info(f"[{req_id}] Ëé∑ÂèñÈîÅÂêéÂáÜÂ§áÂàáÊç¢: ÂΩìÂâçÂÜÖÂ≠ò‰∏≠Ê®°Âûã={current_ai_studio_model_id}, ÁõÆÊ†á={model_id_to_use}")
                    switch_success = await switch_ai_studio_model(page, model_id_to_use, req_id)
                    if switch_success:
                        current_ai_studio_model_id = model_id_to_use
                        model_actually_switched_in_current_api_call = True
                        logger.info(f"[{req_id}] ‚úÖ Ê®°ÂûãÂàáÊç¢ÊàêÂäü„ÄÇÂÖ®Â±ÄÊ®°ÂûãÁä∂ÊÄÅÂ∑≤Êõ¥Êñ∞‰∏∫: {current_ai_studio_model_id}")
                    else:
                        logger.warning(f"[{req_id}] ‚ùå Ê®°ÂûãÂàáÊç¢Ëá≥ {model_id_to_use} Â§±Ë¥• (AI Studio Êú™Êé•ÂèóÊàñË¶ÜÁõñ‰∫ÜÊõ¥Êîπ)„ÄÇ")
                        active_model_id_after_fail = model_before_switch_attempt
                        try:
                            final_prefs_str_after_fail = await page.evaluate("() => localStorage.getItem('aiStudioUserPreference')")
                            if final_prefs_str_after_fail:
                                final_prefs_obj_after_fail = json.loads(final_prefs_str_after_fail)
                                model_path_in_final_prefs = final_prefs_obj_after_fail.get("promptModel")
                                if model_path_in_final_prefs and isinstance(model_path_in_final_prefs, str):
                                    active_model_id_after_fail = model_path_in_final_prefs.split('/')[-1]
                        except Exception as read_final_prefs_err:
                            logger.error(f"[{req_id}] ÂàáÊç¢Â§±Ë¥•ÂêéËØªÂèñÊúÄÁªà localStorage Âá∫Èîô: {read_final_prefs_err}")
                        current_ai_studio_model_id = active_model_id_after_fail
                        logger.info(f"[{req_id}] ÂÖ®Â±ÄÊ®°ÂûãÁä∂ÊÄÅÂú®ÂàáÊç¢Â§±Ë¥•ÂêéËÆæÁΩÆ‰∏∫ (Êàñ‰øùÊåÅ‰∏∫): {current_ai_studio_model_id}")
                        actual_displayed_model_name = "Êú™Áü• (Êó†Ê≥ïËØªÂèñ)"
                        try:
                            model_wrapper_locator = page.locator('#mat-select-value-0 mat-select-trigger').first
                            actual_displayed_model_name = await model_wrapper_locator.inner_text(timeout=3000)
                        except Exception:
                            pass
                        raise HTTPException(
                            status_code=422,
                            detail=f"[{req_id}] AI Studio Êú™ËÉΩÂ∫îÁî®ÊâÄËØ∑Ê±ÇÁöÑÊ®°Âûã '{model_id_to_use}' ÊàñËØ•Ê®°Âûã‰∏çÂèóÊîØÊåÅ„ÄÇËØ∑ÈÄâÊã© AI Studio ÁΩëÈ°µÁïåÈù¢‰∏≠ÂèØÁî®ÁöÑÊ®°Âûã„ÄÇÂΩìÂâçÂÆûÈôÖÁîüÊïàÁöÑÊ®°Âûã ID ‰∏∫ '{current_ai_studio_model_id}', È°µÈù¢ÊòæÁ§∫‰∏∫ '{actual_displayed_model_name}'."
                        )
                else:
                    logger.info(f"[{req_id}] Ëé∑ÂèñÈîÅÂêéÂèëÁé∞Ê®°ÂûãÂ∑≤ÊòØÁõÆÊ†áÊ®°Âûã {current_ai_studio_model_id}ÔºåÊó†ÈúÄÂàáÊç¢")
        async with params_cache_lock:
            cached_model_for_params = page_params_cache.get("last_known_model_id_for_params")
            if model_actually_switched_in_current_api_call or \
               (current_ai_studio_model_id is not None and current_ai_studio_model_id != cached_model_for_params):
                action_taken = "Invalidating" if page_params_cache else "Initializing"
                logger.info(f"[{req_id}] {action_taken} parameter cache. Reason: Model context changed (switched this call: {model_actually_switched_in_current_api_call}, current model: {current_ai_studio_model_id}, cache model: {cached_model_for_params}).")
                page_params_cache.clear()
                if current_ai_studio_model_id:
                    page_params_cache["last_known_model_id_for_params"] = current_ai_studio_model_id
            else:
                logger.debug(f"[{req_id}] Parameter cache for model '{cached_model_for_params}' remains valid (current model: '{current_ai_studio_model_id}', switched this call: {model_actually_switched_in_current_api_call}).")
        try: validate_chat_request(request.messages, req_id)
        except ValueError as e: raise HTTPException(status_code=400, detail=f"[{req_id}] Êó†ÊïàËØ∑Ê±Ç: {e}")
        prepared_prompt = prepare_combined_prompt(request.messages, req_id)
        check_client_disconnected("After Prompt Prep: ")
        logger.info(f"[{req_id}] (Refactored Process) ÂºÄÂßãÊ∏ÖÁ©∫ËÅäÂ§©ËÆ∞ÂΩï...")
        try:
            clear_chat_button = page.locator(CLEAR_CHAT_BUTTON_SELECTOR)
            confirm_button = page.locator(CLEAR_CHAT_CONFIRM_BUTTON_SELECTOR)
            overlay_locator = page.locator('div.cdk-overlay-backdrop')
            proceed_with_clear_clicks = False
            try:
                await expect_async(clear_chat_button).to_be_enabled(timeout=3000)
                proceed_with_clear_clicks = True
            except Exception as e:
                is_new_chat_url = '/prompts/new_chat' in page.url.rstrip('/')
                if is_new_chat_url:
                    logger.info(f"[{req_id}] Ê∏ÖÁ©∫ÊåâÈíÆ‰∏çÂèØÁî® (È¢ÑÊúü)„ÄÇ")
                else:
                    logger.warning(f"[{req_id}] Á≠âÂæÖÊ∏ÖÁ©∫ÊåâÈíÆÂ§±Ë¥•: {e}„ÄÇË∑≥ËøáÁÇπÂáª„ÄÇ")
            check_client_disconnected("After Clear Button Check: ")
            if proceed_with_clear_clicks:
                try:
                    await expect_async(overlay_locator).to_be_hidden(timeout=3000)
                except Exception as overlay_err:
                    logger.warning(f"[{req_id}] Overlay did not disappear before clear click (ignored): {overlay_err}")
                check_client_disconnected("After Overlay Check (Before Clear): ")
                await clear_chat_button.click(timeout=5000)
                check_client_disconnected("After Clear Button Click: ")
                confirm_button_locator = page.locator(CLEAR_CHAT_CONFIRM_BUTTON_SELECTOR)
                try:
                    logger.info(f"[{req_id}] Á≠âÂæÖÊ∏ÖÁ©∫Á°ÆËÆ§ÊåâÈíÆ '{CLEAR_CHAT_CONFIRM_BUTTON_SELECTOR}' ÂèØËßÅÂπ∂ÂèØÁÇπÂáª...")
                    await expect_async(confirm_button_locator).to_be_enabled(timeout=10000)
                    logger.info(f"[{req_id}] ‚úÖ Ê∏ÖÁ©∫Á°ÆËÆ§ÊåâÈíÆÂ∑≤ÂáÜÂ§áÂ•Ω„ÄÇ")
                    check_client_disconnected("After Confirm Button Enabled: ")
                    await confirm_button_locator.click(timeout=5000)
                    check_client_disconnected("After Confirm Button Click: ")
                    logger.info(f"[{req_id}] Ê∏ÖÁ©∫Á°ÆËÆ§ÊåâÈíÆÂ∑≤ÁÇπÂáª„ÄÇ")
                    last_response_container = page.locator(RESPONSE_CONTAINER_SELECTOR).last
                    await asyncio.sleep(0.5)
                    check_client_disconnected("After Clear Post-Delay: ")
                    try:
                        await expect_async(last_response_container).to_be_hidden(timeout=CLEAR_CHAT_VERIFY_TIMEOUT_MS - 500)
                        logger.info(f"[{req_id}] ‚úÖ ËÅäÂ§©Â∑≤ÊàêÂäüÊ∏ÖÁ©∫ (È™åËØÅÈÄöËøá)„ÄÇ")
                    except Exception as verify_err:
                        logger.warning(f"[{req_id}] ‚ö†Ô∏è Ë≠¶Âëä: Ê∏ÖÁ©∫ËÅäÂ§©È™åËØÅÂ§±Ë¥•: {verify_err}")
                except (PlaywrightAsyncError, asyncio.TimeoutError, ClientDisconnectedError) as confirm_err:
                    if isinstance(confirm_err, ClientDisconnectedError): raise
                    logger.error(f"[{req_id}] ‚ùå Á≠âÂæÖÊàñÁÇπÂáªÊ∏ÖÁ©∫Á°ÆËÆ§ÊåâÈíÆÊó∂Âá∫Èîô: {confirm_err}")
                    await save_error_snapshot(f"clear_chat_confirm_button_error_{req_id}")
                    raise PlaywrightAsyncError(f"Clear chat confirm button interaction failed: {confirm_err}") from confirm_err
                except Exception as clear_exc:
                    logger.exception(f"[{req_id}] ‚ùå ÈîôËØØ: Ê∏ÖÁ©∫ËÅäÂ§©Á°ÆËÆ§Èò∂ÊÆµÊÑèÂ§ñÈîôËØØ")
                    await save_error_snapshot(f"clear_chat_confirm_unexpected_{req_id}")
                    raise PlaywrightAsyncError(f"Unexpected error during clear chat confirmation: {clear_exc}") from clear_exc
                check_client_disconnected("After Clear Chat Logic: ")
        except (PlaywrightAsyncError, asyncio.TimeoutError, ClientDisconnectedError) as clear_err:
            if isinstance(clear_err, ClientDisconnectedError): raise
            logger.error(f"[{req_id}] ‚ùå ÈîôËØØ: Ê∏ÖÁ©∫ËÅäÂ§©Èò∂ÊÆµÂá∫Èîô: {clear_err}")
            await save_error_snapshot(f"clear_chat_error_{req_id}")
        except Exception as clear_exc:
            logger.exception(f"[{req_id}] ‚ùå ÈîôËØØ: Ê∏ÖÁ©∫ËÅäÂ§©Èò∂ÊÆµÊÑèÂ§ñÈîôËØØ")
            await save_error_snapshot(f"clear_chat_unexpected_{req_id}")
        check_client_disconnected("After Clear Chat Logic: ")
        if request.temperature is not None and page and not page.is_closed():
            async with params_cache_lock:
                logger.info(f"[{req_id}] (Refactored Process) Ê£ÄÊü•Âπ∂Ë∞ÉÊï¥Ê∏©Â∫¶ËÆæÁΩÆ...")
                requested_temp = request.temperature
                clamped_temp = max(0.0, min(2.0, requested_temp))
                if clamped_temp != requested_temp:
                    logger.warning(f"[{req_id}] ËØ∑Ê±ÇÁöÑÊ∏©Â∫¶ {requested_temp} Ë∂ÖÂá∫ËåÉÂõ¥ [0, 2]ÔºåÂ∑≤Ë∞ÉÊï¥‰∏∫ {clamped_temp}")
                cached_temp = page_params_cache.get("temperature")
                if cached_temp is not None and abs(cached_temp - clamped_temp) < 0.001:
                    logger.info(f"[{req_id}] Ê∏©Â∫¶ ({clamped_temp}) ‰∏éÁºìÂ≠òÂÄº ({cached_temp}) ‰∏ÄËá¥„ÄÇË∑≥ËøáÈ°µÈù¢‰∫§‰∫í„ÄÇ")
                else:
                    logger.info(f"[{req_id}] ËØ∑Ê±ÇÊ∏©Â∫¶ ({clamped_temp}) ‰∏éÁºìÂ≠òÂÄº ({cached_temp}) ‰∏ç‰∏ÄËá¥ÊàñÁºìÂ≠ò‰∏≠Êó†ÂÄº„ÄÇÈúÄË¶Å‰∏éÈ°µÈù¢‰∫§‰∫í„ÄÇ")
                    temp_input_locator = page.locator(TEMPERATURE_INPUT_SELECTOR)
                    try:
                        await expect_async(temp_input_locator).to_be_visible(timeout=5000)
                        check_client_disconnected("Ê∏©Â∫¶Ë∞ÉÊï¥ - ËæìÂÖ•Ê°ÜÂèØËßÅÂêé: ")
                        current_temp_str = await temp_input_locator.input_value(timeout=3000)
                        check_client_disconnected("Ê∏©Â∫¶Ë∞ÉÊï¥ - ËØªÂèñËæìÂÖ•Ê°ÜÂÄºÂêé: ")
                        current_temp_float = float(current_temp_str)
                        logger.info(f"[{req_id}] È°µÈù¢ÂΩìÂâçÊ∏©Â∫¶: {current_temp_float}, ËØ∑Ê±ÇË∞ÉÊï¥ÂêéÊ∏©Â∫¶: {clamped_temp}")
                        if abs(current_temp_float - clamped_temp) < 0.001:
                            logger.info(f"[{req_id}] È°µÈù¢ÂΩìÂâçÊ∏©Â∫¶ ({current_temp_float}) ‰∏éËØ∑Ê±ÇÊ∏©Â∫¶ ({clamped_temp}) ‰∏ÄËá¥„ÄÇÊõ¥Êñ∞ÁºìÂ≠òÂπ∂Ë∑≥ËøáÂÜôÂÖ•„ÄÇ")
                            page_params_cache["temperature"] = current_temp_float
                        else:
                            logger.info(f"[{req_id}] È°µÈù¢Ê∏©Â∫¶ ({current_temp_float}) ‰∏éËØ∑Ê±ÇÊ∏©Â∫¶ ({clamped_temp}) ‰∏çÂêåÔºåÊ≠£Âú®Êõ¥Êñ∞...")
                            await temp_input_locator.fill(str(clamped_temp), timeout=5000)
                            check_client_disconnected("Ê∏©Â∫¶Ë∞ÉÊï¥ - Â°´ÂÖÖËæìÂÖ•Ê°ÜÂêé: ")
                            await asyncio.sleep(0.1)
                            new_temp_str = await temp_input_locator.input_value(timeout=3000)
                            new_temp_float = float(new_temp_str)
                            if abs(new_temp_float - clamped_temp) < 0.001:
                                logger.info(f"[{req_id}] ‚úÖ Ê∏©Â∫¶Â∑≤ÊàêÂäüÊõ¥Êñ∞‰∏∫: {new_temp_float}„ÄÇÊõ¥Êñ∞ÁºìÂ≠ò„ÄÇ")
                                page_params_cache["temperature"] = new_temp_float
                            else:
                                logger.warning(f"[{req_id}] ‚ö†Ô∏è Ê∏©Â∫¶Êõ¥Êñ∞ÂêéÈ™åËØÅÂ§±Ë¥•„ÄÇÈ°µÈù¢ÊòæÁ§∫: {new_temp_float}, ÊúüÊúõ: {clamped_temp}„ÄÇÊ∏ÖÈô§ÁºìÂ≠ò‰∏≠ÁöÑÊ∏©Â∫¶„ÄÇ")
                                page_params_cache.pop("temperature", None)
                                await save_error_snapshot(f"temperature_verify_fail_{req_id}")
                    except ValueError as ve:
                        logger.error(f"[{req_id}] ËΩ¨Êç¢Ê∏©Â∫¶ÂÄº‰∏∫ÊµÆÁÇπÊï∞Êó∂Âá∫Èîô: '{current_temp_str if 'current_temp_str' in locals() else 'Êú™Áü•ÂÄº'}'. ÈîôËØØ: {ve}„ÄÇÊ∏ÖÈô§ÁºìÂ≠ò‰∏≠ÁöÑÊ∏©Â∫¶„ÄÇ")
                        page_params_cache.pop("temperature", None)
                        await save_error_snapshot(f"temperature_value_error_{req_id}")
                    except PlaywrightAsyncError as pw_err:
                        logger.error(f"[{req_id}] ‚ùå Êìç‰ΩúÊ∏©Â∫¶ËæìÂÖ•Ê°ÜÊó∂ÂèëÁîüPlaywrightÈîôËØØ: {pw_err}„ÄÇÊ∏ÖÈô§ÁºìÂ≠ò‰∏≠ÁöÑÊ∏©Â∫¶„ÄÇ")
                        page_params_cache.pop("temperature", None)
                        await save_error_snapshot(f"temperature_playwright_error_{req_id}")
                    except ClientDisconnectedError:
                        logger.info(f"[{req_id}] ÂÆ¢Êà∑Á´ØÂú®Ë∞ÉÊï¥Ê∏©Â∫¶Êó∂Êñ≠ÂºÄËøûÊé•„ÄÇ")
                        raise
                    except Exception as e_temp:
                        logger.exception(f"[{req_id}] ‚ùå Ë∞ÉÊï¥Ê∏©Â∫¶Êó∂ÂèëÁîüÊú™Áü•ÈîôËØØ„ÄÇÊ∏ÖÈô§ÁºìÂ≠ò‰∏≠ÁöÑÊ∏©Â∫¶„ÄÇ")
                        page_params_cache.pop("temperature", None)
                        await save_error_snapshot(f"temperature_unknown_error_{req_id}")
            check_client_disconnected("Ê∏©Â∫¶Ë∞ÉÊï¥ - ÈÄªËæëÂÆåÊàêÂêé: ")
        if request.max_output_tokens is not None and page and not page.is_closed():
            async with params_cache_lock:
                logger.info(f"[{req_id}] (Refactored Process) Ê£ÄÊü•Âπ∂Ë∞ÉÊï¥ÊúÄÂ§ßËæìÂá∫ Token ËÆæÁΩÆ...")
                requested_max_tokens = request.max_output_tokens
                min_val_for_tokens = 1
                max_val_for_tokens_from_model = 65536
                if model_id_to_use and parsed_model_list:
                    current_model_data = next((m for m in parsed_model_list if m.get("id") == model_id_to_use), None)
                    if current_model_data and current_model_data.get("supported_max_output_tokens") is not None:
                        try:
                            supported_tokens = int(current_model_data["supported_max_output_tokens"])
                            if supported_tokens > 0: max_val_for_tokens_from_model = supported_tokens
                            else: logger.warning(f"[{req_id}] Ê®°Âûã {model_id_to_use} supported_max_output_tokens Êó†Êïà: {supported_tokens}")
                        except (ValueError, TypeError): logger.warning(f"[{req_id}] Ê®°Âûã {model_id_to_use} supported_max_output_tokens Ëß£ÊûêÂ§±Ë¥•: {current_model_data['supported_max_output_tokens']}")
                    else: logger.warning(f"[{req_id}] Êú™ÊâæÂà∞Ê®°Âûã {model_id_to_use} ÁöÑ supported_max_output_tokens Êï∞ÊçÆ„ÄÇ")
                else: logger.warning(f"[{req_id}] model_id_to_use ('{model_id_to_use}') Êàñ parsed_model_list ‰∏çÂèØÁî®Ôºå‰ΩøÁî®ÈªòËÆ§ tokens ‰∏äÈôê„ÄÇ")
                clamped_max_tokens = max(min_val_for_tokens, min(max_val_for_tokens_from_model, requested_max_tokens))
                if clamped_max_tokens != requested_max_tokens:
                    logger.warning(f"[{req_id}] ËØ∑Ê±ÇÁöÑÊúÄÂ§ßËæìÂá∫ Tokens {requested_max_tokens} Ë∂ÖÂá∫Ê®°ÂûãËåÉÂõ¥ [{min_val_for_tokens}, {max_val_for_tokens_from_model}]ÔºåÂ∑≤Ë∞ÉÊï¥‰∏∫ {clamped_max_tokens}")
                cached_max_tokens = page_params_cache.get("max_output_tokens")
                if cached_max_tokens is not None and cached_max_tokens == clamped_max_tokens:
                    logger.info(f"[{req_id}] ÊúÄÂ§ßËæìÂá∫ Tokens ({clamped_max_tokens}) ‰∏éÁºìÂ≠òÂÄº ({cached_max_tokens}) ‰∏ÄËá¥„ÄÇË∑≥ËøáÈ°µÈù¢‰∫§‰∫í„ÄÇ")
                else:
                    logger.info(f"[{req_id}] ËØ∑Ê±ÇÊúÄÂ§ßËæìÂá∫ Tokens ({clamped_max_tokens}) ‰∏éÁºìÂ≠òÂÄº ({cached_max_tokens}) ‰∏ç‰∏ÄËá¥ÊàñÁºìÂ≠ò‰∏≠Êó†ÂÄº„ÄÇÈúÄË¶Å‰∏éÈ°µÈù¢‰∫§‰∫í„ÄÇ")
                    max_tokens_input_locator = page.locator(MAX_OUTPUT_TOKENS_SELECTOR)
                    try:
                        await expect_async(max_tokens_input_locator).to_be_visible(timeout=5000)
                        check_client_disconnected("ÊúÄÂ§ßËæìÂá∫TokenË∞ÉÊï¥ - ËæìÂÖ•Ê°ÜÂèØËßÅÂêé: ")
                        current_max_tokens_str = await max_tokens_input_locator.input_value(timeout=3000)
                        check_client_disconnected("ÊúÄÂ§ßËæìÂá∫TokenË∞ÉÊï¥ - ËØªÂèñËæìÂÖ•Ê°ÜÂÄºÂêé: ")
                        current_max_tokens_int = int(current_max_tokens_str)
                        logger.info(f"[{req_id}] È°µÈù¢ÂΩìÂâçÊúÄÂ§ßËæìÂá∫ Tokens: {current_max_tokens_int}, ËØ∑Ê±ÇË∞ÉÊï¥ÂêéÊúÄÂ§ßËæìÂá∫ Tokens: {clamped_max_tokens}")
                        if current_max_tokens_int == clamped_max_tokens:
                            logger.info(f"[{req_id}] È°µÈù¢ÂΩìÂâçÊúÄÂ§ßËæìÂá∫ Tokens ({current_max_tokens_int}) ‰∏éËØ∑Ê±ÇÂÄº ({clamped_max_tokens}) ‰∏ÄËá¥„ÄÇÊõ¥Êñ∞ÁºìÂ≠òÂπ∂Ë∑≥ËøáÂÜôÂÖ•„ÄÇ")
                            page_params_cache["max_output_tokens"] = current_max_tokens_int
                        else:
                            logger.info(f"[{req_id}] È°µÈù¢ÊúÄÂ§ßËæìÂá∫ Tokens ({current_max_tokens_int}) ‰∏éËØ∑Ê±ÇÂÄº ({clamped_max_tokens}) ‰∏çÂêåÔºåÊ≠£Âú®Êõ¥Êñ∞...")
                            await max_tokens_input_locator.fill(str(clamped_max_tokens), timeout=5000)
                            check_client_disconnected("ÊúÄÂ§ßËæìÂá∫TokenË∞ÉÊï¥ - Â°´ÂÖÖËæìÂÖ•Ê°ÜÂêé: ")
                            await asyncio.sleep(0.1)
                            new_max_tokens_str = await max_tokens_input_locator.input_value(timeout=3000)
                            new_max_tokens_int = int(new_max_tokens_str)
                            if new_max_tokens_int == clamped_max_tokens:
                                logger.info(f"[{req_id}] ‚úÖ ÊúÄÂ§ßËæìÂá∫ Tokens Â∑≤ÊàêÂäüÊõ¥Êñ∞‰∏∫: {new_max_tokens_int}„ÄÇÊõ¥Êñ∞ÁºìÂ≠ò„ÄÇ")
                                page_params_cache["max_output_tokens"] = new_max_tokens_int
                            else:
                                logger.warning(f"[{req_id}] ‚ö†Ô∏è ÊúÄÂ§ßËæìÂá∫ Tokens Êõ¥Êñ∞ÂêéÈ™åËØÅÂ§±Ë¥•„ÄÇÈ°µÈù¢ÊòæÁ§∫: {new_max_tokens_int}, ÊúüÊúõ: {clamped_max_tokens}„ÄÇÊ∏ÖÈô§ÁºìÂ≠ò‰∏≠ÁöÑÊ≠§ÂèÇÊï∞„ÄÇ")
                                page_params_cache.pop("max_output_tokens", None)
                                await save_error_snapshot(f"max_tokens_verify_fail_{req_id}")
                    except ValueError as ve:
                        logger.error(f"[{req_id}] ËΩ¨Êç¢ÊúÄÂ§ßËæìÂá∫ Tokens ÂÄº‰∏∫Êï¥Êï∞Êó∂Âá∫Èîô: '{current_max_tokens_str if 'current_max_tokens_str' in locals() else 'Êú™Áü•ÂÄº'}'. ÈîôËØØ: {ve}„ÄÇÊ∏ÖÈô§ÁºìÂ≠ò‰∏≠ÁöÑÊ≠§ÂèÇÊï∞„ÄÇ")
                        page_params_cache.pop("max_output_tokens", None)
                        await save_error_snapshot(f"max_tokens_value_error_{req_id}")
                    except PlaywrightAsyncError as pw_err:
                        logger.error(f"[{req_id}] ‚ùå Êìç‰ΩúÊúÄÂ§ßËæìÂá∫ Tokens ËæìÂÖ•Ê°ÜÊó∂ÂèëÁîüPlaywrightÈîôËØØ: {pw_err}„ÄÇÊ∏ÖÈô§ÁºìÂ≠ò‰∏≠ÁöÑÊ≠§ÂèÇÊï∞„ÄÇ")
                        page_params_cache.pop("max_output_tokens", None)
                        await save_error_snapshot(f"max_tokens_playwright_error_{req_id}")
                    except ClientDisconnectedError:
                        logger.info(f"[{req_id}] ÂÆ¢Êà∑Á´ØÂú®Ë∞ÉÊï¥ÊúÄÂ§ßËæìÂá∫ Tokens Êó∂Êñ≠ÂºÄËøûÊé•„ÄÇ")
                        raise
                    except Exception as e_max_tokens:
                        logger.exception(f"[{req_id}] ‚ùå Ë∞ÉÊï¥ÊúÄÂ§ßËæìÂá∫ Tokens Êó∂ÂèëÁîüÊú™Áü•ÈîôËØØ„ÄÇÊ∏ÖÈô§ÁºìÂ≠ò‰∏≠ÁöÑÊ≠§ÂèÇÊï∞„ÄÇ")
                        page_params_cache.pop("max_output_tokens", None)
                        await save_error_snapshot(f"max_tokens_unknown_error_{req_id}")
            check_client_disconnected("ÊúÄÂ§ßËæìÂá∫TokenË∞ÉÊï¥ - ÈÄªËæëÂÆåÊàêÂêé: ")
        if request.stop is not None and page and not page.is_closed():
            async with params_cache_lock:
                logger.info(f"[{req_id}] (Refactored Process) Ê£ÄÊü•Âπ∂ËÆæÁΩÆÂÅúÊ≠¢Â∫èÂàó...")
                requested_stop_sequences_raw = []
                if isinstance(request.stop, str):
                    requested_stop_sequences_raw = [request.stop]
                elif isinstance(request.stop, list):
                    requested_stop_sequences_raw = [s for s in request.stop if isinstance(s, str) and s.strip()]
                normalized_requested_stops = set(s.strip() for s in requested_stop_sequences_raw if s.strip())
                cached_stops_set = page_params_cache.get("stop_sequences")
                if cached_stops_set is not None and cached_stops_set == normalized_requested_stops:
                    logger.info(f"[{req_id}] ËØ∑Ê±ÇÁöÑÂÅúÊ≠¢Â∫èÂàó ({normalized_requested_stops}) ‰∏éÁºìÂ≠òÂÄº ({cached_stops_set}) ‰∏ÄËá¥„ÄÇË∑≥ËøáÈ°µÈù¢‰∫§‰∫í„ÄÇ")
                else:
                    logger.info(f"[{req_id}] ËØ∑Ê±ÇÂÅúÊ≠¢Â∫èÂàó ({normalized_requested_stops}) ‰∏éÁºìÂ≠òÂÄº ({cached_stops_set}) ‰∏ç‰∏ÄËá¥ÊàñÁºìÂ≠ò‰∏≠Êó†ÂÄº„ÄÇÈúÄË¶Å‰∏éÈ°µÈù¢‰∫§‰∫í„ÄÇ")
                    stop_input_locator = page.locator(STOP_SEQUENCE_INPUT_SELECTOR)
                    remove_chip_buttons_locator = page.locator(MAT_CHIP_REMOVE_BUTTON_SELECTOR)
                    interaction_successful = False
                    try:
                        logger.info(f"[{req_id}] Â∞ùËØïÊ∏ÖÁ©∫Â∑≤ÊúâÁöÑÂÅúÊ≠¢Â∫èÂàó...")
                        initial_chip_count = await remove_chip_buttons_locator.count()
                        removed_count = 0
                        max_removals = initial_chip_count + 5
                        while await remove_chip_buttons_locator.count() > 0 and removed_count < max_removals:
                            check_client_disconnected("ÂÅúÊ≠¢Â∫èÂàóÊ∏ÖÈô§ - Âæ™ÁéØÂºÄÂßã: ")
                            try:
                                await remove_chip_buttons_locator.first.click(timeout=2000)
                                removed_count += 1; await asyncio.sleep(0.15)
                            except Exception: break
                        logger.info(f"[{req_id}] Â∑≤ÊúâÂÅúÊ≠¢Â∫èÂàóÊ∏ÖÁ©∫Â∞ùËØïÂÆåÊàê„ÄÇÁßªÈô§ {removed_count} ‰∏™„ÄÇ")
                        check_client_disconnected("ÂÅúÊ≠¢Â∫èÂàóÊ∏ÖÈô§ - ÂÆåÊàêÂêé: ")
                        if normalized_requested_stops:
                            logger.info(f"[{req_id}] Ê∑ªÂä†Êñ∞ÁöÑÂÅúÊ≠¢Â∫èÂàó: {normalized_requested_stops}")
                            await expect_async(stop_input_locator).to_be_visible(timeout=5000)
                            for seq in normalized_requested_stops:
                                await stop_input_locator.fill(seq, timeout=3000)
                                await stop_input_locator.press("Enter", timeout=3000)
                                await asyncio.sleep(0.2)
                                current_input_val = await stop_input_locator.input_value(timeout=1000)
                                if current_input_val:
                                     logger.warning(f"[{req_id}] Ê∑ªÂä†ÂÅúÊ≠¢Â∫èÂàó '{seq}' ÂêéËæìÂÖ•Ê°ÜÊú™Ê∏ÖÁ©∫ (ÂÄº‰∏∫: '{current_input_val}')„ÄÇ")
                            logger.info(f"[{req_id}] ‚úÖ Êñ∞ÂÅúÊ≠¢Â∫èÂàóÊ∑ªÂä†Êìç‰ΩúÂÆåÊàê„ÄÇ")
                        else:
                            logger.info(f"[{req_id}] Ê≤°ÊúâÊèê‰æõÊñ∞ÁöÑÊúâÊïàÂÅúÊ≠¢Â∫èÂàóÊù•Ê∑ªÂä† (ËØ∑Ê±ÇÊ∏ÖÁ©∫)„ÄÇ")
                        interaction_successful = True
                        page_params_cache["stop_sequences"] = normalized_requested_stops
                        logger.info(f"[{req_id}] ÂÅúÊ≠¢Â∫èÂàóÁºìÂ≠òÂ∑≤Êõ¥Êñ∞‰∏∫: {normalized_requested_stops}")
                    except PlaywrightAsyncError as pw_err:
                        logger.error(f"[{req_id}] ‚ùå Êìç‰ΩúÂÅúÊ≠¢Â∫èÂàóÊó∂ÂèëÁîüPlaywrightÈîôËØØ: {pw_err}„ÄÇÊ∏ÖÈô§ÁºìÂ≠ò‰∏≠ÁöÑÊ≠§ÂèÇÊï∞„ÄÇ")
                        page_params_cache.pop("stop_sequences", None)
                        await save_error_snapshot(f"stop_sequence_playwright_error_{req_id}")
                    except ClientDisconnectedError:
                        logger.info(f"[{req_id}] ÂÆ¢Êà∑Á´ØÂú®Ë∞ÉÊï¥ÂÅúÊ≠¢Â∫èÂàóÊó∂Êñ≠ÂºÄËøûÊé•„ÄÇ")
                        raise
                    except Exception as e_stop_seq:
                        logger.exception(f"[{req_id}] ‚ùå ËÆæÁΩÆÂÅúÊ≠¢Â∫èÂàóÊó∂ÂèëÁîüÊú™Áü•ÈîôËØØ„ÄÇÊ∏ÖÈô§ÁºìÂ≠ò‰∏≠ÁöÑÊ≠§ÂèÇÊï∞„ÄÇ")
                        page_params_cache.pop("stop_sequences", None)
                        await save_error_snapshot(f"stop_sequence_unknown_error_{req_id}")
            check_client_disconnected("ÂÅúÊ≠¢Â∫èÂàóË∞ÉÊï¥ - ÈÄªËæëÂÆåÊàêÂêé: ")
        if request.top_p is not None and page and not page.is_closed():
            logger.info(f"[{req_id}] (Refactored Process) Ê£ÄÊü•Âπ∂Ë∞ÉÊï¥ Top P ËÆæÁΩÆ...")
            requested_top_p = request.top_p
            clamped_top_p = max(0.0, min(1.0, requested_top_p))
            if abs(clamped_top_p - requested_top_p) > 1e-9:
                logger.warning(f"[{req_id}] ËØ∑Ê±ÇÁöÑ Top P {requested_top_p} Ë∂ÖÂá∫ËåÉÂõ¥ [0, 1]ÔºåÂ∑≤Ë∞ÉÊï¥‰∏∫ {clamped_top_p}")
            top_p_input_locator = page.locator(TOP_P_INPUT_SELECTOR)
            try:
                await expect_async(top_p_input_locator).to_be_visible(timeout=5000)
                check_client_disconnected("Top P Ë∞ÉÊï¥ - ËæìÂÖ•Ê°ÜÂèØËßÅÂêé: ")
                current_top_p_str = await top_p_input_locator.input_value(timeout=3000)
                check_client_disconnected("Top P Ë∞ÉÊï¥ - ËØªÂèñËæìÂÖ•Ê°ÜÂÄºÂêé: ")
                current_top_p_float = float(current_top_p_str)
                logger.info(f"[{req_id}] È°µÈù¢ÂΩìÂâç Top P: {current_top_p_float}, ËØ∑Ê±ÇË∞ÉÊï¥Âêé Top P: {clamped_top_p}")
                if abs(current_top_p_float - clamped_top_p) > 1e-9:
                    logger.info(f"[{req_id}] È°µÈù¢ Top P ({current_top_p_float}) ‰∏éËØ∑Ê±Ç Top P ({clamped_top_p}) ‰∏çÂêåÔºåÊ≠£Âú®Êõ¥Êñ∞...")
                    await top_p_input_locator.fill(str(clamped_top_p), timeout=5000)
                    check_client_disconnected("Top P Ë∞ÉÊï¥ - Â°´ÂÖÖËæìÂÖ•Ê°ÜÂêé: ")
                    await asyncio.sleep(0.1)
                    new_top_p_str = await top_p_input_locator.input_value(timeout=3000)
                    new_top_p_float = float(new_top_p_str)
                    if abs(new_top_p_float - clamped_top_p) < 1e-9:
                        logger.info(f"[{req_id}] ‚úÖ Top P Â∑≤ÊàêÂäüÊõ¥Êñ∞‰∏∫: {new_top_p_float}")
                    else:
                        logger.warning(f"[{req_id}] ‚ö†Ô∏è Top P Êõ¥Êñ∞ÂêéÈ™åËØÅÂ§±Ë¥•„ÄÇÈ°µÈù¢ÊòæÁ§∫: {new_top_p_float}, ÊúüÊúõ: {clamped_top_p}")
                else:
                    logger.info(f"[{req_id}] È°µÈù¢ Top P ({current_top_p_float}) ‰∏éËØ∑Ê±Ç Top P ({clamped_top_p}) ‰∏ÄËá¥ÊàñÂú®ÂÆπÂ∑ÆËåÉÂõ¥ÂÜÖÔºåÊó†ÈúÄÊõ¥Êîπ„ÄÇ")
            except ValueError as ve:
                logger.error(f"[{req_id}] ËΩ¨Êç¢ Top P ÂÄº‰∏∫ÊµÆÁÇπÊï∞Êó∂Âá∫Èîô: '{current_top_p_str if 'current_top_p_str' in locals() else 'Êú™Áü•ÂÄº'}'. ÈîôËØØ: {ve}")
                await save_error_snapshot(f"top_p_value_error_{req_id}")
            except PlaywrightAsyncError as pw_err:
                logger.error(f"[{req_id}] ‚ùå Êìç‰Ωú Top P ËæìÂÖ•Ê°ÜÊó∂ÂèëÁîüPlaywrightÈîôËØØ: {pw_err}")
                await save_error_snapshot(f"top_p_playwright_error_{req_id}")
            except ClientDisconnectedError:
                logger.info(f"[{req_id}] ÂÆ¢Êà∑Á´ØÂú®Ë∞ÉÊï¥ Top P Êó∂Êñ≠ÂºÄËøûÊé•„ÄÇ")
                raise
            except Exception as e_top_p:
                logger.exception(f"[{req_id}] ‚ùå Ë∞ÉÊï¥ Top P Êó∂ÂèëÁîüÊú™Áü•ÈîôËØØ")
                await save_error_snapshot(f"top_p_unknown_error_{req_id}")
            check_client_disconnected("Top P Ë∞ÉÊï¥ - ÈÄªËæëÂÆåÊàêÂêé: ")
        logger.info(f"[{req_id}] (Refactored Process) Â°´ÂÖÖÂπ∂Êèê‰∫§ÊèêÁ§∫ ({len(prepared_prompt)} chars)...")
        prompt_textarea_locator = page.locator(PROMPT_TEXTAREA_SELECTOR)
        autosize_wrapper_locator = page.locator('ms-prompt-input-wrapper ms-autosize-textarea')
        try:
            await expect_async(prompt_textarea_locator).to_be_visible(timeout=5000)
            check_client_disconnected("After Input Visible: ")
            logger.info(f"[{req_id}]   - ‰ΩøÁî® JavaScript evaluate Â°´ÂÖÖÊèêÁ§∫ÊñáÊú¨...")
            await prompt_textarea_locator.evaluate(
                '''
                (element, text) => {
                    element.value = text;
                    element.dispatchEvent(new Event('input', { bubbles: true, cancelable: true }));
                    element.dispatchEvent(new Event('change', { bubbles: true, cancelable: true }));
                }
                ''',
                prepared_prompt
            )
            await autosize_wrapper_locator.evaluate('(element, text) => { element.setAttribute("data-value", text); }', prepared_prompt)
            logger.info(f"[{req_id}]   - JavaScript evaluate Â°´ÂÖÖÂÆåÊàêÔºådata-value Â∑≤Â∞ùËØïÊõ¥Êñ∞„ÄÇ")
            check_client_disconnected("After Input Fill (evaluate): ")
            await expect_async(submit_button_locator).to_be_enabled(timeout=10000)
            check_client_disconnected("After Submit Button Enabled: ")
            await asyncio.sleep(0.3)
            check_client_disconnected("After Submit Pre-Shortcut-Delay: ")
            submitted_successfully_via_shortcut = False
            user_prompt_autosize_locator = page.locator('ms-prompt-input-wrapper ms-autosize-textarea').nth(1)
            logger.info(f"[{req_id}]   - Áî®‰∫éÂø´Êç∑ÈîÆÂêéÈ™åËØÅÁöÑÁî®Êà∑ËæìÂÖ•Âå∫ÂüüÈÄâÊã©Âô®: nth(1) of 'ms-prompt-input-wrapper ms-autosize-textarea'")
            try:
                host_os_from_launcher = os.environ.get('HOST_OS_FOR_SHORTCUT')
                is_mac_determined = False
                if host_os_from_launcher:
                    logger.info(f"[{req_id}]   - ‰ªéÂêØÂä®Âô®ÁéØÂ¢ÉÂèòÈáè HOST_OS_FOR_SHORTCUT Ëé∑ÂèñÂà∞Êìç‰ΩúÁ≥ªÁªüÊèêÁ§∫: '{host_os_from_launcher}'")
                    if host_os_from_launcher == "Darwin":
                        is_mac_determined = True
                    elif host_os_from_launcher in ["Windows", "Linux"]:
                        is_mac_determined = False
                    else:
                        logger.warning(f"[{req_id}]   - Êú™Áü•ÁöÑ HOST_OS_FOR_SHORTCUT ÂÄº: '{host_os_from_launcher}'„ÄÇÂ∞ÜÂõûÈÄÄÂà∞ÊµèËßàÂô®Ê£ÄÊµã„ÄÇ")
                        host_os_from_launcher = None
                if not host_os_from_launcher:
                    if host_os_from_launcher is None:
                        logger.info(f"[{req_id}]   - HOST_OS_FOR_SHORTCUT Êú™ËÆæÁΩÆÊàñÂÄºÊú™Áü•ÔºåÂ∞ÜËøõË°åÊµèËßàÂô®ÂÜÖÈÉ®Êìç‰ΩúÁ≥ªÁªüÊ£ÄÊµã„ÄÇ")
                    user_agent_data_platform = None
                    try:
                        user_agent_data_platform = await page.evaluate("() => navigator.userAgentData?.platform || ''")
                    except Exception as e_ua_data:
                        logger.warning(f"[{req_id}]   - navigator.userAgentData.platform ËØªÂèñÂ§±Ë¥• ({e_ua_data})ÔºåÂ∞ùËØï navigator.userAgent„ÄÇ")
                        user_agent_string = await page.evaluate("() => navigator.userAgent || ''")
                        user_agent_string_lower = user_agent_string.lower()
                        if "macintosh" in user_agent_string_lower or "mac os x" in user_agent_string_lower or "macintel" in user_agent_string_lower:
                            user_agent_data_platform = "macOS"
                        elif "windows" in user_agent_string_lower:
                            user_agent_data_platform = "Windows"
                        elif "linux" in user_agent_string_lower:
                            user_agent_data_platform = "Linux"
                        else:
                            user_agent_data_platform = "Other"
                    if user_agent_data_platform and user_agent_data_platform != "Other":
                        user_agent_data_platform_lower = user_agent_data_platform.lower()
                        is_mac_determined = "mac" in user_agent_data_platform_lower or "macos" in user_agent_data_platform_lower or "macintel" in user_agent_data_platform_lower
                        logger.info(f"[{req_id}]   - ÊµèËßàÂô®ÂÜÖÈÉ®Ê£ÄÊµãÂà∞Âπ≥Âè∞: '{user_agent_data_platform}', Êé®Êñ≠ is_mac: {is_mac_determined}")
                    else:
                        logger.warning(f"[{req_id}]   - ÊµèËßàÂô®Âπ≥Âè∞‰ø°ÊÅØËé∑ÂèñÂ§±Ë¥•„ÄÅ‰∏∫Á©∫Êàñ‰∏∫'Other' ('{user_agent_data_platform}')„ÄÇÈªòËÆ§‰ΩøÁî®ÈùûMacÂø´Êç∑ÈîÆ„ÄÇ")
                        is_mac_determined = False
                shortcut_modifier = "Meta" if is_mac_determined else "Control"
                shortcut_key = "Enter"
                logger.info(f"[{req_id}]   - ÊúÄÁªàÈÄâÊã©Âø´Êç∑ÈîÆ: {shortcut_modifier}+{shortcut_key} (Âü∫‰∫é is_mac_determined: {is_mac_determined})")
                logger.info(f"[{req_id}]   - Â∞ùËØïÂ∞ÜÁÑ¶ÁÇπËÆæÁΩÆÂà∞ËæìÂÖ•Ê°Ü...")
                await prompt_textarea_locator.focus(timeout=5000)
                check_client_disconnected("After Input Focus (Shortcut): ")
                await asyncio.sleep(0.1)
                logger.info(f"[{req_id}]   - ÁÑ¶ÁÇπËÆæÁΩÆÂÆåÊàêÔºåÂáÜÂ§áÊåâ‰∏ãÂø´Êç∑ÈîÆ...")
                try:
                    await page.keyboard.press(f'{shortcut_modifier}+{shortcut_key}')
                    logger.info(f"[{req_id}]   - Â∑≤‰ΩøÁî®ÁªÑÂêàÈîÆÊñπÂºèÊ®°ÊãüÊåâ‰∏ã: {shortcut_modifier}+{shortcut_key}")
                except Exception as combo_err:
                    logger.warning(f"[{req_id}]   - ÁªÑÂêàÈîÆÊñπÂºèÂ§±Ë¥•: {combo_err}ÔºåÂ∞ùËØïÂàÜÊ≠•ÊåâÈîÆ...")
                    try:
                        await page.keyboard.down(shortcut_modifier)
                        await asyncio.sleep(0.05)
                        await page.keyboard.down(shortcut_key)
                        await asyncio.sleep(0.05)
                        await page.keyboard.up(shortcut_key)
                        await asyncio.sleep(0.05)
                        await page.keyboard.up(shortcut_modifier)
                        logger.info(f"[{req_id}]   - Â∑≤‰ΩøÁî®ÂàÜÊ≠•ÊåâÈîÆÊñπÂºèÊ®°Êãü: {shortcut_modifier}+{shortcut_key}")
                    except Exception as step_err:
                        logger.error(f"[{req_id}]   - ÂàÜÊ≠•ÊåâÈîÆ‰πüÂ§±Ë¥•: {step_err}")
                check_client_disconnected("After Keyboard Press: ")
                user_prompt_actual_textarea_locator = page.locator(
                    'ms-prompt-input-wrapper textarea[aria-label="Start typing a prompt"]'
                )
                selector_string = 'ms-prompt-input-wrapper textarea[aria-label="Start typing a prompt"]'
                logger.info(f"[{req_id}]   - Áî®‰∫éÂø´Êç∑ÈîÆÂêéÈ™åËØÅÁöÑÁî®Êà∑ËæìÂÖ• textarea ÈÄâÊã©Âô®: '{selector_string}'")
                validation_attempts = 7
                validation_interval = 0.2
                for i in range(validation_attempts):
                    try:
                        current_value = await user_prompt_actual_textarea_locator.input_value(timeout=500)
                        if current_value == "":
                            submitted_successfully_via_shortcut = True
                            logger.info(f"[{req_id}]   - ‚úÖ Âø´Êç∑ÈîÆÊèê‰∫§ÊàêÂäüÁ°ÆËÆ§ (Áî®Êà∑ËæìÂÖ• textarea value Â∑≤Ê∏ÖÁ©∫ after {i+1} attempts)„ÄÇ")
                            break
                        else:
                            if DEBUG_LOGS_ENABLED:
                                logger.debug(f"[{req_id}]   - Áî®Êà∑ËæìÂÖ• textarea value È™åËØÅÂ∞ùËØï {i+1}/{validation_attempts}: ÂΩìÂâç='{current_value}', ÊúüÊúõ=''")
                    except PlaywrightAsyncError as e_val:
                        if DEBUG_LOGS_ENABLED:
                            logger.debug(f"[{req_id}]   - Ëé∑ÂèñÁî®Êà∑ËæìÂÖ• textarea value Êó∂Âá∫Èîô (Â∞ùËØï {i+1}): {e_val.message.splitlines()[0]}")
                        if "timeout" in e_val.message.lower():
                            pass
                        else:
                            logger.warning(f"[{req_id}]   - Ëé∑ÂèñÁî®Êà∑ËæìÂÖ• textarea value Êó∂ Playwright ÈîôËØØ (Â∞ùËØï {i+1}): {e_val.message.splitlines()[0]}")
                            if "strict mode violation" in e_val.message.lower():
                                await save_error_snapshot(f"shortcut_submit_textarea_value_strict_error_{req_id}")
                                break
                            break
                    except Exception as e_gen:
                        logger.warning(f"[{req_id}]   - Ëé∑ÂèñÁî®Êà∑ËæìÂÖ• textarea value Êó∂ÂèëÁîüÂÖ∂‰ªñÈîôËØØ (Â∞ùËØï {i+1}): {e_gen}")
                        break
                    if i < validation_attempts - 1:
                        await asyncio.sleep(validation_interval)
                if not submitted_successfully_via_shortcut:
                    final_value_for_log = "(Êó†Ê≥ïËé∑ÂèñÊàñÊú™Ê∏ÖÁ©∫)"
                    try:
                        final_value_for_log = await user_prompt_actual_textarea_locator.input_value(timeout=300)
                    except:
                        pass
                    logger.warning(f"[{req_id}]   - ‚ö†Ô∏è Âø´Êç∑ÈîÆÊèê‰∫§ÂêéÁî®Êà∑ËæìÂÖ• textarea value ('{final_value_for_log}') Êú™Âú®È¢ÑÊúüÊó∂Èó¥ÂÜÖ ({validation_attempts * validation_interval:.1f}s) Ê∏ÖÁ©∫„ÄÇ")
            except Exception as shortcut_err:
                logger.error(f"[{req_id}]   - ‚ùå Âø´Êç∑ÈîÆÊèê‰∫§ËøáÁ®ã‰∏≠ÂèëÁîüÈîôËØØ: {shortcut_err}", exc_info=True)
                await save_error_snapshot(f"shortcut_submit_error_{req_id}")
                raise PlaywrightAsyncError(f"Failed to submit prompt via keyboard shortcut: {shortcut_err}") from shortcut_err
            if not submitted_successfully_via_shortcut:
                 logger.error(f"[{req_id}] ‰∏•ÈáçÈîôËØØ: Êú™ËÉΩÈÄöËøáÂø´Êç∑ÈîÆÁ°ÆËÆ§Êèê‰∫§„ÄÇ")
                 raise PlaywrightAsyncError("Failed to confirm prompt submission via shortcut.")
        except (PlaywrightAsyncError, asyncio.TimeoutError, ClientDisconnectedError) as submit_err:
            if isinstance(submit_err, ClientDisconnectedError): raise
            logger.error(f"[{req_id}] ‚ùå ÈîôËØØ: Â°´ÂÖÖÊàñÊèê‰∫§ÊèêÁ§∫Êó∂Âá∫Èîô: {submit_err}", exc_info=True)
            await save_error_snapshot(f"submit_prompt_error_{req_id}")
            raise HTTPException(status_code=502, detail=f"[{req_id}] Failed to submit prompt to AI Studio: {submit_err}")
        except Exception as submit_exc:
            logger.exception(f"[{req_id}] ‚ùå ÈîôËØØ: Â°´ÂÖÖÊàñÊèê‰∫§ÊèêÁ§∫Êó∂ÊÑèÂ§ñÈîôËØØ")
            await save_error_snapshot(f"submit_prompt_unexpected_{req_id}")
            raise HTTPException(status_code=500, detail=f"[{req_id}] Unexpected error during prompt submission: {submit_exc}")
        check_client_disconnected("After Submit Logic: ")
        logger.info(f"[{req_id}] (Refactored Process) ÂÆö‰ΩçÂìçÂ∫îÂÖÉÁ¥†...")
        response_container = page.locator(RESPONSE_CONTAINER_SELECTOR).last
        response_element = response_container.locator(RESPONSE_TEXT_SELECTOR)
        try:
            await expect_async(response_container).to_be_attached(timeout=20000)
            check_client_disconnected("After Response Container Attached: ")
            await expect_async(response_element).to_be_attached(timeout=90000)
            logger.info(f"[{req_id}]   - ÂìçÂ∫îÂÖÉÁ¥†Â∑≤ÂÆö‰Ωç„ÄÇ")
        except (PlaywrightAsyncError, asyncio.TimeoutError, ClientDisconnectedError) as locate_err:
            if isinstance(locate_err, ClientDisconnectedError): raise
            logger.error(f"[{req_id}] ‚ùå ÈîôËØØ: ÂÆö‰ΩçÂìçÂ∫îÂÖÉÁ¥†Â§±Ë¥•ÊàñË∂ÖÊó∂: {locate_err}")
            await save_error_snapshot(f"response_locate_error_{req_id}")
            raise HTTPException(status_code=502, detail=f"[{req_id}] Failed to locate AI Studio response element: {locate_err}")
        except Exception as locate_exc:
            logger.exception(f"[{req_id}] ‚ùå ÈîôËØØ: ÂÆö‰ΩçÂìçÂ∫îÂÖÉÁ¥†Êó∂ÊÑèÂ§ñÈîôËØØ")
            await save_error_snapshot(f"response_locate_unexpected_{req_id}")
            raise HTTPException(status_code=500, detail=f"[{req_id}] Unexpected error locating response element: {locate_exc}")
        check_client_disconnected("After Locate Response: ")

        # --- MERGED: Helper logic integration ---
        use_helper = False
        helper_endpoint = os.environ.get('HELPER_ENDPOINT')
        helper_sapisid = os.environ.get('HELPER_SAPISID')
        if helper_endpoint and helper_sapisid:
            logger.info(f"[{req_id}] Ê£ÄÊµãÂà∞ Helper ÈÖçÁΩÆÔºåÂ∞ÜÂ∞ùËØï‰ΩøÁî® Helper ÊúçÂä°Ëé∑ÂèñÂìçÂ∫î„ÄÇ")
            use_helper = True
        else:
            logger.info(f"[{req_id}] Êú™Ê£ÄÊµãÂà∞ÂÆåÊï¥ÁöÑ Helper ÈÖçÁΩÆÔºåÂ∞Ü‰ΩøÁî® Playwright È°µÈù¢‰∫§‰∫íËé∑ÂèñÂìçÂ∫î„ÄÇ")

        if use_helper:
            try:
                if is_streaming:
                    completion_event = Event()
                    async def create_stream_generator_from_helper(event_to_set: Event) -> AsyncGenerator[str, None]:
                        try:
                            async for data_chunk in use_helper_get_response(helper_endpoint, helper_sapisid):
                                if client_disconnected_event.is_set():
                                    logger.info(f"[{req_id}] (Helper Stream Gen) ÂÆ¢Êà∑Á´ØÊñ≠ÂºÄÔºåÂÅúÊ≠¢„ÄÇ")
                                    break
                                if data_chunk == "[ERROR]": # Helper indicated an error
                                    logger.error(f"[{req_id}] (Helper Stream Gen) Helper ÊúçÂä°ËøîÂõûÈîôËØØ‰ø°Âè∑„ÄÇ")
                                    yield generate_sse_error_chunk("Helper service reported an error.", req_id, "helper_error")
                                    break 
                                if data_chunk == "[DONE]": # Helper indicated completion
                                    logger.info(f"[{req_id}] (Helper Stream Gen) Helper ÊúçÂä°ÊåáÁ§∫ÂÆåÊàê„ÄÇ")
                                    break
                                yield f"data: {data_chunk}\n\n" # Assume helper sends pre-formatted SSE data chunks
                            yield "data: [DONE]\n\n" # Ensure final DONE is sent
                        except Exception as e_helper_stream:
                            logger.error(f"[{req_id}] (Helper Stream Gen) ‰ªé Helper Ëé∑ÂèñÊµÅÂºèÊï∞ÊçÆÊó∂Âá∫Èîô: {e_helper_stream}", exc_info=True)
                            yield generate_sse_error_chunk(f"Error streaming from helper: {e_helper_stream}", req_id)
                            yield "data: [DONE]\n\n"
                        finally:
                            if not event_to_set.is_set(): event_to_set.set()
                    
                    stream_gen_func = create_stream_generator_from_helper(completion_event)
                    if not result_future.done():
                        result_future.set_result(StreamingResponse(stream_gen_func, media_type="text/event-stream"))
                    else:
                        if not completion_event.is_set(): completion_event.set() # Ensure event is set if future already done
                    return completion_event # Return the event for the worker to wait on
                else: # Non-streaming with helper
                    full_response_content = ""
                    think_content = ""
                    body_content = ""
                    async for data_chunk in use_helper_get_response(helper_endpoint, helper_sapisid):
                        if data_chunk == "[ERROR]":
                            raise HTTPException(status_code=502, detail=f"[{req_id}] Helper service reported an error during non-streaming fetch.")
                        if data_chunk == "[DONE]":
                            break
                        try:
                            # Assuming helper sends OpenAI-like delta chunks even for non-streaming,
                            # and we need to aggregate them.
                            stream_data = json.loads(data_chunk)
                            if "choices" in stream_data and stream_data["choices"]:
                                delta = stream_data["choices"][0].get("delta", {})
                                if "reasoning_content" in delta: # Example for structured content
                                    think_content += delta["reasoning_content"]
                                elif "content" in delta:
                                    body_content += delta["content"]
                        except json.JSONDecodeError:
                            logger.warning(f"[{req_id}] (Helper Non-Stream) Êó†Ê≥ïËß£ÊûêÊù•Ëá™ Helper ÁöÑ JSON Êï∞ÊçÆÂùó: {data_chunk}")
                            body_content += data_chunk # Fallback: append raw if not JSON
                    
                    if think_content:
                        full_response_content = f"<think>{think_content}</think>\n{body_content}"
                    else:
                        full_response_content = body_content
                    
                    response_payload = {
                        "id": f"{CHAT_COMPLETION_ID_PREFIX}{req_id}-{int(time.time())}",
                        "object": "chat.completion", "created": int(time.time()), "model": MODEL_NAME,
                        "choices": [{"index": 0, "message": {"role": "assistant", "content": full_response_content}, "finish_reason": "stop"}],
                        "usage": {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}
                    }
                    if not result_future.done():
                        result_future.set_result(JSONResponse(content=response_payload))
                    return None # No event for non-streaming
            except Exception as e_helper:
                logger.error(f"[{req_id}] ‰ΩøÁî® Helper ÊúçÂä°Êó∂ÂèëÁîüÈîôËØØ: {e_helper}„ÄÇÂ∞ÜÂõûÈÄÄÂà∞ Playwright È°µÈù¢‰∫§‰∫í„ÄÇ", exc_info=True)
                use_helper = False # Fallback to Playwright
        
        # --- Fallback to Playwright page interaction if helper is not used or failed ---
        if not use_helper:
            logger.info(f"[{req_id}] (Refactored Process) Á≠âÂæÖÂìçÂ∫îÁîüÊàêÂÆåÊàêÊàñÊ£ÄÊµãÊ®°ÂûãÈîôËØØ...")
            MODEL_ERROR_CONTAINER_SELECTOR = 'ms-chat-turn:last-child div.model-error'
            completion_detected_via_edit_button = False
            page_model_error_message: Optional[str] = None
            completion_detected_via_edit_button = await _wait_for_response_completion(
                page, req_id, response_element, None, check_client_disconnected, None
            )
            check_client_disconnected("After _wait_for_response_completion attempt: ")
            if not completion_detected_via_edit_button:
                logger.info(f"[{req_id}] _wait_for_response_completion Êú™ÈÄöËøáÁºñËæëÊåâÈíÆÁ°ÆËÆ§ÂÆåÊàêÔºåÊ£ÄÊü•ÊòØÂê¶Â≠òÂú®Ê®°ÂûãÈîôËØØ...")
                try:
                    error_container_locator = page.locator(MODEL_ERROR_CONTAINER_SELECTOR)
                    await expect_async(error_container_locator).to_be_visible(timeout=2000)
                    specific_error_text_locator = error_container_locator.locator('*:not(mat-icon)')
                    try:
                        page_model_error_message = await specific_error_text_locator.first.text_content(timeout=500)
                        if page_model_error_message: page_model_error_message = page_model_error_message.strip()
                    except PlaywrightAsyncError:
                        page_model_error_message = await error_container_locator.text_content(timeout=500)
                        if page_model_error_message: page_model_error_message = page_model_error_message.strip()
                    if page_model_error_message:
                        logger.error(f"[{req_id}] ‚ùå Ê£ÄÊµãÂà∞ AI Studio Ê®°ÂûãËøîÂõûÁöÑÈîôËØØ‰ø°ÊÅØ: {page_model_error_message}")
                        await save_error_snapshot(f"model_returned_error_{req_id}")
                        raise HTTPException(status_code=502, detail=f"[{req_id}] AI Studio Model Error: {page_model_error_message}")
                    else:
                        logger.warning(f"[{req_id}] Ê£ÄÊµãÂà∞ model-error ÂÆπÂô®Ôºå‰ΩÜÊú™ËÉΩÊèêÂèñÂÖ∑‰ΩìÈîôËØØÊñáÊú¨„ÄÇ")
                        await save_error_snapshot(f"model_error_container_no_text_{req_id}")
                        raise HTTPException(status_code=502, detail=f"[{req_id}] AI Studio returned an unspecified model error (error container found).")
                except (PlaywrightAsyncError, asyncio.TimeoutError) as e_model_err_check:
                    logger.info(f"[{req_id}] Êú™Ê£ÄÊµãÂà∞ÊòéÁ°ÆÁöÑ model-error ÂÆπÂô® (ÊàñÊ£ÄÊü•Ë∂ÖÊó∂: {type(e_model_err_check).__name__})„ÄÇÁªßÁª≠ÊåâÂéüË∂ÖÊó∂ÈÄªËæëÂ§ÑÁêÜ„ÄÇ")
                    if not completion_detected_via_edit_button:
                         raise HTTPException(status_code=504, detail=f"[{req_id}] AI Studio response generation timed out (and no specific model error detected).")
            if not completion_detected_via_edit_button:
                logger.info(f"[{req_id}] (Refactored Process) Ê£ÄÊü•È°µÈù¢ Toast ÈîôËØØÊèêÁ§∫...")
                page_toast_error = await detect_and_extract_page_error(page, req_id)
                if page_toast_error:
                    logger.error(f"[{req_id}] ‚ùå ÈîôËØØ: AI Studio È°µÈù¢ËøîÂõû Toast ÈîôËØØ: {page_toast_error}")
                    await save_error_snapshot(f"page_toast_error_detected_{req_id}")
                    raise HTTPException(status_code=502, detail=f"[{req_id}] AI Studio Page Error: {page_toast_error}")
                check_client_disconnected("After Page Toast Error Check: ")
            else:
                logger.info(f"[{req_id}] Â∑≤ÈÄöËøáÁºñËæëÊåâÈíÆÁ°ÆËÆ§ÂÆåÊàêÔºåË∑≥Ëøá Toast ÈîôËØØÊ£ÄÊü•„ÄÇ")
            if not completion_detected_via_edit_button:
                logger.error(f"[{req_id}] ÈÄªËæëÂºÇÂ∏∏ÔºöÂìçÂ∫îÊú™ÂÆåÊàêÔºå‰πüÊú™Ê£ÄÊµãÂà∞Ê®°ÂûãÈîôËØØÔºå‰ΩÜ‰∏çÂ∫îÂà∞ËææÊ≠§Â§ÑËé∑ÂèñÂÜÖÂÆπ„ÄÇ")
                raise HTTPException(status_code=500, detail=f"[{req_id}] Internal logic error in response processing.")
            logger.info(f"[{req_id}] (Refactored Process) Ëé∑ÂèñÊúÄÁªàÂìçÂ∫îÂÜÖÂÆπ...")
            final_content = await _get_final_response_content(
                page, req_id, check_client_disconnected
            )
            if final_content is None:
                try:
                    error_container_locator = page.locator(MODEL_ERROR_CONTAINER_SELECTOR)
                    if await error_container_locator.is_visible(timeout=500):
                        late_error_message = await error_container_locator.text_content(timeout=300) or "Unknown model error after content fetch attempt."
                        logger.error(f"[{req_id}] Ëé∑ÂèñÂÜÖÂÆπÂ§±Ë¥•ÂêéÔºåÊ£ÄÊµãÂà∞Âª∂ËøüÂá∫Áé∞ÁöÑÊ®°ÂûãÈîôËØØ: {late_error_message.strip()}")
                        raise HTTPException(status_code=502, detail=f"[{req_id}] AI Studio Model Error (detected after content fetch failure): {late_error_message.strip()}")
                except:
                    pass
                raise HTTPException(status_code=500, detail=f"[{req_id}] Failed to extract final response content from AI Studio.")
            check_client_disconnected("After Get Content: ")
            logger.info(f"[{req_id}] (Refactored Process) Ê†ºÂºèÂåñÂπ∂ËÆæÁΩÆÁªìÊûú (Ê®°Âºè: {'ÊµÅÂºè' if is_streaming else 'ÈùûÊµÅÂºè'})...")
            if is_streaming:
                completion_event = Event()
                async def create_stream_generator(event_to_set: Event, content_to_stream: str) -> AsyncGenerator[str, None]:
                    logger.info(f"[{req_id}] (Stream Gen) ÂºÄÂßã‰º™ÊµÅÂºèËæìÂá∫ ({len(content_to_stream)} chars)...")
                    try:
                        total_chars = len(content_to_stream)
                        chunk_size = 5
                        for i in range(0, total_chars, chunk_size):
                            if client_disconnected_event.is_set():
                                logger.info(f"[{req_id}] (Stream Gen) Êñ≠ÂºÄËøûÊé•ÔºåÂÅúÊ≠¢„ÄÇ")
                                break
                            chunk = content_to_stream[i:i + chunk_size]
                            if not chunk:
                                continue
                            yield generate_sse_chunk(chunk, req_id, MODEL_NAME)
                            await asyncio.sleep(PSEUDO_STREAM_DELAY)
                        yield generate_sse_stop_chunk(req_id, MODEL_NAME)
                        yield "data: [DONE]\n\n"
                        logger.info(f"[{req_id}] (Stream Gen) ‚úÖ ‰º™ÊµÅÂºèÂìçÂ∫îÂèëÈÄÅÂÆåÊØï„ÄÇ")
                    except asyncio.CancelledError:
                        logger.info(f"[{req_id}] (Stream Gen) ÊµÅÁîüÊàêÂô®Ë¢´ÂèñÊ∂à„ÄÇ")
                    except Exception as e:
                        logger.exception(f"[{req_id}] (Stream Gen) ‚ùå ‰º™ÊµÅÂºèÁîüÊàêËøáÁ®ã‰∏≠Âá∫Èîô")
                        try: yield generate_sse_error_chunk(f"Stream generation error: {e}", req_id); yield "data: [DONE]\n\n"
                        except: pass
                    finally:
                        logger.info(f"[{req_id}] (Stream Gen) ËÆæÁΩÆÂÆåÊàê‰∫ã‰ª∂„ÄÇ")
                        if not event_to_set.is_set(): event_to_set.set()
                stream_generator_func = create_stream_generator(completion_event, final_content)
                if not result_future.done():
                    result_future.set_result(StreamingResponse(stream_generator_func, media_type="text/event-stream"))
                    logger.info(f"[{req_id}] (Refactored Process) ÊµÅÂºèÂìçÂ∫îÁîüÊàêÂô®Â∑≤ËÆæÁΩÆ„ÄÇ")
                else:
                    logger.warning(f"[{req_id}] (Refactored Process) Future Â∑≤ÂÆåÊàê/ÂèñÊ∂àÔºåÊó†Ê≥ïËÆæÁΩÆÊµÅÂºèÁªìÊûú„ÄÇ")
                    if not completion_event.is_set(): completion_event.set()
                return completion_event
            else:
                response_payload = {
                    "id": f"{CHAT_COMPLETION_ID_PREFIX}{req_id}-{int(time.time())}",
                    "object": "chat.completion", "created": int(time.time()), "model": MODEL_NAME,
                    "choices": [{"index": 0, "message": {"role": "assistant", "content": final_content}, "finish_reason": "stop"}],
                    "usage": {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}
                }
                if not result_future.done():
                    result_future.set_result(JSONResponse(content=response_payload))
                    logger.info(f"[{req_id}] (Refactored Process) ÈùûÊµÅÂºè JSON ÂìçÂ∫îÂ∑≤ËÆæÁΩÆ„ÄÇ")
                else:
                    logger.warning(f"[{req_id}] (Refactored Process) Future Â∑≤ÂÆåÊàê/ÂèñÊ∂àÔºåÊó†Ê≥ïËÆæÁΩÆ JSON ÁªìÊûú„ÄÇ")
                return None
    except ClientDisconnectedError as disco_err:
        logger.info(f"[{req_id}] (Refactored Process) ÊçïËé∑Âà∞ÂÆ¢Êà∑Á´ØÊñ≠ÂºÄËøûÊé•‰ø°Âè∑: {disco_err}")
        if not result_future.done():
             result_future.set_exception(HTTPException(status_code=499, detail=f"[{req_id}] Client disconnected during processing."))
    except HTTPException as http_err:
        logger.warning(f"[{req_id}] (Refactored Process) ÊçïËé∑Âà∞ HTTP ÂºÇÂ∏∏: {http_err.status_code} - {http_err.detail}")
        if not result_future.done(): result_future.set_exception(http_err)
    except PlaywrightAsyncError as pw_err:
        logger.error(f"[{req_id}] (Refactored Process) ÊçïËé∑Âà∞ Playwright ÈîôËØØ: {pw_err}")
        await save_error_snapshot(f"process_playwright_error_{req_id}")
        if not result_future.done(): result_future.set_exception(HTTPException(status_code=502, detail=f"[{req_id}] Playwright interaction failed: {pw_err}"))
    except asyncio.TimeoutError as timeout_err:
        logger.error(f"[{req_id}] (Refactored Process) ÊçïËé∑Âà∞Êìç‰ΩúË∂ÖÊó∂: {timeout_err}")
        await save_error_snapshot(f"process_timeout_error_{req_id}")
        if not result_future.done(): result_future.set_exception(HTTPException(status_code=504, detail=f"[{req_id}] Operation timed out: {timeout_err}"))
    except asyncio.CancelledError:
        logger.info(f"[{req_id}] (Refactored Process) ‰ªªÂä°Ë¢´ÂèñÊ∂à„ÄÇ")
        if not result_future.done(): result_future.cancel("Processing task cancelled")
    except Exception as e:
        logger.exception(f"[{req_id}] (Refactored Process) ÊçïËé∑Âà∞ÊÑèÂ§ñÈîôËØØ")
        await save_error_snapshot(f"process_unexpected_error_{req_id}")
        if not result_future.done(): result_future.set_exception(HTTPException(status_code=500, detail=f"[{req_id}] Unexpected server error: {e}"))
    finally:
        if disconnect_check_task and not disconnect_check_task.done():
            disconnect_check_task.cancel()
            try: await disconnect_check_task
            except asyncio.CancelledError: pass
            except Exception as task_clean_err: logger.error(f"[{req_id}] Ê∏ÖÁêÜ‰ªªÂä°Êó∂Âá∫Èîô: {task_clean_err}")
        logger.info(f"[{req_id}] (Refactored Process) Â§ÑÁêÜÂÆåÊàê„ÄÇ")
        if is_streaming and completion_event and not completion_event.is_set() and (result_future.done() and result_future.exception() is not None):
             logger.warning(f"[{req_id}] (Refactored Process) ÊµÅÂºèËØ∑Ê±ÇÂºÇÂ∏∏ÔºåÁ°Æ‰øùÂÆåÊàê‰∫ã‰ª∂Â∑≤ËÆæÁΩÆ„ÄÇ")
             completion_event.set()
        return completion_event

# --- Main Chat Endpoint ---
@app.post("/v1/chat/completions")
async def chat_completions(request: ChatCompletionRequest, http_request: Request):
    req_id = ''.join(random.choices('abcdefghijklmnopqrstuvwxyz0123456789', k=7))
    logger.info(f"[{req_id}] Êî∂Âà∞ /v1/chat/completions ËØ∑Ê±Ç (Stream={request.stream})")
    logger.debug(f"[{req_id}] ÂÆåÊï¥ËØ∑Ê±ÇÂèÇÊï∞: {request.model_dump_json(indent=2)}")
    launch_mode = os.environ.get('LAUNCH_MODE', 'unknown')
    browser_page_critical = launch_mode != "direct_debug_no_browser"
    service_unavailable = is_initializing or \
                          not is_playwright_ready or \
                          (browser_page_critical and (not is_page_ready or not is_browser_connected)) or \
                          not worker_task or worker_task.done()
    if service_unavailable:
        status_code = 503
        error_details = []
        if is_initializing: error_details.append("ÂàùÂßãÂåñËøõË°å‰∏≠")
        if not is_playwright_ready: error_details.append("Playwright Êú™Â∞±Áª™")
        if browser_page_critical:
            if not is_browser_connected: error_details.append("ÊµèËßàÂô®Êú™ËøûÊé•")
            if not is_page_ready: error_details.append("È°µÈù¢Êú™Â∞±Áª™")
        if not worker_task or worker_task.done(): error_details.append("Worker Êú™ËøêË°å")
        detail = f"[{req_id}] ÊúçÂä°ÂΩìÂâç‰∏çÂèØÁî® ({', '.join(error_details)}). ËØ∑Á®çÂêéÈáçËØï."
        logger.error(f"[{req_id}] ÊúçÂä°‰∏çÂèØÁî®ËØ¶ÊÉÖ: {detail}")
        raise HTTPException(status_code=status_code, detail=detail, headers={"Retry-After": "30"})
    result_future = Future()
    request_item = {
        "req_id": req_id, "request_data": request, "http_request": http_request,
        "result_future": result_future, "enqueue_time": time.time(), "cancelled": False
    }
    await request_queue.put(request_item)
    logger.info(f"[{req_id}] ËØ∑Ê±ÇÂ∑≤Âä†ÂÖ•ÈòüÂàó (ÂΩìÂâçÈòüÂàóÈïøÂ∫¶: {request_queue.qsize()})")
    try:
        timeout_seconds = RESPONSE_COMPLETION_TIMEOUT / 1000 + 120
        result = await asyncio.wait_for(result_future, timeout=timeout_seconds)
        logger.info(f"[{req_id}] Worker Â§ÑÁêÜÂÆåÊàêÔºåËøîÂõûÁªìÊûú„ÄÇ")
        return result
    except asyncio.TimeoutError:
        logger.error(f"[{req_id}] ‚ùå Á≠âÂæÖ Worker ÂìçÂ∫îË∂ÖÊó∂ ({timeout_seconds}s)„ÄÇ")
        raise HTTPException(status_code=504, detail=f"[{req_id}] Request processing timed out waiting for worker response.")
    except asyncio.CancelledError:
        logger.info(f"[{req_id}] ËØ∑Ê±Ç Future Ë¢´ÂèñÊ∂à (ÂèØËÉΩÁî±ÂÆ¢Êà∑Á´ØÊñ≠ÂºÄËøûÊé•Ëß¶Âèë)„ÄÇ")
        if not result_future.done() or result_future.exception() is None:
             raise HTTPException(status_code=499, detail=f"[{req_id}] Request cancelled by client or server.")
        else:
             raise result_future.exception()
    except HTTPException as http_err:
        raise http_err
    except Exception as e:
        logger.exception(f"[{req_id}] ‚ùå Á≠âÂæÖ Worker ÂìçÂ∫îÊó∂ÂèëÁîüÊÑèÂ§ñÈîôËØØ")
        raise HTTPException(status_code=500, detail=f"[{req_id}] Unexpected error waiting for worker response: {e}")

# --- Cancel Request Endpoint ---
async def cancel_queued_request(req_id: str) -> bool:
    cancelled = False
    items_to_requeue = []
    found = False
    try:
        while True:
            item = request_queue.get_nowait()
            if item.get("req_id") == req_id and not item.get("cancelled", False):
                logger.info(f"[{req_id}] Âú®ÈòüÂàó‰∏≠ÊâæÂà∞ËØ∑Ê±ÇÔºåÊ†áËÆ∞‰∏∫Â∑≤ÂèñÊ∂à„ÄÇ")
                item["cancelled"] = True
                item_future = item.get("result_future")
                if item_future and not item_future.done():
                    item_future.set_exception(HTTPException(status_code=499, detail=f"[{req_id}] Request cancelled by API call."))
                items_to_requeue.append(item)
                cancelled = True
                found = True
            else:
                items_to_requeue.append(item)
    except asyncio.QueueEmpty:
        pass
    finally:
        for item in items_to_requeue:
            await request_queue.put(item)
    return cancelled

@app.post("/v1/cancel/{req_id}")
async def cancel_request(req_id: str):
    logger.info(f"[{req_id}] Êî∂Âà∞ÂèñÊ∂àËØ∑Ê±Ç„ÄÇ")
    cancelled = await cancel_queued_request(req_id)
    if cancelled:
        return JSONResponse(content={"success": True, "message": f"Request {req_id} marked as cancelled in queue."})
    else:
        return JSONResponse(
            content={"success": False, "message": f"Request {req_id} not found in queue (it might be processing or already finished)."},
            status_code=404
        )

@app.get("/v1/queue")
async def get_queue_status():
    queue_items = []
    items_to_requeue = []
    try:
        while True:
            item = request_queue.get_nowait()
            items_to_requeue.append(item)
            req_id = item.get("req_id", "unknown")
            timestamp = item.get("enqueue_time", 0)
            is_streaming = item.get("request_data").stream if hasattr(item.get("request_data", {}), "stream") else False
            cancelled = item.get("cancelled", False)
            queue_items.append({
                "req_id": req_id, "enqueue_time": timestamp,
                "wait_time_seconds": round(time.time() - timestamp, 2) if timestamp else None,
                "is_streaming": is_streaming, "cancelled": cancelled
            })
    except asyncio.QueueEmpty:
        pass
    finally:
        for item in items_to_requeue:
            await request_queue.put(item)
    return JSONResponse(content={
        "queue_length": len(queue_items),
        "is_processing_locked": processing_lock.locked(),
        "items": sorted(queue_items, key=lambda x: x.get("enqueue_time", 0))
    })

@app.websocket("/ws/logs")
async def websocket_log_endpoint(websocket: WebSocket):
    if not log_ws_manager:
        try:
            await websocket.accept()
            await websocket.send_text(json.dumps({
                "type": "error", "status": "disconnected",
                "message": "Êó•ÂøóÊúçÂä°ÂÜÖÈÉ®ÈîôËØØ (ÁÆ°ÁêÜÂô®Êú™ÂàùÂßãÂåñ)„ÄÇ",
                "timestamp": datetime.datetime.now().isoformat()}))
            await websocket.close(code=1011)
        except Exception: pass
        return
    client_id = str(uuid.uuid4())
    try:
        await log_ws_manager.connect(client_id, websocket)
        while True:
            data = await websocket.receive_text()
            if data.lower() == "ping":
                 await websocket.send_text(json.dumps({"type": "pong", "timestamp": datetime.datetime.now().isoformat()}))
    except WebSocketDisconnect:
        pass
    except Exception as e:
        logger.error(f"Êó•Âøó WebSocket (ÂÆ¢Êà∑Á´Ø {client_id}) ÂèëÁîüÂºÇÂ∏∏: {e}", exc_info=True)
    finally:
        if log_ws_manager:
            log_ws_manager.disconnect(client_id)

# --- Main Guard ---
if __name__ == "__main__":
    print("ÈîôËØØ: server.py ‰∏çÂ∫îÁõ¥Êé•‰Ωú‰∏∫‰∏ªËÑöÊú¨ËøêË°å„ÄÇ", file=sys.stderr)
    print("ËØ∑‰ΩøÁî® launch_camoufox.py (Áî®‰∫éË∞ÉËØï) Êàñ start.py (Áî®‰∫éÂêéÂè∞ÊúçÂä°) Êù•ÂêØÂä®„ÄÇ", file=sys.stderr)
    print("\nÂ¶ÇÊûúÁ°ÆÂÆûÈúÄË¶ÅÁõ¥Êé•ËøêË°å server.py ËøõË°åÂ∫ïÂ±ÇÊµãËØï (‰∏çÊé®Ëçê):", file=sys.stderr)
    print("  1. Á°Æ‰øùÂ∑≤ËÆæÁΩÆÂøÖË¶ÅÁöÑÁéØÂ¢ÉÂèòÈáèÔºåÂ¶Ç CAMOUFOX_WS_ENDPOINT, LAUNCH_MODE, SERVER_REDIRECT_PRINT, SERVER_LOG_LEVEL„ÄÇ", file=sys.stderr)
    print("  2. ÁÑ∂ÂêéÂèØ‰ª•Â∞ùËØï: python -m uvicorn server:app --host 0.0.0.0 --port <Á´ØÂè£Âè∑>", file=sys.stderr)
    print("     ‰æãÂ¶Ç: LAUNCH_MODE=direct_debug_no_browser SERVER_REDIRECT_PRINT=false python -m uvicorn server:app --port 8000", file=sys.stderr)
    sys.exit(1)

# --- Model Switching Helper ---
async def switch_ai_studio_model(page: AsyncPage, model_id: str, req_id: str) -> bool:
    logger.info(f"[{req_id}] ÂºÄÂßãÂàáÊç¢Ê®°ÂûãÂà∞: {model_id}")
    original_prefs_str: Optional[str] = None
    original_prompt_model: Optional[str] = None
    new_chat_url = f"https://{AI_STUDIO_URL_PATTERN}prompts/new_chat"
    try:
        original_prefs_str = await page.evaluate("() => localStorage.getItem('aiStudioUserPreference')")
        if original_prefs_str:
            try:
                original_prefs_obj = json.loads(original_prefs_str)
                original_prompt_model = original_prefs_obj.get("promptModel")
                logger.info(f"[{req_id}] ÂàáÊç¢Ââç localStorage.promptModel ‰∏∫: {original_prompt_model or 'Êú™ËÆæÁΩÆ'}")
            except json.JSONDecodeError:
                logger.warning(f"[{req_id}] Êó†Ê≥ïËß£ÊûêÂéüÂßãÁöÑ aiStudioUserPreference JSON Â≠óÁ¨¶‰∏≤„ÄÇ")
                original_prefs_str = None
        current_prefs_for_modification = json.loads(original_prefs_str) if original_prefs_str else {}
        full_model_path = f"models/{model_id}"
        if current_prefs_for_modification.get("promptModel") == full_model_path:
            logger.info(f"[{req_id}] Ê®°ÂûãÂ∑≤ÁªèËÆæÁΩÆ‰∏∫ {model_id} (localStorage ‰∏≠Â∑≤ÊòØÁõÆÊ†áÂÄº)ÔºåÊó†ÈúÄÂàáÊç¢")
            if page.url != new_chat_url:
                 logger.info(f"[{req_id}] ÂΩìÂâç URL ‰∏çÊòØ new_chat ({page.url})ÔºåÂØºËà™Âà∞ {new_chat_url}")
                 await page.goto(new_chat_url, wait_until="domcontentloaded", timeout=30000)
                 await expect_async(page.locator(INPUT_SELECTOR)).to_be_visible(timeout=30000)
            return True
        logger.info(f"[{req_id}] ‰ªé {current_prefs_for_modification.get('promptModel', 'Êú™Áü•')} Êõ¥Êñ∞ localStorage.promptModel ‰∏∫ {full_model_path}")
        current_prefs_for_modification["promptModel"] = full_model_path
        await page.evaluate("(prefsStr) => localStorage.setItem('aiStudioUserPreference', prefsStr)", json.dumps(current_prefs_for_modification))
        logger.info(f"[{req_id}] localStorage Â∑≤Êõ¥Êñ∞ÔºåÂØºËà™Âà∞ '{new_chat_url}' Â∫îÁî®Êñ∞Ê®°Âûã...")
        await page.goto(new_chat_url, wait_until="domcontentloaded", timeout=30000)
        input_field = page.locator(INPUT_SELECTOR)
        await expect_async(input_field).to_be_visible(timeout=30000)
        logger.info(f"[{req_id}] È°µÈù¢Â∑≤ÂØºËà™Âà∞Êñ∞ËÅäÂ§©Âπ∂Âä†ËΩΩÂÆåÊàêÔºåËæìÂÖ•Ê°ÜÂèØËßÅ")
        final_prefs_str = await page.evaluate("() => localStorage.getItem('aiStudioUserPreference')")
        final_prompt_model_in_storage: Optional[str] = None
        if final_prefs_str:
            try:
                final_prefs_obj = json.loads(final_prefs_str)
                final_prompt_model_in_storage = final_prefs_obj.get("promptModel")
            except json.JSONDecodeError:
                logger.warning(f"[{req_id}] Êó†Ê≥ïËß£ÊûêÂà∑Êñ∞ÂêéÁöÑ aiStudioUserPreference JSON Â≠óÁ¨¶‰∏≤„ÄÇ")
        if final_prompt_model_in_storage == full_model_path:
            logger.info(f"[{req_id}] ‚úÖ AI Studio localStorage ‰∏≠Ê®°ÂûãÂ∑≤ÊàêÂäüËÆæÁΩÆ‰∏∫: {full_model_path}")
            page_display_match = False
            expected_display_name_for_target_id = None
            actual_displayed_model_name_on_page = "Êó†Ê≥ïËØªÂèñ"
            if parsed_model_list:
                for m_obj in parsed_model_list:
                    if m_obj.get("id") == model_id:
                        expected_display_name_for_target_id = m_obj.get("display_name")
                        break
            if not expected_display_name_for_target_id:
                logger.warning(f"[{req_id}] Êó†Ê≥ïÂú®parsed_model_list‰∏≠ÊâæÂà∞ÁõÆÊ†áID '{model_id}' ÁöÑÊòæÁ§∫ÂêçÁß∞ÔºåË∑≥ËøáÈ°µÈù¢ÊòæÁ§∫ÂêçÁß∞È™åËØÅ„ÄÇËøôÂèØËÉΩ‰∏çÂáÜÁ°Æ„ÄÇ")
                page_display_match = True
            else:
                try:
                    model_name_locator = page.locator('mat-select[data-test-ms-model-selector] div.model-option-content span.gmat-body-medium')
                    actual_displayed_model_name_on_page_raw = await model_name_locator.first.inner_text(timeout=5000)
                    actual_displayed_model_name_on_page = actual_displayed_model_name_on_page_raw.strip()
                    normalized_actual_display = actual_displayed_model_name_on_page.lower()
                    normalized_expected_display = expected_display_name_for_target_id.strip().lower()
                    if normalized_actual_display == normalized_expected_display:
                        page_display_match = True
                        logger.info(f"[{req_id}] ‚úÖ È°µÈù¢ÊòæÁ§∫Ê®°Âûã ('{actual_displayed_model_name_on_page}') ‰∏éÊúüÊúõ ('{expected_display_name_for_target_id}') ‰∏ÄËá¥„ÄÇ")
                    else:
                        logger.error(f"[{req_id}] ‚ùå È°µÈù¢ÊòæÁ§∫Ê®°Âûã ('{actual_displayed_model_name_on_page}') ‰∏éÊúüÊúõ ('{expected_display_name_for_target_id}') ‰∏ç‰∏ÄËá¥„ÄÇ(Raw page: '{actual_displayed_model_name_on_page_raw}')")
                except Exception as e_disp:
                    logger.warning(f"[{req_id}] ËØªÂèñÈ°µÈù¢ÊòæÁ§∫ÁöÑÂΩìÂâçÊ®°ÂûãÂêçÁß∞Êó∂Âá∫Èîô: {e_disp}„ÄÇÂ∞ÜÊó†Ê≥ïÈ™åËØÅÈ°µÈù¢ÊòæÁ§∫„ÄÇ")
            if page_display_match:
                return True
            else:
                logger.error(f"[{req_id}] ‚ùå Ê®°ÂûãÂàáÊç¢Â§±Ë¥•ÔºåÂõ†‰∏∫È°µÈù¢ÊòæÁ§∫ÁöÑÊ®°Âûã‰∏éÊúüÊúõ‰∏çÁ¨¶ (Âç≥‰ΩølocalStorageÂèØËÉΩÂ∑≤Êõ¥Êîπ)„ÄÇ")
        else:
            logger.error(f"[{req_id}] ‚ùå AI Studio Êú™Êé•ÂèóÊ®°ÂûãÊõ¥Êîπ (localStorage)„ÄÇÊúüÊúõ='{full_model_path}', ÂÆûÈôÖ='{final_prompt_model_in_storage or 'Êú™ËÆæÁΩÆÊàñÊó†Êïà'}'.")
        logger.info(f"[{req_id}] Ê®°ÂûãÂàáÊç¢Â§±Ë¥•„ÄÇÂ∞ùËØïÊÅ¢Â§çÂà∞È°µÈù¢ÂΩìÂâçÂÆûÈôÖÊòæÁ§∫ÁöÑÊ®°ÂûãÁöÑÁä∂ÊÄÅ...")
        current_displayed_name_for_revert_raw = "Êó†Ê≥ïËØªÂèñ"
        current_displayed_name_for_revert_stripped = "Êó†Ê≥ïËØªÂèñ"
        try:
            model_name_locator_revert = page.locator('mat-select[data-test-ms-model-selector] div.model-option-content span.gmat-body-medium')
            current_displayed_name_for_revert_raw = await model_name_locator_revert.first.inner_text(timeout=5000)
            current_displayed_name_for_revert_stripped = current_displayed_name_for_revert_raw.strip()
            logger.info(f"[{req_id}] ÊÅ¢Â§çÔºöÈ°µÈù¢ÂΩìÂâçÊòæÁ§∫ÁöÑÊ®°ÂûãÂêçÁß∞ (ÂéüÂßã: '{current_displayed_name_for_revert_raw}', Ê∏ÖÁêÜÂêé: '{current_displayed_name_for_revert_stripped}')")
        except Exception as e_read_disp_revert:
            logger.warning(f"[{req_id}] ÊÅ¢Â§çÔºöËØªÂèñÈ°µÈù¢ÂΩìÂâçÊòæÁ§∫Ê®°ÂûãÂêçÁß∞Â§±Ë¥•: {e_read_disp_revert}„ÄÇÂ∞ÜÂ∞ùËØïÂõûÈÄÄÂà∞ÂéüÂßãlocalStorage„ÄÇ")
            if original_prefs_str:
                logger.info(f"[{req_id}] ÊÅ¢Â§çÔºöÁî±‰∫éÊó†Ê≥ïËØªÂèñÂΩìÂâçÈ°µÈù¢ÊòæÁ§∫ÔºåÂ∞ùËØïÂ∞Ü localStorage ÊÅ¢Â§çÂà∞ÂéüÂßãÁä∂ÊÄÅ: '{original_prompt_model or 'Êú™ËÆæÁΩÆ'}'")
                await page.evaluate("(origPrefs) => localStorage.setItem('aiStudioUserPreference', origPrefs)", original_prefs_str)
                logger.info(f"[{req_id}] ÊÅ¢Â§çÔºöÂØºËà™Âà∞ '{new_chat_url}' ‰ª•Â∫îÁî®ÊÅ¢Â§çÁöÑÂéüÂßã localStorage ËÆæÁΩÆ...")
                await page.goto(new_chat_url, wait_until="domcontentloaded", timeout=20000)
                await expect_async(page.locator(INPUT_SELECTOR)).to_be_visible(timeout=20000)
                logger.info(f"[{req_id}] ÊÅ¢Â§çÔºöÈ°µÈù¢Â∑≤ÂØºËà™Âà∞Êñ∞ËÅäÂ§©Âπ∂Âä†ËΩΩÔºåÂ∑≤Â∞ùËØïÂ∫îÁî®ÂéüÂßã localStorage„ÄÇ")
            else:
                logger.warning(f"[{req_id}] ÊÅ¢Â§çÔºöÊó†ÊúâÊïàÁöÑÂéüÂßã localStorage Áä∂ÊÄÅÂèØÊÅ¢Â§çÔºå‰πüÊó†Ê≥ïËØªÂèñÂΩìÂâçÈ°µÈù¢ÊòæÁ§∫„ÄÇ")
            return False
        model_id_to_revert_to = None
        if parsed_model_list and current_displayed_name_for_revert_stripped != "Êó†Ê≥ïËØªÂèñ":
            normalized_current_display_for_revert = current_displayed_name_for_revert_stripped.lower()
            for m_obj in parsed_model_list:
                parsed_list_display_name = m_obj.get("display_name", "").strip().lower()
                if parsed_list_display_name == normalized_current_display_for_revert:
                    model_id_to_revert_to = m_obj.get("id")
                    logger.info(f"[{req_id}] ÊÅ¢Â§çÔºöÈ°µÈù¢ÊòæÁ§∫ÂêçÁß∞ '{current_displayed_name_for_revert_stripped}' ÂØπÂ∫îÊ®°ÂûãID: {model_id_to_revert_to}")
                    break
            if not model_id_to_revert_to:
                logger.warning(f"[{req_id}] ÊÅ¢Â§çÔºöÊó†Ê≥ïÂú® parsed_model_list ‰∏≠ÊâæÂà∞‰∏éÈ°µÈù¢ÊòæÁ§∫ÂêçÁß∞ '{current_displayed_name_for_revert_stripped}' ÂåπÈÖçÁöÑÊ®°ÂûãID„ÄÇ")
        else:
            if current_displayed_name_for_revert_stripped == "Êó†Ê≥ïËØªÂèñ":
                 logger.warning(f"[{req_id}] ÊÅ¢Â§çÔºöÂõ†Êó†Ê≥ïËØªÂèñÈ°µÈù¢ÊòæÁ§∫ÂêçÁß∞ÔºåÊïÖ‰∏çËÉΩ‰ªé parsed_model_list ËΩ¨Êç¢ID„ÄÇ")
            else:
                 logger.warning(f"[{req_id}] ÊÅ¢Â§çÔºöparsed_model_list ‰∏∫Á©∫ÔºåÊó†Ê≥ï‰ªéÊòæÁ§∫ÂêçÁß∞ '{current_displayed_name_for_revert_stripped}' ËΩ¨Êç¢Ê®°ÂûãID„ÄÇ")
        if model_id_to_revert_to:
            base_prefs_for_final_revert = {}
            try:
                current_ls_content_str = await page.evaluate("() => localStorage.getItem('aiStudioUserPreference')")
                if current_ls_content_str:
                    base_prefs_for_final_revert = json.loads(current_ls_content_str)
                elif original_prefs_str:
                    base_prefs_for_final_revert = json.loads(original_prefs_str)
            except json.JSONDecodeError:
                logger.warning(f"[{req_id}] ÊÅ¢Â§çÔºöËß£ÊûêÁé∞Êúâ localStorage ‰ª•ÊûÑÂª∫ÊÅ¢Â§çÂÅèÂ•ΩÂ§±Ë¥•„ÄÇ")
            path_to_revert_to = f"models/{model_id_to_revert_to}"
            base_prefs_for_final_revert["promptModel"] = path_to_revert_to
            logger.info(f"[{req_id}] ÊÅ¢Â§çÔºöÂáÜÂ§áÂ∞Ü localStorage.promptModel ËÆæÁΩÆÂõûÈ°µÈù¢ÂÆûÈôÖÊòæÁ§∫ÁöÑÊ®°ÂûãÁöÑË∑ØÂæÑ: '{path_to_revert_to}'")
            await page.evaluate("(prefsStr) => localStorage.setItem('aiStudioUserPreference', prefsStr)", json.dumps(base_prefs_for_final_revert))
            logger.info(f"[{req_id}] ÊÅ¢Â§çÔºöÂØºËà™Âà∞ '{new_chat_url}' ‰ª•Â∫îÁî®ÊÅ¢Â§çÂà∞ '{model_id_to_revert_to}' ÁöÑ localStorage ËÆæÁΩÆ...")
            await page.goto(new_chat_url, wait_until="domcontentloaded", timeout=30000)
            await expect_async(page.locator(INPUT_SELECTOR)).to_be_visible(timeout=30000)
            logger.info(f"[{req_id}] ÊÅ¢Â§çÔºöÈ°µÈù¢Â∑≤ÂØºËà™Âà∞Êñ∞ËÅäÂ§©Âπ∂Âä†ËΩΩ„ÄÇlocalStorage Â∫îÂ∑≤ËÆæÁΩÆ‰∏∫ÂèçÊò†Ê®°Âûã '{model_id_to_revert_to}'„ÄÇ")
        else:
            logger.error(f"[{req_id}] ÊÅ¢Â§çÔºöÊó†Ê≥ïÂ∞ÜÊ®°ÂûãÊÅ¢Â§çÂà∞È°µÈù¢ÊòæÁ§∫ÁöÑÁä∂ÊÄÅÔºåÂõ†‰∏∫Êú™ËÉΩ‰ªéÊòæÁ§∫ÂêçÁß∞ '{current_displayed_name_for_revert_stripped}' Á°ÆÂÆöÊúâÊïàÊ®°ÂûãID„ÄÇ")
            if original_prefs_str:
                logger.warning(f"[{req_id}] ÊÅ¢Â§çÔºö‰Ωú‰∏∫ÊúÄÁªàÂêéÂ§áÔºåÂ∞ùËØïÊÅ¢Â§çÂà∞ÂéüÂßã localStorage: '{original_prompt_model or 'Êú™ËÆæÁΩÆ'}'")
                await page.evaluate("(origPrefs) => localStorage.setItem('aiStudioUserPreference', origPrefs)", original_prefs_str)
                logger.info(f"[{req_id}] ÊÅ¢Â§çÔºöÂØºËà™Âà∞ '{new_chat_url}' ‰ª•Â∫îÁî®ÊúÄÁªàÂêéÂ§áÁöÑÂéüÂßã localStorage„ÄÇ")
                await page.goto(new_chat_url, wait_until="domcontentloaded", timeout=20000)
                await expect_async(page.locator(INPUT_SELECTOR)).to_be_visible(timeout=20000)
                logger.info(f"[{req_id}] ÊÅ¢Â§çÔºöÈ°µÈù¢Â∑≤ÂØºËà™Âà∞Êñ∞ËÅäÂ§©Âπ∂Âä†ËΩΩÔºåÂ∑≤Â∫îÁî®ÊúÄÁªàÂêéÂ§áÁöÑÂéüÂßã localStorage„ÄÇ")
            else:
                logger.warning(f"[{req_id}] ÊÅ¢Â§çÔºöÊó†ÊúâÊïàÁöÑÂéüÂßã localStorage Áä∂ÊÄÅÂèØ‰Ωú‰∏∫ÊúÄÁªàÂêéÂ§á„ÄÇ")
        return False
    except Exception as e:
        logger.exception(f"[{req_id}] ‚ùå ÂàáÊç¢Ê®°ÂûãËøáÁ®ã‰∏≠ÂèëÁîü‰∏•ÈáçÈîôËØØ")
        await save_error_snapshot(f"model_switch_error_{req_id}")
        try:
            if original_prefs_str:
                logger.info(f"[{req_id}] ÂèëÁîüÂºÇÂ∏∏ÔºåÂ∞ùËØïÊÅ¢Â§ç localStorage Ëá≥: {original_prompt_model or 'Êú™ËÆæÁΩÆ'}")
                await page.evaluate("(origPrefs) => localStorage.setItem('aiStudioUserPreference', origPrefs)", original_prefs_str)
                logger.info(f"[{req_id}] ÂºÇÂ∏∏ÊÅ¢Â§çÔºöÂØºËà™Âà∞ '{new_chat_url}' ‰ª•Â∫îÁî®ÊÅ¢Â§çÁöÑ localStorage„ÄÇ")
                await page.goto(new_chat_url, wait_until="domcontentloaded", timeout=15000)
                await expect_async(page.locator(INPUT_SELECTOR)).to_be_visible(timeout=15000)
        except Exception as recovery_err:
            logger.error(f"[{req_id}] ÂºÇÂ∏∏ÂêéÊÅ¢Â§ç localStorage Â§±Ë¥•: {recovery_err}")
        return False

# --- Load Excluded Models ---
def load_excluded_models(filename: str):
    global excluded_model_ids, logger
    excluded_file_path = os.path.join(os.path.dirname(__file__), filename)
    try:
        if os.path.exists(excluded_file_path):
            with open(excluded_file_path, 'r', encoding='utf-8') as f:
                loaded_ids = {line.strip() for line in f if line.strip()}
            if loaded_ids:
                excluded_model_ids.update(loaded_ids)
                logger.info(f"‚úÖ ‰ªé '{filename}' Âä†ËΩΩ‰∫Ü {len(loaded_ids)} ‰∏™Ê®°ÂûãÂà∞ÊéíÈô§ÂàóË°®: {excluded_model_ids}")
            else:
                logger.info(f"'{filename}' Êñá‰ª∂‰∏∫Á©∫Êàñ‰∏çÂåÖÂê´ÊúâÊïàÁöÑÊ®°Âûã IDÔºåÊéíÈô§ÂàóË°®Êú™Êõ¥Êîπ„ÄÇ")
        else:
            logger.info(f"Ê®°ÂûãÊéíÈô§ÂàóË°®Êñá‰ª∂ '{filename}' Êú™ÊâæÂà∞ÔºåÊéíÈô§ÂàóË°®‰∏∫Á©∫„ÄÇ")
    except Exception as e:
        logger.error(f"‚ùå ‰ªé '{filename}' Âä†ËΩΩÊéíÈô§Ê®°ÂûãÂàóË°®Êó∂Âá∫Èîô: {e}", exc_info=True)

# --- Handle Initial Model State and Storage ---
async def _handle_initial_model_state_and_storage(page: AsyncPage):
    global current_ai_studio_model_id, logger, parsed_model_list, model_list_fetch_event, INPUT_SELECTOR
    logger.info("--- (Êñ∞) Â§ÑÁêÜÂàùÂßãÊ®°ÂûãÁä∂ÊÄÅ, localStorage Âíå isAdvancedOpen ---")
    needs_reload_and_storage_update = False
    reason_for_reload = ""
    try:
        initial_prefs_str = await page.evaluate("() => localStorage.getItem('aiStudioUserPreference')")
        if not initial_prefs_str:
            needs_reload_and_storage_update = True
            reason_for_reload = "localStorage.aiStudioUserPreference Êú™ÊâæÂà∞„ÄÇ"
            logger.info(f"   Âà§ÂÆöÈúÄË¶ÅÂà∑Êñ∞ÂíåÂ≠òÂÇ®Êõ¥Êñ∞: {reason_for_reload}")
        else:
            logger.info("   localStorage ‰∏≠ÊâæÂà∞ 'aiStudioUserPreference'„ÄÇÊ≠£Âú®Ëß£Êûê...")
            try:
                pref_obj = json.loads(initial_prefs_str)
                prompt_model_path = pref_obj.get("promptModel")
                is_advanced_open_in_storage = pref_obj.get("isAdvancedOpen")
                is_prompt_model_valid = isinstance(prompt_model_path, str) and prompt_model_path.strip()
                if not is_prompt_model_valid:
                    needs_reload_and_storage_update = True
                    reason_for_reload = "localStorage.promptModel Êó†ÊïàÊàñÊú™ËÆæÁΩÆ„ÄÇ"
                    logger.info(f"   Âà§ÂÆöÈúÄË¶ÅÂà∑Êñ∞ÂíåÂ≠òÂÇ®Êõ¥Êñ∞: {reason_for_reload}")
                elif is_advanced_open_in_storage is not True:
                    needs_reload_and_storage_update = True
                    reason_for_reload = f"localStorage.isAdvancedOpen ({is_advanced_open_in_storage}) ‰∏ç‰∏∫ True„ÄÇ"
                    logger.info(f"   Âà§ÂÆöÈúÄË¶ÅÂà∑Êñ∞ÂíåÂ≠òÂÇ®Êõ¥Êñ∞: {reason_for_reload}")
                else:
                    current_ai_studio_model_id = prompt_model_path.split('/')[-1]
                    logger.info(f"   ‚úÖ localStorage ÊúâÊïà‰∏î isAdvancedOpen=true„ÄÇÂàùÂßãÊ®°Âûã ID ‰ªé localStorage ËÆæÁΩÆ‰∏∫: {current_ai_studio_model_id}")
            except json.JSONDecodeError:
                needs_reload_and_storage_update = True
                reason_for_reload = "Ëß£Êûê localStorage.aiStudioUserPreference JSON Â§±Ë¥•„ÄÇ"
                logger.error(f"   Âà§ÂÆöÈúÄË¶ÅÂà∑Êñ∞ÂíåÂ≠òÂÇ®Êõ¥Êñ∞: {reason_for_reload}")
        if needs_reload_and_storage_update:
            logger.info(f"   ÊâßË°åÂà∑Êñ∞ÂíåÂ≠òÂÇ®Êõ¥Êñ∞ÊµÅÁ®ãÔºåÂéüÂõ†: {reason_for_reload}")
            logger.info("   Ê≠•È™§ 1: Ë∞ÉÁî® _set_model_from_page_display(set_storage=True) Êõ¥Êñ∞ localStorage ÂíåÂÖ®Â±ÄÊ®°Âûã ID...")
            await _set_model_from_page_display(page, set_storage=True)
            current_page_url = page.url
            logger.info(f"   Ê≠•È™§ 2: ÈáçÊñ∞Âä†ËΩΩÈ°µÈù¢ ({current_page_url}) ‰ª•Â∫îÁî® isAdvancedOpen=true...")
            try:
                await page.goto(current_page_url, wait_until="domcontentloaded", timeout=30000)
                await expect_async(page.locator(INPUT_SELECTOR)).to_be_visible(timeout=30000)
                logger.info(f"   ‚úÖ È°µÈù¢Â∑≤ÊàêÂäüÈáçÊñ∞Âä†ËΩΩÂà∞: {page.url}")
            except Exception as reload_err:
                logger.error(f"   ‚ùå È°µÈù¢ÈáçÊñ∞Âä†ËΩΩÂ§±Ë¥•: {reload_err}. ÂêéÁª≠Ê®°ÂûãÁä∂ÊÄÅÂèØËÉΩ‰∏çÂáÜÁ°Æ„ÄÇ", exc_info=True)
                await save_error_snapshot("initial_storage_reload_fail")
            logger.info("   Ê≠•È™§ 3: ÈáçÊñ∞Âä†ËΩΩÂêéÔºåÂÜçÊ¨°Ë∞ÉÁî® _set_model_from_page_display(set_storage=False) ‰ª•ÂêåÊ≠•ÂÖ®Â±ÄÊ®°Âûã ID...")
            await _set_model_from_page_display(page, set_storage=False)
            logger.info(f"   ‚úÖ Âà∑Êñ∞ÂíåÂ≠òÂÇ®Êõ¥Êñ∞ÊµÅÁ®ãÂÆåÊàê„ÄÇÊúÄÁªàÂÖ®Â±ÄÊ®°Âûã ID: {current_ai_studio_model_id}")
        else:
            logger.info("   localStorage Áä∂ÊÄÅËâØÂ•Ω (isAdvancedOpen=true, promptModelÊúâÊïà)ÔºåÊó†ÈúÄÂà∑Êñ∞È°µÈù¢„ÄÇ")
    except Exception as e:
        logger.error(f"‚ùå (Êñ∞) Â§ÑÁêÜÂàùÂßãÊ®°ÂûãÁä∂ÊÄÅÂíå localStorage Êó∂ÂèëÁîü‰∏•ÈáçÈîôËØØ: {e}", exc_info=True)
        try:
            logger.warning("   Áî±‰∫éÂèëÁîüÈîôËØØÔºåÂ∞ùËØïÂõûÈÄÄ‰ªÖ‰ªéÈ°µÈù¢ÊòæÁ§∫ËÆæÁΩÆÂÖ®Â±ÄÊ®°Âûã ID (‰∏çÂÜôÂÖ•localStorage)...")
            await _set_model_from_page_display(page, set_storage=False)
        except Exception as fallback_err:
            logger.error(f"   ÂõûÈÄÄËÆæÁΩÆÊ®°ÂûãID‰πüÂ§±Ë¥•: {fallback_err}")

async def _set_model_from_page_display(page: AsyncPage, set_storage: bool = False):
    global current_ai_studio_model_id, logger, parsed_model_list, model_list_fetch_event
    try:
        logger.info("   Â∞ùËØï‰ªéÈ°µÈù¢ÊòæÁ§∫ÂÖÉÁ¥†ËØªÂèñÂΩìÂâçÊ®°ÂûãÂêçÁß∞...")
        model_name_locator = page.locator('mat-select[data-test-ms-model-selector] div.model-option-content span.gmat-body-medium')
        displayed_model_name_from_page_raw = await model_name_locator.first.inner_text(timeout=7000)
        displayed_model_name = displayed_model_name_from_page_raw.strip()
        logger.info(f"   È°µÈù¢ÂΩìÂâçÊòæÁ§∫Ê®°ÂûãÂêçÁß∞ (ÂéüÂßã: '{displayed_model_name_from_page_raw}', Ê∏ÖÁêÜÂêé: '{displayed_model_name}')")
        found_model_id_from_display = None
        if not model_list_fetch_event.is_set():
            logger.info("   Á≠âÂæÖÊ®°ÂûãÂàóË°®Êï∞ÊçÆ (ÊúÄÂ§ö5Áßí) ‰ª•‰æøËΩ¨Êç¢ÊòæÁ§∫ÂêçÁß∞...")
            try: await asyncio.wait_for(model_list_fetch_event.wait(), timeout=5.0)
            except asyncio.TimeoutError: logger.warning("   Á≠âÂæÖÊ®°ÂûãÂàóË°®Ë∂ÖÊó∂ÔºåÂèØËÉΩÊó†Ê≥ïÂáÜÁ°ÆËΩ¨Êç¢ÊòæÁ§∫ÂêçÁß∞‰∏∫ID„ÄÇ")
        if parsed_model_list:
            for model_obj in parsed_model_list:
                if model_obj.get("display_name") and model_obj.get("display_name").strip() == displayed_model_name:
                    found_model_id_from_display = model_obj.get("id")
                    logger.info(f"   ÊòæÁ§∫ÂêçÁß∞ '{displayed_model_name}' ÂØπÂ∫îÊ®°Âûã ID: {found_model_id_from_display}")
                    break
            if not found_model_id_from_display:
                 logger.warning(f"   Êú™Âú®Â∑≤Áü•Ê®°ÂûãÂàóË°®‰∏≠ÊâæÂà∞‰∏éÊòæÁ§∫ÂêçÁß∞ '{displayed_model_name}' ÂåπÈÖçÁöÑ ID„ÄÇ")
        else:
            logger.warning("   Ê®°ÂûãÂàóË°®Â∞ö‰∏çÂèØÁî®ÔºåÊó†Ê≥ïÂ∞ÜÊòæÁ§∫ÂêçÁß∞ËΩ¨Êç¢‰∏∫ID„ÄÇ")
        new_model_value = found_model_id_from_display if found_model_id_from_display else displayed_model_name
        if current_ai_studio_model_id != new_model_value:
            current_ai_studio_model_id = new_model_value
            logger.info(f"   ÂÖ®Â±Ä current_ai_studio_model_id Â∑≤Êõ¥Êñ∞‰∏∫: {current_ai_studio_model_id}")
        else:
            logger.info(f"   ÂÖ®Â±Ä current_ai_studio_model_id ('{current_ai_studio_model_id}') ‰∏é‰ªéÈ°µÈù¢Ëé∑ÂèñÁöÑÂÄº‰∏ÄËá¥ÔºåÊú™Êõ¥Êîπ„ÄÇ")
        if set_storage:
            logger.info(f"   ÂáÜÂ§á‰∏∫È°µÈù¢Áä∂ÊÄÅËÆæÁΩÆ localStorage (Á°Æ‰øù isAdvancedOpen=true)...")
            existing_prefs_for_update_str = await page.evaluate("() => localStorage.getItem('aiStudioUserPreference')")
            prefs_to_set = {}
            if existing_prefs_for_update_str:
                try:
                    prefs_to_set = json.loads(existing_prefs_for_update_str)
                except json.JSONDecodeError:
                    logger.warning("   Ëß£ÊûêÁé∞Êúâ localStorage.aiStudioUserPreference Â§±Ë¥•ÔºåÂ∞ÜÂàõÂª∫Êñ∞ÁöÑÂÅèÂ•ΩËÆæÁΩÆ„ÄÇ")
            prefs_to_set["isAdvancedOpen"] = True
            logger.info(f"     Âº∫Âà∂ isAdvancedOpen: true")
            prefs_to_set["areToolsOpen"] = False
            logger.info(f"     Âº∫Âà∂ areToolsOpen: false")
            if found_model_id_from_display:
                new_prompt_model_path = f"models/{found_model_id_from_display}"
                prefs_to_set["promptModel"] = new_prompt_model_path
                logger.info(f"     ËÆæÁΩÆ promptModel ‰∏∫: {new_prompt_model_path} (Âü∫‰∫éÊâæÂà∞ÁöÑID)")
            elif "promptModel" not in prefs_to_set:
                logger.warning(f"     Êó†Ê≥ï‰ªéÈ°µÈù¢ÊòæÁ§∫ '{displayed_model_name}' ÊâæÂà∞Ê®°ÂûãIDÔºå‰∏î localStorage ‰∏≠Êó†Áé∞Êúâ promptModel„ÄÇpromptModel Â∞Ü‰∏ç‰ºöË¢´‰∏ªÂä®ËÆæÁΩÆ‰ª•ÈÅøÂÖçÊΩúÂú®ÈóÆÈ¢ò„ÄÇ")
            default_keys_if_missing = {
                "bidiModel": "models/gemini-1.0-pro-001",
                "isSafetySettingsOpen": False,
                "hasShownSearchGroundingTos": False,
                "autosaveEnabled": True,
                "theme": "system",
                "bidiOutputFormat": 3,
                "isSystemInstructionsOpen": False,
                "warmWelcomeDisplayed": True,
                "getCodeLanguage": "Node.js",
                "getCodeHistoryToggle": False,
                "fileCopyrightAcknowledged": True
            }
            for key, val_default in default_keys_if_missing.items():
                if key not in prefs_to_set:
                    prefs_to_set[key] = val_default
            await page.evaluate("(prefsStr) => localStorage.setItem('aiStudioUserPreference', prefsStr)", json.dumps(prefs_to_set))
            logger.info(f"   ‚úÖ localStorage.aiStudioUserPreference Â∑≤Êõ¥Êñ∞„ÄÇisAdvancedOpen: {prefs_to_set.get('isAdvancedOpen')}, areToolsOpen: {prefs_to_set.get('areToolsOpen')}, promptModel: '{prefs_to_set.get('promptModel', 'Êú™ËÆæÁΩÆ/‰øùÁïôÂéüÊ†∑')}'„ÄÇ")
    except Exception as e_set_disp:
        logger.error(f"   Â∞ùËØï‰ªéÈ°µÈù¢ÊòæÁ§∫ËÆæÁΩÆÊ®°ÂûãÊó∂Âá∫Èîô: {e_set_disp}", exc_info=True)
