# server.py
import asyncio
import random
import time
import json # Added for potential JSON operations
from typing import List, Optional, Dict, Any, Union, AsyncGenerator
import os
import traceback # Keep traceback import
from contextlib import asynccontextmanager # Import asynccontextmanager
import sys # Import sys for exiting
import platform # To check OS type
# Removed argparse import
# import argparse

from fastapi import FastAPI, Request, HTTPException
from fastapi.responses import JSONResponse, StreamingResponse, FileResponse
from pydantic import BaseModel, Field
# Assuming camoufox is installed and provides sync/async APIs
# Adjust the import based on actual library structure if needed
from camoufox.sync_api import Camoufox as CamoufoxSync
# Import the async module directly
import camoufox.async_api
from playwright.sync_api import Page as SyncPage, Browser as SyncBrowser, Playwright as SyncPlaywright, Error as PlaywrightSyncError, expect as expect_sync # Added expect
from playwright.async_api import Page as AsyncPage, Browser as AsyncBrowser, Playwright as AsyncPlaywright, Error as PlaywrightAsyncError, expect as expect_async, BrowserContext as AsyncBrowserContext # Added expect, BrowserContext
from playwright.async_api import async_playwright # Import standard async_playwright

# --- ANSI Colors Removed ---
# ...

# --- Configuration (Mirrored from server.cjs, adjust as needed) ---
# SERVER_PORT = 2048 # Port will be handled by uvicorn when running
AI_STUDIO_URL_PATTERN = 'aistudio.google.com/'
RESPONSE_COMPLETION_TIMEOUT = 300000 # 5 minutes total timeout (in ms)
POLLING_INTERVAL = 300 # ms - Standard polling interval
POLLING_INTERVAL_STREAM = 200 # ms - Stream-specific polling interval
SILENCE_TIMEOUT_MS = 1500 # ms
# v2.12: Timeout for secondary checks *after* spinner disappears
POST_SPINNER_CHECK_DELAY_MS = 500 # Spinneræ¶ˆå¤±åç¨ä½œç­‰å¾…å†æ£€æŸ¥å…¶ä»–çŠ¶æ€
FINAL_STATE_CHECK_TIMEOUT_MS = 1500 # æ£€æŸ¥æŒ‰é’®å’Œè¾“å…¥æ¡†æœ€ç»ˆçŠ¶æ€çš„è¶…æ—¶
SPINNER_CHECK_TIMEOUT_MS = 1000 # æ£€æŸ¥SpinnerçŠ¶æ€çš„è¶…æ—¶
POST_COMPLETION_BUFFER = 1000 # JSONæ¨¡å¼ä¸‹å¯ä»¥ç¼©çŸ­æ£€æŸ¥åç­‰å¾…æ—¶é—´
# !! æ–°å¢ï¼šæ¸…ç©ºéªŒè¯ç›¸å…³å¸¸é‡ !! (Mirrored)
CLEAR_CHAT_VERIFY_TIMEOUT_MS = 5000 # ç­‰å¾…æ¸…ç©ºç”Ÿæ•ˆçš„æ€»è¶…æ—¶æ—¶é—´ (ms)
CLEAR_CHAT_VERIFY_INTERVAL_MS = 300 # æ£€æŸ¥æ¸…ç©ºçŠ¶æ€çš„è½®è¯¢é—´éš” (ms)

# --- Configuration ---
STORAGE_STATE_PATH = os.path.join(os.path.dirname(__file__), "auth_state.json") # Path to save/load auth state
# Remove USER_DATA_DIR and related path logic as persistence doesn't work
# USER_DATA_DIR = os.path.join(os.path.dirname(__file__), "camoufox_profile")
# CAMOUFOX_CACHE_DIR = "/Users/aq/Library/Caches/camoufox"
# CAMOUFOX_EXECUTABLE_PATH = os.path.join(CAMOUFOX_CACHE_DIR, "Camoufox.app", "Contents", "MacOS", "Camoufox")

# --- Constants (Mirrored from server.cjs) ---
MODEL_NAME = 'google-ai-studio-via-camoufox-fastapi' # Updated model name
CHAT_COMPLETION_ID_PREFIX = 'chatcmpl-'

# --- Selectors (Mirrored from server.cjs, verify if still valid in Firefox/Camoufox) ---
INPUT_SELECTOR = 'ms-prompt-input-wrapper textarea'
SUBMIT_BUTTON_SELECTOR = 'button[aria-label="Run"]'
RESPONSE_CONTAINER_SELECTOR = 'ms-chat-turn .chat-turn-container.model'
RESPONSE_TEXT_SELECTOR = 'ms-cmark-node.cmark-node'
LOADING_SPINNER_SELECTOR = 'button[aria-label="Run"] svg .stoppable-spinner'
ERROR_TOAST_SELECTOR = 'div.toast.warning, div.toast.error'
# !! æ–°å¢ï¼šæ¸…ç©ºèŠå¤©è®°å½•ç›¸å…³é€‰æ‹©å™¨ !! (Mirrored)
CLEAR_CHAT_BUTTON_SELECTOR = 'button[aria-label="Clear chat"][data-test-clear="outside"]:has(span.material-symbols-outlined:has-text("refresh"))'
CLEAR_CHAT_CONFIRM_BUTTON_SELECTOR = 'button.mdc-button:has-text("Continue")'

# --- Global State (Modified) ---
playwright_manager: Optional[AsyncPlaywright] = None # To manage playwright itself
browser_instance: Optional[AsyncBrowser] = None # Store the browser instance connected via WebSocket
context_instance: Optional[AsyncBrowserContext] = None # Context is temporary within init
page_instance: Optional[AsyncPage] = None
is_playwright_ready = False # Renamed from is_camoufox_ready
is_browser_connected = False
is_page_ready = False
is_initializing = False
# Removed cli_args global variable
# cli_args = None
# TODO: Implement request queue and processing state if needed (using asyncio.Queue for async)


# --- Pydantic Models for API validation ---
class MessageContentItem(BaseModel):
    type: str
    text: Optional[str] = None
    # Add image_url field if needed for vision models later
    # image_url: Optional[ImageUrl] = None

class Message(BaseModel):
    role: str
    content: Union[str, List[MessageContentItem]] # Handle text and OpenAI vision format

class ChatCompletionRequest(BaseModel):
    messages: List[Message]
    model: Optional[str] = MODEL_NAME # Optional, but helps if client sends it
    stream: Optional[bool] = False
    # Add other potential OpenAI compatible fields if needed (temperature, etc.)


# --- Helper Functions (Ported/Adapted from server.cjs) ---

def prepare_ai_studio_prompt(user_prompt: str, system_prompt: Optional[str] = None) -> str:
    # (Ported from server.cjs prepareAIStudioPrompt)
    # Start with the base instruction as a normal string
    base_instruction = """
IMPORTANT: Your entire response MUST be a single JSON object. Do not include any text outside of this JSON object.
The JSON object must have a single key named "response".
Inside the value of the "response" key (which is a string), you MUST put the exact marker "<<<START_RESPONSE>>>"" at the very beginning of your actual answer. There should be NO text before this marker within the response string.
"""

    system_instruction = ""
    if system_prompt and system_prompt.strip():
        # Use f-string formatting safely here
        system_instruction = f"System Instruction: {system_prompt}\n"

    # Use a regular multiline string for the examples and final prompt
    # Use single quotes for the outer triple quotes to avoid conflict with internal double quotes
    # Simplify escaping inside the python code example
    prompt_template = '''
Example 1:
User asks: "What is the capital of France?"
Your response MUST be:
{
  "response": "<<<START_RESPONSE>>>The capital of France is Paris."
}

Example 2:
User asks: "Write a python function to add two numbers"
Your response MUST be:
{
  "response": "<<<START_RESPONSE>>>```python\ndef add(a, b):\n  return a + b\n```"
}

Now, answer the following user prompt, ensuring your output strictly adheres to the JSON format AND the start marker requirement described above:

User Prompt: "{user_prompt_placeholder}"

Your JSON Response:
'''

    # Combine the parts and replace the placeholder
    full_prompt = base_instruction
    if system_instruction:
        full_prompt += "\n" + system_instruction # Add newline before system instruction
    full_prompt += prompt_template.replace("{user_prompt_placeholder}", user_prompt)

    return full_prompt

def prepare_ai_studio_prompt_stream(user_prompt: str, system_prompt: Optional[str] = None) -> str:
    # (Ported from server.cjs prepareAIStudioPromptStream)
    # vNEXT: Use Markdown Code Block for streaming
    base_instruction = """
IMPORTANT: For this streaming request, your entire response MUST be enclosed in a single markdown code block (like ``` block ```).
Inside this code block, your actual answer text MUST start immediately after the exact marker "<<<START_RESPONSE>>>".
Start your response exactly with "```\n<<<START_RESPONSE>>>" followed by your answer content.
Continue outputting your answer content. You SHOULD include the final closing "```" at the very end of your full response stream.
"""

    system_instruction = ""
    if system_prompt and system_prompt.strip():
        system_instruction = f"System Instruction: {system_prompt}\n"

    # Use a regular multiline string for the examples and final prompt
    # Use single quotes for the outer triple quotes
    prompt_template = '''
Example 1 (Streaming):
User asks: "What is the capital of France?"
Your streamed response MUST look like this over time:
Stream part 1: ```\n<<<START_RESPONSE>>>The capital
Stream part 2:  of France is
Stream part 3:  Paris.\n```

Example 2 (Streaming):
User asks: "Write a python function to add two numbers"
Your streamed response MUST look like this over time:
Stream part 1: ```\n<<<START_RESPONSE>>>```python\ndef add(a, b):
Stream part 2: \n  return a + b\n
Stream part 3: ```\n```

Now, answer the following user prompt, ensuring your output strictly adheres to the markdown code block, start marker, and streaming requirements described above:

User Prompt: "{user_prompt_placeholder}"

Your Response (Streaming, within a markdown code block):
'''

    # Combine the parts and replace the placeholder
    full_prompt = base_instruction
    if system_instruction:
        full_prompt += "\n" + system_instruction
    full_prompt += prompt_template.replace("{user_prompt_placeholder}", user_prompt)

    return full_prompt

def validate_chat_request(messages: List[Message], req_id: str) -> Dict[str, Optional[str]]:
    # (Ported and adapted from server.cjs validateChatRequest)
    if not messages:
        raise ValueError(f"[{req_id}] Invalid request: 'messages' array is missing or empty.")

    user_message = next((msg for msg in reversed(messages) if msg.role == 'user'), None)
    if not user_message:
        raise ValueError(f"[{req_id}] Invalid request: No user message found.")

    user_prompt_content_input = user_message.content
    processed_user_prompt = ""

    if user_prompt_content_input is None:
        print(f"[{req_id}] (Validation) Warning: Last user message content is null. Treating as empty string.")
        processed_user_prompt = ""
    elif isinstance(user_prompt_content_input, str):
        processed_user_prompt = user_prompt_content_input
    elif isinstance(user_prompt_content_input, list): # Handle OpenAI vision format
        print(f"[{req_id}] (Validation) Info: Last user message content is an array. Processing text parts...")
        text_parts = []
        unsupported_parts = False
        for item_model in user_prompt_content_input:
            item = item_model.dict() # Convert Pydantic model to dict
            if item.get('type') == 'text' and isinstance(item.get('text'), str):
                text_parts.append(item['text'])
            elif item.get('type') == 'image_url':
                print(f"[{req_id}] (Validation) Warning: Found 'image_url'. This proxy cannot process images. Ignoring.")
                unsupported_parts = True
            else:
                print(f"[{req_id}] (Validation) Warning: Found unexpected item in content array: {item}. Converting to JSON string.")
                try:
                    text_parts.append(json.dumps(item))
                    unsupported_parts = True
                except Exception as e:
                    print(f"[{req_id}] (Validation) Error stringifying array item: {e}. Skipping.")
        processed_user_prompt = "\n".join(text_parts)
        if unsupported_parts:
            print(f"[{req_id}] (Validation) Warning: Some parts ignored (e.g., images).")
        if not processed_user_prompt:
            print(f"[{req_id}] (Validation) Warning: Processed array content resulted in an empty prompt.")
    else:
         print(f"[{req_id}] (Validation) Warning: User message content is unexpected type ({type(user_prompt_content_input)}). Converting to string.")
         processed_user_prompt = str(user_prompt_content_input)

    system_message = next((msg for msg in messages if msg.role == 'system'), None)
    processed_system_prompt = None
    if system_message:
        if isinstance(system_message.content, str):
            processed_system_prompt = system_message.content
        else:
             print(f"[{req_id}] (Validation) Warning: System prompt content is not a string. Ignoring.")

    return {
        "userPrompt": processed_user_prompt,
        "systemPrompt": processed_system_prompt
    }

async def get_raw_text_content(response_element, previous_text: str, req_id: str) -> str:
    # (Ported/Adapted from server.cjs getRawTextContent - using async Playwright)
    # Attempts to get text from <pre> first, then falls back to the main element
    try:
        await response_element.wait_for(state='attached', timeout=1500)
        pre_element = response_element.locator('pre').last
        raw_text = previous_text # Default to previous if all attempts fail
        try:
            await pre_element.wait_for(state='attached', timeout=500)
            raw_text = await pre_element.inner_text(timeout=1000)
        except PlaywrightAsyncError:
            # If <pre> fails, try the parent response element's inner_text
            # print(f"[{req_id}] (Info) Failed to get text from <pre>, falling back to parent.")
            try:
                 raw_text = await response_element.inner_text(timeout=2000)
            except PlaywrightAsyncError as e_parent:
                 print(f"[{req_id}] (Warn) getRawTextContent (inner_text) failed on both <pre> and parent: {e_parent}. Returning previous.")
                 raw_text = previous_text # Return previous if parent also fails
        return raw_text
    except PlaywrightAsyncError as e_attach:
        print(f"[{req_id}] (Warn) getRawTextContent failed waiting for response element attach: {e_attach}. Returning previous.")
        return previous_text
    except Exception as e_general:
         print(f"[{req_id}] (Warn) getRawTextContent unexpected error: {e_general}. Returning previous.")
         return previous_text

def generate_sse_chunk(delta: str, req_id: str, model: str) -> str:
    chunk = {
        "id": f"{CHAT_COMPLETION_ID_PREFIX}{req_id}-{int(time.time())}-{random.randint(100, 999)}",
        "object": "chat.completion.chunk",
        "created": int(time.time()),
        "model": model,
        "choices": [{"index": 0, "delta": {"content": delta}, "finish_reason": None}]
    }
    return f"data: {json.dumps(chunk)}\n\n"

def generate_sse_stop_chunk(req_id: str, model: str, reason: str = "stop") -> str:
     chunk = {
        "id": f"{CHAT_COMPLETION_ID_PREFIX}{req_id}-{int(time.time())}-{random.randint(100, 999)}",
        "object": "chat.completion.chunk",
        "created": int(time.time()),
        "model": model,
        "choices": [{"index": 0, "delta": {}, "finish_reason": reason}]
    }
     return f"data: {json.dumps(chunk)}\n\n"

def generate_sse_error_chunk(message: str, req_id: str, error_type: str = "server_error") -> str:
    error_payload = {"error": {"message": f"[{req_id}] {message}", "type": error_type}}
    return f"data: {json.dumps(error_payload)}\n\n"


# --- Helper Functions (Pre-checks) ---
def check_dependencies():
    """Checks if FastAPI/Uvicorn and Playwright are installed."""
    print("--- æ­¥éª¤ 1: æ£€æŸ¥æœåŠ¡å™¨ä¾èµ–é¡¹ ---")
    required = {
        "fastapi": "fastapi",
        "uvicorn": "uvicorn[standard]",
        "playwright": "playwright"
    }
    missing = []
    modules_ok = True

    for mod_name, install_name in required.items():
        print(f"   - æ£€æŸ¥ {mod_name}... ", end="")
        try:
            __import__(mod_name)
            print("âœ“ å·²æ‰¾åˆ°")
        except ImportError:
            print("âŒ æœªæ‰¾åˆ°")
            missing.append(install_name)
            modules_ok = False

    if not modules_ok:
        print("\nâŒ é”™è¯¯: ç¼ºå°‘å¿…è¦çš„ Python åº“!")
        print("   è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…:")
        install_cmd = f"pip install {' '.join(missing)}"
        print(f"   {install_cmd}")
        sys.exit(1)
    else:
        print("âœ… æœåŠ¡å™¨ä¾èµ–æ£€æŸ¥é€šè¿‡.")
    print("---\n")


# --- Page Initialization Logic --- (Translate print statements)
async def _initialize_page_logic(browser: AsyncBrowser):
    global page_instance, is_page_ready
    print("--- åˆå§‹åŒ–é¡µé¢é€»è¾‘ (è¿æ¥åˆ°ç°æœ‰æµè§ˆå™¨) ---") # ä¸­æ–‡

    temp_context = None
    loaded_state = None

    if os.path.exists(STORAGE_STATE_PATH):
        print(f"æ‰¾åˆ°ç°æœ‰çŠ¶æ€æ–‡ä»¶: {STORAGE_STATE_PATH}. å°è¯•åŠ è½½...") # ä¸­æ–‡
        try:
            with open(STORAGE_STATE_PATH, 'r') as f:
                loaded_state = json.load(f)
            print("å­˜å‚¨çŠ¶æ€åŠ è½½æˆåŠŸã€‚") # ä¸­æ–‡
        except Exception as e:
            print(f"è­¦å‘Š: ä» {STORAGE_STATE_PATH} åŠ è½½å­˜å‚¨çŠ¶æ€å¤±è´¥: {e}. å°†åœ¨æ²¡æœ‰å·²ä¿å­˜çŠ¶æ€çš„æƒ…å†µä¸‹ç»§ç»­ã€‚") # ä¸­æ–‡
            loaded_state = None
    else:
        print("æœªæ‰¾åˆ°ç°æœ‰å­˜å‚¨çŠ¶æ€æ–‡ä»¶ã€‚å¦‚æœéœ€è¦ï¼Œå°†å°è¯•å…¨æ–°ç™»å½•ã€‚") # ä¸­æ–‡

    try:
        print(f"ä½¿ç”¨å·²è¿æ¥çš„æµè§ˆå™¨å®ä¾‹ã€‚ç‰ˆæœ¬: {browser.version}") # ä¸­æ–‡

        print("åˆ›å»ºæ–°çš„æµè§ˆå™¨ä¸Šä¸‹æ–‡" + (" (ä½¿ç”¨å·²åŠ è½½çŠ¶æ€)ã€‚" if loaded_state else "ã€‚") ) # ä¸­æ–‡
        try:
            viewport_size = {'width': 460, 'height': 800}
            print(f"   å°è¯•è®¾ç½®è§†å£å¤§å°: {viewport_size}") # ä¸­æ–‡
            temp_context = await browser.new_context(
                storage_state=loaded_state,
                viewport=viewport_size
            )
        except Exception as context_err:
            print(f"è­¦å‘Š: ä½¿ç”¨å·²åŠ è½½çŠ¶æ€åˆ›å»ºä¸Šä¸‹æ–‡å¤±è´¥: {context_err}. å°è¯•ä¸ä½¿ç”¨çŠ¶æ€...") # ä¸­æ–‡
            if loaded_state:
                loaded_state = None
                temp_context = await browser.new_context()
            else:
                raise
        print("æ–°çš„æµè§ˆå™¨ä¸Šä¸‹æ–‡å·²åˆ›å»ºã€‚") # ä¸­æ–‡
        if not temp_context:
            raise RuntimeError("æœªèƒ½åˆ›å»ºæµè§ˆå™¨ä¸Šä¸‹æ–‡ã€‚") # ä¸­æ–‡

        found_page = None
        pages = temp_context.pages
        print(f"-> åœ¨ä¸Šä¸‹æ–‡ä¸­æ‰¾åˆ° {len(pages)} ä¸ªç°æœ‰é¡µé¢ã€‚æ­£åœ¨æœç´¢ AI Studio ({AI_STUDIO_URL_PATTERN})...") # ä¸­æ–‡
        target_url_base = f"https://{AI_STUDIO_URL_PATTERN}"
        target_full_url = f"{target_url_base}prompts/new_chat"
        login_url_pattern = 'accounts.google.com'
        current_url = ""

        for p in pages:
            try:
                page_url_check = p.url
                print(f"   æ£€æŸ¥é¡µé¢: {page_url_check}") # ä¸­æ–‡
                if not p.is_closed() and target_url_base in page_url_check:
                    print(f"-> æ‰¾åˆ°æ½œåœ¨çš„ AI Studio é¡µé¢: {page_url_check}") # ä¸­æ–‡
                    found_page = p
                    current_url = page_url_check
                    if "/prompts/" not in current_url:
                       print(f"   å¯¼èˆªç°æœ‰é¡µé¢åˆ° {target_full_url}...") # ä¸­æ–‡
                       try:
                           await p.goto(target_full_url, wait_until="domcontentloaded", timeout=35000)
                           current_url = p.url
                           print(f"   å¯¼èˆªæˆåŠŸ: {current_url}") # ä¸­æ–‡
                           if login_url_pattern in current_url:
                                 print("è­¦å‘Š: ç°æœ‰é¡µé¢é‡å®šå‘åˆ°ç™»å½•é¡µã€‚") # ä¸­æ–‡
                                 await p.close()
                                 found_page = None
                                 current_url = ""
                                 break
                       except Exception as nav_err:
                           print(f"   è­¦å‘Š: åœ¨ç°æœ‰é¡µé¢ä¸Šå¯¼èˆªå¤±è´¥: {nav_err}.") # ä¸­æ–‡
                           found_page = None
                           current_url = ""
                    break
            except Exception as e:
                if not p.is_closed():
                    print(f"   è­¦å‘Š: æ£€æŸ¥é¡µé¢ URL æ—¶å‡ºé”™: {e}") # ä¸­æ–‡

        if not found_page:
            print(f"-> æ­£åœ¨æ‰“å¼€æ–°é¡µé¢...") # ä¸­æ–‡
            found_page = await temp_context.new_page()
            print(f"   å¯¼èˆªæ–°é¡µé¢åˆ° {target_full_url}...") # ä¸­æ–‡
            await found_page.goto(target_full_url, wait_until="domcontentloaded", timeout=60000)
            current_url = found_page.url
            print(f"-> æ–°é¡µé¢å¯¼èˆªå°è¯•å®Œæˆã€‚å½“å‰ URL: {current_url}") # ä¸­æ–‡

        if login_url_pattern in current_url:
            print("\nğŸ›‘ éœ€è¦æ“ä½œ: å·²é‡å®šå‘åˆ° Google ç™»å½•ï¼(ç™»å½•çŠ¶æ€å¯èƒ½ä¸¢å¤±æˆ–è¿‡æœŸ) ğŸ›‘") # ä¸­æ–‡
            print("   è¯·åœ¨æµè§ˆå™¨çª—å£ (ç”± camoufox æœåŠ¡å™¨ç®¡ç†) ä¸­ç™»å½•æ‚¨çš„ Google è´¦æˆ·ã€‚") # ä¸­æ–‡
            input("   åœ¨æ‚¨ç™»å½•å¹¶çœ‹åˆ° AI Studio åï¼Œåœ¨æ­¤å¤„æŒ‰ Enter é”®...") # ä¸­æ–‡

            print("   ç»§ç»­... ç­‰å¾…æµè§ˆå™¨ URL åŒ…å« AI Studio æ¨¡å¼...") # ä¸­æ–‡
            try:
                await found_page.wait_for_url(f"**/{AI_STUDIO_URL_PATTERN}**", timeout=20000)
                current_url = found_page.url
                print(f"   ç™»å½•åç¡®è®¤ URL: {current_url}") # ä¸­æ–‡
                if login_url_pattern in current_url:
                    raise RuntimeError("æ‰‹åŠ¨ç™»å½•å°è¯•åä»åœ¨ç™»å½•é¡µé¢ã€‚") # ä¸­æ–‡

                print("   ç™»å½•æˆåŠŸï¼æ­£åœ¨ä¿å­˜è®¤è¯çŠ¶æ€...") # ä¸­æ–‡
                try:
                    await temp_context.storage_state(path=STORAGE_STATE_PATH)
                    print(f"   è®¤è¯çŠ¶æ€å·²ä¿å­˜åˆ°: {STORAGE_STATE_PATH}") # ä¸­æ–‡
                except Exception as save_err:
                    print(f"   è­¦å‘Š: ä¿å­˜è®¤è¯çŠ¶æ€å¤±è´¥: {save_err}") # ä¸­æ–‡

            except Exception as wait_err:
                print(f"   ç™»å½•å°è¯•åç­‰å¾… AI Studio URL æ—¶å‡ºé”™: {wait_err}") # ä¸­æ–‡
                last_known_url = found_page.url
                raise RuntimeError(f"ç™»å½•æç¤ºåæœªèƒ½æ£€æµ‹åˆ° AI Studio URLã€‚æœ€åå·²çŸ¥ URL: {last_known_url}. é”™è¯¯: {wait_err}") # ä¸­æ–‡

        elif target_url_base not in current_url:
            print(f"\nâš ï¸ è­¦å‘Š: æœ€åˆåˆ°è¾¾æ„å¤–é¡µé¢: {current_url}") # ä¸­æ–‡
            if loaded_state:
                 print("   è¿™å¯èƒ½æ˜¯ç”±äºåŠ è½½çš„å­˜å‚¨çŠ¶æ€æ— æ•ˆã€‚å°è¯•åˆ é™¤çŠ¶æ€æ–‡ä»¶ã€‚") # ä¸­æ–‡
            raise RuntimeError(f"åˆå§‹å¯¼èˆªåå‡ºç°æ„å¤–é¡µé¢: {current_url}") # ä¸­æ–‡

        print(f"-> å·²ç¡®è®¤é¡µé¢æ˜¯ AI Studio: {current_url}") # ä¸­æ–‡
        await found_page.bring_to_front()
        print("-> å·²å°è¯•å°†é¡µé¢ç½®äºå‰å°ã€‚") # ä¸­æ–‡
        await expect_async(found_page.locator(INPUT_SELECTOR)).to_be_visible(timeout=15000)
        print("-> æ ¸å¿ƒè¾“å…¥åŒºåŸŸå¯è§ã€‚") # ä¸­æ–‡

        page_instance = found_page
        is_page_ready = True
        print(f"âœ… é¡µé¢é€»è¾‘åˆå§‹åŒ–æˆåŠŸã€‚") # ä¸­æ–‡

    except RuntimeError as e:
        print(f"âŒ é¡µé¢é€»è¾‘åˆå§‹åŒ–å¤±è´¥: {e}") # ä¸­æ–‡
        page_instance = None
        is_page_ready = False
        raise e
    except Exception as e:
        print(f"âŒ å¸¸è§„é¡µé¢é€»è¾‘åˆå§‹åŒ–å¤±è´¥: {e}") # ä¸­æ–‡
        traceback.print_exc()
        page_instance = None
        is_page_ready = False
        raise e

# --- Page Shutdown Logic --- (Translate print statements)
async def _close_page_logic():
    global page_instance, is_page_ready
    print("--- è¿è¡Œé¡µé¢é€»è¾‘å…³é—­ --- ") # ä¸­æ–‡
    page_instance = None
    is_page_ready = False
    print("é¡µé¢é€»è¾‘çŠ¶æ€å·²é‡ç½®ã€‚") # ä¸­æ–‡

# --- Lifespan context manager --- (Translate print statements)
@asynccontextmanager
async def lifespan(app_param: FastAPI):
    global playwright_manager, browser_instance, page_instance
    global is_playwright_ready, is_browser_connected, is_page_ready, is_initializing

    is_initializing = True
    print("\n" + "="*60)
    print(f"          ğŸš€ AI Studio Proxy Server (Python/FastAPI) ğŸš€")
    print("="*60)
    print(f"FastAPI ç”Ÿå‘½å‘¨æœŸ: å¯åŠ¨ä¸­...") # ä¸­æ–‡
    try:
        print(f"   å¯åŠ¨ Playwright...") # ä¸­æ–‡
        playwright_manager = await async_playwright().start()
        is_playwright_ready = True
        print(f"   âœ… Playwright å·²å¯åŠ¨ã€‚") # ä¸­æ–‡

        ws_endpoint = os.environ.get('CAMOUFOX_WS_ENDPOINT')
        if not ws_endpoint:
             raise ValueError("æœªæ‰¾åˆ°æˆ–ç¯å¢ƒå˜é‡ CAMOUFOX_WS_ENDPOINT ä¸ºç©ºã€‚") # ä¸­æ–‡

        print(f"   è¿æ¥åˆ° Camoufox æœåŠ¡å™¨äº: {ws_endpoint}") # ä¸­æ–‡
        try:
            browser_instance = await playwright_manager.firefox.connect(ws_endpoint, timeout=30000)
            is_browser_connected = True
            print(f"   âœ… å·²è¿æ¥åˆ°æµè§ˆå™¨å®ä¾‹: ç‰ˆæœ¬ {browser_instance.version}") # ä¸­æ–‡
        except Exception as connect_err:
            print(f"   âŒ è¿æ¥åˆ° Camoufox æœåŠ¡å™¨ {ws_endpoint} æ—¶å‡ºé”™: {connect_err}") # ä¸­æ–‡
            is_browser_connected = False
            raise RuntimeError(f"æœªèƒ½è¿æ¥åˆ° Camoufox æœåŠ¡å™¨") from connect_err # ä¸­æ–‡

        await _initialize_page_logic(browser_instance)

        print(f"âœ… FastAPI ç”Ÿå‘½å‘¨æœŸ: å¯åŠ¨å®Œæˆã€‚") # ä¸­æ–‡
        is_initializing = False
        yield

    except Exception as startup_err:
        print(f"âŒ FastAPI ç”Ÿå‘½å‘¨æœŸ: å¯åŠ¨æœŸé—´å‡ºé”™: {startup_err}") # ä¸­æ–‡
        is_initializing = False
        if browser_instance and browser_instance.is_connected():
            try: await browser_instance.close()
            except: pass
        if playwright_manager:
            try: await playwright_manager.stop()
            except: pass
        raise RuntimeError(f"åº”ç”¨ç¨‹åºå¯åŠ¨å¤±è´¥: {startup_err}") from startup_err # ä¸­æ–‡
    finally:
        is_initializing = False

    print(f"\nFastAPI ç”Ÿå‘½å‘¨æœŸ: å…³é—­ä¸­...") # ä¸­æ–‡
    await _close_page_logic()

    if browser_instance and browser_instance.is_connected():
        print(f"   æ­£åœ¨å…³é—­ä¸æµè§ˆå™¨å®ä¾‹çš„è¿æ¥...") # ä¸­æ–‡
        try:
            await browser_instance.close()
            print(f"   âœ… æµè§ˆå™¨è¿æ¥å·²å…³é—­ã€‚") # ä¸­æ–‡
        except Exception as close_err:
            print(f"   âŒ å…³é—­æµè§ˆå™¨è¿æ¥æ—¶å‡ºé”™: {close_err}") # ä¸­æ–‡
        finally:
            browser_instance = None
            is_browser_connected = False
    else:
        print(f"   âš ï¸ æœªæ‰¾åˆ°æ´»åŠ¨çš„æµè§ˆå™¨è¿æ¥ä»¥å…³é—­ã€‚") # ä¸­æ–‡

    if playwright_manager:
        print(f"   åœæ­¢ Playwright...") # ä¸­æ–‡
        try:
            await playwright_manager.stop()
            print(f"   âœ… Playwright å·²åœæ­¢ã€‚") # ä¸­æ–‡
        except Exception as stop_err:
            print(f"   âŒ åœæ­¢ Playwright æ—¶å‡ºé”™: {stop_err}") # ä¸­æ–‡
        finally:
            playwright_manager = None
            is_playwright_ready = False
    else:
        print(f"   âš ï¸ æœªæ‰¾åˆ° Playwright ç®¡ç†å™¨ã€‚") # ä¸­æ–‡

    print(f"âœ… FastAPI ç”Ÿå‘½å‘¨æœŸ: å…³é—­å®Œæˆã€‚") # ä¸­æ–‡


# --- FastAPI App ---
app = FastAPI(
    title="AI Studio Proxy Server (Python/FastAPI/Camoufox)",
    description="A proxy server to interact with Google AI Studio using Playwright and Camoufox.",
    version="0.1.0-py",
    lifespan=lifespan # Use the updated lifespan context manager
)

# --- Serve Static HTML for Web UI --- (New Route)
@app.get("/", response_class=FileResponse)
async def read_index():
    # Assumes index.html is in the same directory as server.py
    index_html_path = os.path.join(os.path.dirname(__file__), "index.html")
    if not os.path.exists(index_html_path):
        raise HTTPException(status_code=404, detail="index.html not found")
    return FileResponse(index_html_path)

# --- API Endpoints --- (Translate print statements)
@app.get("/health")
async def health_check():
    status_val = "OK" if is_playwright_ready and is_browser_connected and is_page_ready else "Error"
    status = {
        "status": status_val,
        "message": "",
        "playwrightReady": is_playwright_ready,
        "browserConnected": is_browser_connected,
        "pageReady": is_page_ready,
        "initializing": is_initializing,
    }
    if status_val == "OK":
        status["message"] = "æœåŠ¡è¿è¡Œä¸­ï¼ŒPlaywright æ´»åŠ¨ï¼Œæµè§ˆå™¨å·²è¿æ¥ï¼Œé¡µé¢å·²åˆå§‹åŒ–ã€‚" # ä¸­æ–‡
        return JSONResponse(content=status, status_code=200)
    else:
        reasons = []
        if not is_playwright_ready: reasons.append("Playwright æœªåˆå§‹åŒ–") # ä¸­æ–‡
        if not is_browser_connected: reasons.append("æµè§ˆå™¨æ–­å¼€æˆ–ä¸å¯ç”¨") # ä¸­æ–‡
        if not is_page_ready: reasons.append("ç›®æ ‡é¡µé¢æœªåˆå§‹åŒ–æˆ–æœªå°±ç»ª") # ä¸­æ–‡
        if is_initializing: reasons.append("åˆå§‹åŒ–å½“å‰æ­£åœ¨è¿›è¡Œä¸­") # ä¸­æ–‡
        status["message"] = f"æœåŠ¡ä¸å¯ç”¨ã€‚é—®é¢˜: {', '.join(reasons)}." # ä¸­æ–‡
        return JSONResponse(content=status, status_code=503)

@app.get("/v1/models")
async def list_models():
    print("[API] æ”¶åˆ° /v1/models è¯·æ±‚ã€‚") # ä¸­æ–‡
    return {
        "object": "list",
        "data": [
            {
                "id": MODEL_NAME,
                "object": "model",
                "created": int(time.time()),
                "owned_by": "camoufox-proxy",
                # Add other fields if needed by client
                "permission": [],
                "root": MODEL_NAME,
                "parent": None,
            }
        ]
    }

# --- Helper: Detect Error ---
async def detect_and_extract_page_error(page: AsyncPage, req_id: str):
    """æ£€æŸ¥å¯è§çš„é”™è¯¯/è­¦å‘Šæç¤ºæ¡†å¹¶æå–æ¶ˆæ¯ã€‚"""
    error_toast_locator = page.locator(ERROR_TOAST_SELECTOR).last
    try:
        await error_toast_locator.wait_for(state='visible', timeout=1500)
        print(f"[{req_id}]    æ£€æµ‹åˆ°é”™è¯¯/è­¦å‘Šæç¤ºæ¡†å…ƒç´ ã€‚") # ä¸­æ–‡
        message_locator = error_toast_locator.locator('span.content-text')
        error_message = await message_locator.text_content(timeout=1000)
        if error_message:
             print(f"[{req_id}]    æå–çš„é”™è¯¯æ¶ˆæ¯: {error_message}") # ä¸­æ–‡
             return error_message.strip()
        else:
             print(f"[{req_id}]    è­¦å‘Š: æ£€æµ‹åˆ°æç¤ºæ¡†ï¼Œä½†æ— æ³•ä» span.content-text æå–ç‰¹å®šæ¶ˆæ¯ã€‚") # ä¸­æ–‡
             return "æ£€æµ‹åˆ°é”™è¯¯æç¤ºæ¡†ï¼Œä½†æ— æ³•æå–ç‰¹å®šæ¶ˆæ¯ã€‚" # ä¸­æ–‡
    except PlaywrightAsyncError:
        return None
    except Exception as e:
        print(f"[{req_id}]    è­¦å‘Š: æ£€æŸ¥é¡µé¢é”™è¯¯æ—¶å‡ºé”™: {e}") # ä¸­æ–‡
        return None

# --- Helper: Try Parse JSON ---
def try_parse_json(text: str, req_id: str):
    """Attempts to find and parse the outermost JSON object/array in text."""
    if not text or not isinstance(text, str):
        return None
    text = text.strip()

    start_index = -1
    end_index = -1

    first_brace = text.find('{')
    first_bracket = text.find('[')

    # Prioritize object if both found and object starts earlier
    if first_brace != -1 and (first_bracket == -1 or first_brace < first_bracket):
        start_index = first_brace
        end_index = text.rfind('}')
    elif first_bracket != -1:
        start_index = first_bracket
        end_index = text.rfind(']')

    if start_index == -1 or end_index == -1 or end_index < start_index:
        # print(f"[{req_id}] (JSON Parse) Could not find valid start/end markers.") # Optional debug
        return None

    json_text = text[start_index : end_index + 1]

    try:
        return json.loads(json_text)
    except json.JSONDecodeError as e:
        # print(f"[{req_id}] (JSON Parse) Failed for extracted text: {e}") # Optional debug
        return None

# --- Snapshot Helper --- (Translate logs)
async def save_error_snapshot(error_name: str = 'error'):
    """å‘ç”Ÿé”™è¯¯æ—¶ä¿å­˜å±å¹•æˆªå›¾å’Œ HTML å¿«ç…§ã€‚"""
    name_parts = error_name.split('_')
    req_id = name_parts[-1] if len(name_parts) > 1 and len(name_parts[-1]) == 7 else None
    base_error_name = error_name if not req_id else '_'.join(name_parts[:-1])
    log_prefix = f"[{req_id}]" if req_id else "[æ— è¯·æ±‚ID]" # ä¸­æ–‡

    if not browser_instance or not browser_instance.is_connected() or not page_instance or page_instance.is_closed():
        print(f"{log_prefix} æ— æ³•ä¿å­˜å¿«ç…§ ({base_error_name})ï¼Œæµè§ˆå™¨/é¡µé¢ä¸å¯ç”¨ã€‚") # ä¸­æ–‡
        return

    print(f"{log_prefix} å°è¯•ä¿å­˜é”™è¯¯å¿«ç…§ ({base_error_name})...") # ä¸­æ–‡
    timestamp = int(time.time() * 1000)
    error_dir = os.path.join(os.path.dirname(__file__), 'errors_py')
    try:
        if not os.path.exists(error_dir):
            os.makedirs(error_dir, exist_ok=True)

        filename_suffix = f"{req_id}_{timestamp}" if req_id else f"{timestamp}"
        filename_base = f"{base_error_name}_{filename_suffix}"
        screenshot_path = os.path.join(error_dir, f"{filename_base}.png")
        html_path = os.path.join(error_dir, f"{filename_base}.html")

        try:
            await page_instance.screenshot(path=screenshot_path, full_page=True, timeout=15000)
            print(f"{log_prefix}   å¿«ç…§å·²ä¿å­˜åˆ°: {screenshot_path}") # ä¸­æ–‡
        except Exception as ss_err:
            print(f"{log_prefix}   ä¿å­˜å±å¹•æˆªå›¾å¤±è´¥ ({base_error_name}): {ss_err}") # ä¸­æ–‡

        try:
            content = await page_instance.content()
            with open(html_path, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"{log_prefix}   HTML å·²ä¿å­˜åˆ°: {html_path}") # ä¸­æ–‡
        except Exception as html_err:
            print(f"{log_prefix}   ä¿å­˜ HTML å¤±è´¥ ({base_error_name}): {html_err}") # ä¸­æ–‡

    except Exception as dir_err:
        print(f"{log_prefix}   åˆ›å»ºé”™è¯¯ç›®å½•æˆ–ä¿å­˜å¿«ç…§æ—¶å‡ºé”™: {dir_err}") # ä¸­æ–‡

# --- Main Chat Completion Logic --- (Remove Clear Chat, add delay, translate logs)
async def process_chat_request(req_id: str, request: ChatCompletionRequest, http_request: Request):
    print(f"[{req_id}] å¤„ç†èŠå¤©è¯·æ±‚...") # ä¸­æ–‡
    is_streaming = request.stream

    if not page_instance or page_instance.is_closed() or not is_page_ready:
        print(f"[{req_id}] é”™è¯¯: é¡µé¢åœ¨å¤„ç†æœŸé—´å˜å¾—æ— æ•ˆ (is_closed={page_instance.is_closed()}, is_page_ready={is_page_ready}).") # ä¸­æ–‡
        raise HTTPException(status_code=503, detail=f"[{req_id}] AI Studio é¡µé¢åœ¨å¤„ç†è¿‡ç¨‹ä¸­ä¸¢å¤±æˆ–æœªå°±ç»ªã€‚") # ä¸­æ–‡

    page = page_instance

    # 1. Validation
    try:
         validation_result = validate_chat_request(request.messages, req_id)
         user_prompt = validation_result["userPrompt"]
         system_prompt = validation_result["systemPrompt"]
         if user_prompt is None:
             raise ValueError("å¤„ç†åçš„ç”¨æˆ·æç¤ºæ„å¤–ä¸º Noneã€‚") # ä¸­æ–‡
    except ValueError as e:
        raise HTTPException(status_code=400, detail=f"[{req_id}] æ— æ•ˆè¯·æ±‚: {e}") # ä¸­æ–‡

    print(f"[{req_id}] ç”¨æˆ·æç¤º (å·²éªŒè¯, é•¿åº¦={len(user_prompt)}): '{user_prompt[:80]}...'") # ä¸­æ–‡
    if system_prompt:
        print(f"[{req_id}] ç³»ç»Ÿæç¤º (å·²éªŒè¯, é•¿åº¦={len(system_prompt)}): '{system_prompt[:80]}...'") # ä¸­æ–‡

    # 2. Prepare Prompt
    if is_streaming:
         prepared_prompt = prepare_ai_studio_prompt_stream(user_prompt, system_prompt)
         print(f"[{req_id}] å‡†å¤‡å¥½çš„æµå¼æç¤º (å¼€å§‹): '{prepared_prompt[:150]}...'") # ä¸­æ–‡
    else:
         prepared_prompt = prepare_ai_studio_prompt(user_prompt, system_prompt)
         print(f"[{req_id}] å‡†å¤‡å¥½çš„éæµå¼æç¤º (å¼€å§‹): '{prepared_prompt[:150]}...'") # ä¸­æ–‡

    # --- Client Disconnect Handling --- (Translate logs)
    client_disconnected = False
    disconnect_event = asyncio.Event()
    disconnect_task = None
    async def check_disconnect():
        nonlocal client_disconnected, disconnect_task
        try:
            while True:
                disconnected = await http_request.is_disconnected()
                if disconnected:
                    client_disconnected = True
                    disconnect_event.set()
                    print(f"[{req_id}] å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ (é€šè¿‡è½®è¯¢æ£€æµ‹åˆ°)ã€‚") # ä¸­æ–‡
                    break
                await asyncio.sleep(0.5)
        except asyncio.CancelledError:
            pass
        except Exception as e:
             if not client_disconnected:
                 client_disconnected = True
                 disconnect_event.set()
                 print(f"[{req_id}] å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ (é€šè¿‡å¼‚å¸¸æ£€æµ‹åˆ°: {type(e).__name__})ã€‚") # ä¸­æ–‡

    disconnect_task = asyncio.create_task(check_disconnect())
    # --- End Client Disconnect Handling ---

    try:
        # --- REMOVED Clear Chat Logic --- 

        # 3. Interact and Submit (Modified: Use Keyboard Shortcut first)
        print(f"[{req_id}] å¡«å……æç¤ºå¹¶ç‚¹å‡»æäº¤...") # ä¸­æ–‡
        input_field = page.locator(INPUT_SELECTOR)
        submit_button = page.locator(SUBMIT_BUTTON_SELECTOR)

        await expect_async(input_field).to_be_visible(timeout=10000)
        await input_field.fill(prepared_prompt, timeout=60000)
        await expect_async(submit_button).to_be_enabled(timeout=10000)

        print(f"[{req_id}] ç­‰å¾…ä¸€å°æ®µæ—¶é—´è®©UIç¨³å®š...") # ä¸­æ–‡
        await page.wait_for_timeout(200) # Add small delay

        # --- Try submitting with Control+Enter first ---
        submitted_successfully = False
        try:
            print(f"[{req_id}] å°è¯•ä½¿ç”¨ Control+Enter å¿«æ·é”®æäº¤...") # ä¸­æ–‡
            await page.keyboard.press('Control+Enter')
            # Heuristic check: See if input field clears quickly after sending
            await expect_async(input_field).to_have_value('', timeout=2000) 
            print(f"[{req_id}] å¿«æ·é”®æäº¤æˆåŠŸ (è¾“å…¥æ¡†å·²æ¸…ç©º)ã€‚") # ä¸­æ–‡
            submitted_successfully = True
        except PlaywrightAsyncError as key_press_error:
            print(f"[{req_id}] è­¦å‘Š: Control+Enter å¿«æ·é”®æäº¤å¤±è´¥æˆ–æœªåŠæ—¶æ¸…ç©ºè¾“å…¥æ¡†: {key_press_error.message.split('\n')[0]}") # ä¸­æ–‡
            # Fallback to clicking the button

        # --- Fallback to clicking if shortcut failed ---
        if not submitted_successfully:
            print(f"[{req_id}] å¿«æ·é”®æäº¤å¤±è´¥ï¼Œå›é€€åˆ°æ¨¡æ‹Ÿç‚¹å‡»æäº¤æŒ‰é’®...") # ä¸­æ–‡
            print(f"[{req_id}] ç¡®ä¿æäº¤æŒ‰é’®åœ¨è§†å›¾ä¸­...") # ä¸­æ–‡
            try:
                await submit_button.scroll_into_view_if_needed(timeout=5000)
                print(f"[{req_id}] æäº¤æŒ‰é’®å·²æ»šåŠ¨åˆ°è§†å›¾ä¸­ (å¦‚æœéœ€è¦)ã€‚") # ä¸­æ–‡
            except Exception as scroll_err:
                print(f"[{req_id}] è­¦å‘Š: å°†æäº¤æŒ‰é’®æ»šåŠ¨åˆ°è§†å›¾ä¸­å¤±è´¥: {scroll_err}") # ä¸­æ–‡

            print(f"[{req_id}] ç‚¹å‡»æäº¤æŒ‰é’® (force=True)...") # ä¸­æ–‡
            try:
                 await submit_button.click(timeout=10000, force=True)
                 # Add a slightly longer check after click fallback
                 await expect_async(input_field).to_have_value('', timeout=3000)
                 print(f"[{req_id}] æ¨¡æ‹Ÿç‚¹å‡»æäº¤æˆåŠŸ (è¾“å…¥æ¡†å·²æ¸…ç©º)ã€‚") # ä¸­æ–‡
                 submitted_successfully = True
            except PlaywrightAsyncError as click_error:
                 print(f"[{req_id}] âŒ é”™è¯¯: æ¨¡æ‹Ÿç‚¹å‡»æäº¤æŒ‰é’®ä¹Ÿå¤±è´¥äº†: {click_error.message.split('\n')[0]}") # ä¸­æ–‡
                 await save_error_snapshot(f"submit_fallback_click_fail_{req_id}")
                 raise click_error # Re-raise the error if both methods fail

        # 4. Locate Response Element
        print(f"[{req_id}] å®šä½å“åº”å…ƒç´ ...") # ä¸­æ–‡
        response_element = page.locator(RESPONSE_CONTAINER_SELECTOR).last.locator(RESPONSE_TEXT_SELECTOR)
        # Increase timeout slightly for response element appearance after potential submit delay
        await expect_async(response_element).to_be_attached(timeout=20000) 
        print(f"[{req_id}] å“åº”å…ƒç´ å·²å®šä½ã€‚") # ä¸­æ–‡

        # 5. Handle Response (Streaming or Non-streaming)
        if is_streaming:
            print(f"[{req_id}] å¤„ç† SSE æµ...") # ä¸­æ–‡
            async def stream_generator():
                last_raw_text = ""
                last_sent_response_content = ""
                response_started = False
                spinner_disappeared = False
                last_text_change_timestamp = time.time() * 1000
                stream_finished_naturally = False
                start_time = time.time() * 1000
                spinner_locator = page.locator(LOADING_SPINNER_SELECTOR)
                start_marker = '<<<START_RESPONSE>>>'
                loop_counter = 0
                last_scroll_time = 0 # Track last scroll time
                scroll_interval_ms = 3000 # Scroll every 3 seconds

                try:
                    while time.time() * 1000 - start_time < RESPONSE_COMPLETION_TIMEOUT:
                        current_loop_time_ms = time.time() * 1000 # Get current time in ms
                        if client_disconnected:
                             print(f"[{req_id}] ç”±äºå®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼Œåœæ­¢æµç”Ÿæˆå™¨ã€‚") # ä¸­æ–‡
                             break

                        loop_start_time = time.time() * 1000
                        loop_counter += 1

                        # --- Periodic Scroll --- 
                        if current_loop_time_ms - last_scroll_time > scroll_interval_ms:
                            try:
                                # print(f"[{req_id}] (Stream) Scrolling to bottom...") # Optional debug log
                                await page.evaluate('window.scrollTo(0, document.body.scrollHeight)')
                                last_scroll_time = current_loop_time_ms
                            except Exception as scroll_e:
                                print(f"[{req_id}] (Stream) è­¦å‘Š: æ»šåŠ¨åˆ°åº•éƒ¨å¤±è´¥: {scroll_e}")
                        # --- End Periodic Scroll ---

                        if loop_counter % 10 == 0:
                             page_err_stream_periodic = await detect_and_extract_page_error(page, req_id)
                             if page_err_stream_periodic:
                                  print(f"[{req_id}] âŒ æµå¤„ç†æœŸé—´æ£€æµ‹åˆ°é”™è¯¯ (å‘¨æœŸæ€§æ£€æŸ¥): {page_err_stream_periodic}") # ä¸­æ–‡
                                  await save_error_snapshot(f"page_error_stream_periodic_{req_id}")
                                  yield generate_sse_error_chunk(f"AI Studio é”™è¯¯: {page_err_stream_periodic}", req_id, "upstream_error") # ä¸­æ–‡
                                  yield "data: [DONE]\n\n"
                                  return
                        
                        current_raw_text = await get_raw_text_content(response_element, last_raw_text, req_id)

                        if current_raw_text != last_raw_text:
                            last_text_change_timestamp = time.time() * 1000
                            potential_new_delta = ""
                            current_content_after_marker = ""

                            marker_index = current_raw_text.find(start_marker)
                            if marker_index != -1:
                                if not response_started:
                                    print(f"[{req_id}]    (æµ) æ‰¾åˆ°èµ·å§‹æ ‡è®° '{start_marker}'.") # ä¸­æ–‡
                                    response_started = True
                                current_content_after_marker = current_raw_text[marker_index + len(start_marker):]
                                potential_new_delta = current_content_after_marker[len(last_sent_response_content):]
                            elif response_started:
                                 potential_new_delta = ""
                                 print(f"[{req_id}] è­¦å‘Š: èµ·å§‹æ ‡è®°åœ¨è¢«çœ‹åˆ°åæ¶ˆå¤±äº†ã€‚") # ä¸­æ–‡

                            if potential_new_delta:
                                yield generate_sse_chunk(potential_new_delta, req_id, MODEL_NAME)
                                last_sent_response_content += potential_new_delta

                            last_raw_text = current_raw_text

                        if not spinner_disappeared:
                             try:
                                 if await spinner_locator.is_hidden():
                                     spinner_disappeared = True
                                     last_text_change_timestamp = time.time() * 1000
                                     print(f"[{req_id}]    Spinner å·²éšè—ã€‚æ£€æŸ¥é™é»˜çŠ¶æ€...") # ä¸­æ–‡
                             except PlaywrightAsyncError:
                                 pass
                        
                        is_silent = spinner_disappeared and (time.time() * 1000 - last_text_change_timestamp > SILENCE_TIMEOUT_MS)
                        if is_silent:
                            print(f"[{req_id}] æ£€æµ‹åˆ°é™é»˜ã€‚å®Œæˆæµã€‚") # ä¸­æ–‡
                            stream_finished_naturally = True
                            break

                        loop_duration = time.time() * 1000 - loop_start_time
                        wait_time = max(0, POLLING_INTERVAL_STREAM - loop_duration) / 1000
                        await asyncio.sleep(wait_time)

                    if client_disconnected:
                         yield generate_sse_stop_chunk(req_id, MODEL_NAME, "client_disconnect")
                         return

                    page_err_stream_final = await detect_and_extract_page_error(page, req_id)
                    if page_err_stream_final:
                        print(f"[{req_id}] âŒ åœ¨å®Œæˆæµä¹‹å‰æ£€æµ‹åˆ°é”™è¯¯: {page_err_stream_final}") # ä¸­æ–‡
                        await save_error_snapshot(f"page_error_stream_final_{req_id}")
                        yield generate_sse_error_chunk(f"AI Studio é”™è¯¯: {page_err_stream_final}", req_id, "upstream_error") # ä¸­æ–‡
                        yield "data: [DONE]\n\n"
                        return
                    
                    if stream_finished_naturally:
                        final_raw_text = await get_raw_text_content(response_element, last_raw_text, req_id)
                        final_content_after_marker = ""
                        final_marker_index = final_raw_text.find(start_marker)
                        if final_marker_index != -1:
                             final_content_after_marker = final_raw_text[final_marker_index + len(start_marker):]
                        final_delta = final_content_after_marker[len(last_sent_response_content):]
                        if final_delta:
                             print(f"[{req_id}] å‘é€æœ€ç»ˆå¢é‡ (é•¿åº¦: {len(final_delta)})") # ä¸­æ–‡
                             yield generate_sse_chunk(final_delta, req_id, MODEL_NAME)

                        yield generate_sse_stop_chunk(req_id, MODEL_NAME)
                        print(f"[{req_id}] âœ… æµè‡ªç„¶å®Œæˆã€‚") # ä¸­æ–‡
                    else: 
                        print(f"[{req_id}] âš ï¸ æµåœ¨ {RESPONSE_COMPLETION_TIMEOUT / 1000} ç§’åè¶…æ—¶ã€‚") # ä¸­æ–‡
                        await save_error_snapshot(f"streaming_timeout_{req_id}")
                        yield generate_sse_error_chunk("æµå¤„ç†åœ¨æœåŠ¡å™¨ä¸Šè¶…æ—¶ã€‚", req_id) # ä¸­æ–‡
                        yield generate_sse_stop_chunk(req_id, MODEL_NAME, "timeout")

                    yield "data: [DONE]\n\n"

                except asyncio.CancelledError:
                     print(f"[{req_id}] æµç”Ÿæˆå™¨å·²å–æ¶ˆ (å¯èƒ½å®¢æˆ·ç«¯æ–­å¼€è¿æ¥)ã€‚") # ä¸­æ–‡
                     yield "data: [DONE]\n\n"
                except Exception as e:
                    print(f"[{req_id}] âŒ æµå¼ç”ŸæˆæœŸé—´å‡ºé”™: {e}") # ä¸­æ–‡
                    await save_error_snapshot(f"streaming_error_{req_id}")
                    traceback.print_exc()
                    yield generate_sse_error_chunk(f"æµå¼å¤„ç†æœŸé—´æœåŠ¡å™¨é”™è¯¯: {e}", req_id) # ä¸­æ–‡
                    yield "data: [DONE]\n\n"

            return StreamingResponse(stream_generator(), media_type="text/event-stream")

        else: # Non-streaming
            print(f"[{req_id}] å¤„ç†éæµå¼å“åº”...") # ä¸­æ–‡
            start_time_ns = time.time()
            final_state_reached = False
            final_state_check_initiated = False
            spinner_locator = page.locator(LOADING_SPINNER_SELECTOR)
            input_field = page.locator(INPUT_SELECTOR)
            submit_button = page.locator(SUBMIT_BUTTON_SELECTOR)
            last_scroll_time_ns = 0 # Track last scroll time
            scroll_interval_ms_ns = 3000 # Scroll every 3 seconds

            while time.time() - start_time_ns < RESPONSE_COMPLETION_TIMEOUT / 1000:
                current_loop_time_ms_ns = time.time() * 1000
                if client_disconnected:
                    print(f"[{req_id}] ç”±äºå®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼Œéæµå¼å¤„ç†å·²å–æ¶ˆã€‚") # ä¸­æ–‡
                    raise HTTPException(status_code=499, detail=f"[{req_id}] å®¢æˆ·ç«¯å…³é—­äº†è¯·æ±‚") # ä¸­æ–‡

                # --- Periodic Scroll --- 
                if current_loop_time_ms_ns - last_scroll_time_ns > scroll_interval_ms_ns:
                    try:
                        # print(f"[{req_id}] (Non-Stream) Scrolling to bottom...") # Optional debug log
                        await page.evaluate('window.scrollTo(0, document.body.scrollHeight)')
                        last_scroll_time_ns = current_loop_time_ms_ns
                    except Exception as scroll_e:
                        print(f"[{req_id}] (Non-Stream) è­¦å‘Š: æ»šåŠ¨åˆ°åº•éƒ¨å¤±è´¥: {scroll_e}")
                # --- End Periodic Scroll ---

                spinner_hidden = False
                input_empty = False
                button_disabled = False

                try:
                    await expect_async(spinner_locator).to_be_hidden(timeout=SPINNER_CHECK_TIMEOUT_MS)
                    spinner_hidden = True
                except PlaywrightAsyncError: pass

                if spinner_hidden:
                    try:
                        await expect_async(input_field).to_have_value('', timeout=FINAL_STATE_CHECK_TIMEOUT_MS)
                        input_empty = True
                    except PlaywrightAsyncError: pass

                    if input_empty:
                        try:
                            await expect_async(submit_button).to_be_disabled(timeout=FINAL_STATE_CHECK_TIMEOUT_MS)
                            button_disabled = True
                        except PlaywrightAsyncError: pass

                if spinner_hidden and input_empty and button_disabled:
                    if not final_state_check_initiated:
                        final_state_check_initiated = True
                        print(f"[{req_id}]    æ£€æµ‹åˆ°æ½œåœ¨æœ€ç»ˆçŠ¶æ€ã€‚ç­‰å¾… {POST_COMPLETION_BUFFER} æ¯«ç§’ä»¥ç¡®è®¤...") # ä¸­æ–‡
                        await asyncio.sleep(POST_COMPLETION_BUFFER / 1000)
                        print(f"[{req_id}]    {POST_COMPLETION_BUFFER} æ¯«ç§’ç­‰å¾…ç»“æŸã€‚ä¸¥æ ¼é‡æ–°æ£€æŸ¥çŠ¶æ€...") # ä¸­æ–‡
                        try:
                            await expect_async(spinner_locator).to_be_hidden(timeout=500)
                            await expect_async(input_field).to_have_value('', timeout=500)
                            await expect_async(submit_button).to_be_disabled(timeout=500)
                            print(f"[{req_id}]    çŠ¶æ€å·²ç¡®è®¤ã€‚æ£€æŸ¥æ–‡æœ¬ç¨³å®šæ€§ {SILENCE_TIMEOUT_MS} æ¯«ç§’...") # ä¸­æ–‡

                            text_stable = False
                            silence_check_start_time = time.time()
                            last_check_text = await get_raw_text_content(response_element, '', req_id)

                            while time.time() - silence_check_start_time < SILENCE_TIMEOUT_MS / 1000:
                                await asyncio.sleep(POLLING_INTERVAL / 1000)
                                current_check_text = await get_raw_text_content(response_element, '', req_id)
                                if current_check_text == last_check_text:
                                    if time.time() - silence_check_start_time >= SILENCE_TIMEOUT_MS / 1000:
                                         print(f"[{req_id}]    æ–‡æœ¬ç¨³å®š {SILENCE_TIMEOUT_MS} æ¯«ç§’ã€‚å¤„ç†å®Œæˆã€‚") # ä¸­æ–‡
                                         text_stable = True
                                         break
                                else:
                                    print(f"[{req_id}]    (é™é»˜æ£€æŸ¥) æ–‡æœ¬å·²æ›´æ”¹ã€‚é‡ç½®è®¡æ—¶å™¨ã€‚") # ä¸­æ–‡
                                    silence_check_start_time = time.time()
                                    last_check_text = current_check_text

                            if text_stable:
                                final_state_reached = True
                                break
                            else:
                                print(f"[{req_id}]    âš ï¸ è­¦å‘Š: æ–‡æœ¬é™é»˜æ£€æŸ¥åœ¨ {SILENCE_TIMEOUT_MS} æ¯«ç§’åè¶…æ—¶ã€‚æ— è®ºå¦‚ä½•ç»§ç»­ã€‚") # ä¸­æ–‡
                                final_state_reached = True
                                break

                        except PlaywrightAsyncError as recheck_error:
                            print(f"[{req_id}]    çŠ¶æ€åœ¨ç¡®è®¤æœŸé—´å‘ç”Ÿå˜åŒ– ({recheck_error})ã€‚ç»§ç»­è½®è¯¢ã€‚") # ä¸­æ–‡
                            final_state_check_initiated = False
                        except Exception as stability_err:
                             print(f"[{req_id}]    æ–‡æœ¬ç¨³å®šæ€§æ£€æŸ¥æœŸé—´å‡ºé”™: {stability_err}") # ä¸­æ–‡
                             traceback.print_exc()
                             final_state_check_initiated = False

                else:
                    if final_state_check_initiated:
                         print(f"[{req_id}]    æœ€ç»ˆçŠ¶æ€æ¡ä»¶ä¸å†æ»¡è¶³ã€‚é‡ç½®ç¡®è®¤æ ‡å¿—ã€‚") # ä¸­æ–‡
                         final_state_check_initiated = False
                    await asyncio.sleep(POLLING_INTERVAL * 2 / 1000)

            if client_disconnected:
                 raise HTTPException(status_code=499, detail=f"[{req_id}] å®¢æˆ·ç«¯å…³é—­äº†è¯·æ±‚") # ä¸­æ–‡

            print(f"[{req_id}] åœ¨æœ€ç»ˆè§£æå‰æ£€æŸ¥é¡µé¢é”™è¯¯...") # ä¸­æ–‡
            page_err_nonstream = await detect_and_extract_page_error(page, req_id)
            if page_err_nonstream:
                 print(f"[{req_id}] âŒ åœ¨æœ€ç»ˆè§£æå‰æ£€æµ‹åˆ°é”™è¯¯: {page_err_nonstream}") # ä¸­æ–‡
                 await save_error_snapshot(f"page_error_nonstream_{req_id}")
                 raise HTTPException(status_code=502, detail=f"[{req_id}] AI Studio é”™è¯¯: {page_err_nonstream}") # ä¸­æ–‡

            if not final_state_reached:
                 print(f"[{req_id}] âš ï¸ éæµå¼ç­‰å¾…è¶…æ—¶ã€‚å°è¯•å†…å®¹æ£€ç´¢ã€‚") # ä¸­æ–‡
                 await save_error_snapshot(f"nonstream_final_state_timeout_{req_id}")
            else:
                 print(f"[{req_id}] âœ… æœ€ç»ˆçŠ¶æ€å·²åˆ°è¾¾ã€‚è·å–å¹¶è§£ææœ€ç»ˆå†…å®¹...") # ä¸­æ–‡

            final_content_for_user = ""
            try:
                 final_raw_text = await get_raw_text_content(response_element, '', req_id)
                 print(f"[{req_id}] æœ€ç»ˆåŸå§‹æ–‡æœ¬ (é•¿åº¦={len(final_raw_text)}): '{final_raw_text[:100]}...'") # ä¸­æ–‡

                 if not final_raw_text or not final_raw_text.strip():
                     print(f"[{req_id}] è­¦å‘Š: ä»å“åº”å…ƒç´ è·å–çš„åŸå§‹æ–‡æœ¬ä¸ºç©ºã€‚") # ä¸­æ–‡
                     final_content_for_user = ""
                 else:
                    parsed_json = try_parse_json(final_raw_text, req_id)
                    ai_response_text_from_json = None

                    if parsed_json:
                         if isinstance(parsed_json.get("response"), str):
                              ai_response_text_from_json = parsed_json["response"]
                              print(f"[{req_id}]    ä» JSON ä¸­æå–äº† 'response' å­—æ®µã€‚") # ä¸­æ–‡
                         else:
                             try:
                                 ai_response_text_from_json = json.dumps(parsed_json)
                                 print(f"[{req_id}]    è­¦å‘Š: åœ¨ JSON ä¸­æœªæ‰¾åˆ°/éå­—ç¬¦ä¸² 'response' å­—æ®µã€‚ä½¿ç”¨å­—ç¬¦ä¸²åŒ–çš„ JSONã€‚") # ä¸­æ–‡
                             except Exception as stringify_err:
                                  print(f"[{req_id}]    å­—ç¬¦ä¸²åŒ–è§£æçš„ JSON æ—¶å‡ºé”™: {stringify_err}") # ä¸­æ–‡
                                  ai_response_text_from_json = final_raw_text
                    else:
                        print(f"[{req_id}]    è­¦å‘Š: æ— æ³•ä»åŸå§‹æ–‡æœ¬è§£æ JSONã€‚ä½¿ç”¨åŸå§‹æ–‡æœ¬ä½œä¸ºå“åº”ã€‚") # ä¸­æ–‡
                        ai_response_text_from_json = final_raw_text
                    
                    start_marker = '<<<START_RESPONSE>>>'
                    if ai_response_text_from_json and ai_response_text_from_json.startswith(start_marker):
                        final_content_for_user = ai_response_text_from_json[len(start_marker):]
                        print(f"[{req_id}]    ç§»é™¤äº†èµ·å§‹æ ‡è®°ã€‚") # ä¸­æ–‡
                    elif ai_response_text_from_json:
                        final_content_for_user = ai_response_text_from_json
                        print(f"[{req_id}]    è­¦å‘Š: åœ¨æœ€ç»ˆæ–‡æœ¬ä¸­æœªæ‰¾åˆ°èµ·å§‹æ ‡è®°ã€‚") # ä¸­æ–‡
                    else:
                         final_content_for_user = ""

            except Exception as e:
                print(f"[{req_id}] âŒ è·å–/è§£ææœ€ç»ˆéæµå¼å†…å®¹æ—¶å‡ºé”™: {e}") # ä¸­æ–‡
                await save_error_snapshot(f"get_final_content_error_{req_id}")
                traceback.print_exc()
                raise HTTPException(status_code=500, detail=f"[{req_id}] å¤„ç†æœ€ç»ˆå“åº”æ—¶å‡ºé”™: {e}") # ä¸­æ–‡

            response_payload = {
                "id": f"{CHAT_COMPLETION_ID_PREFIX}{req_id}-{int(time.time())}",
                "object": "chat.completion",
                "created": int(time.time()),
                "model": MODEL_NAME,
                "choices": [{
                    "index": 0,
                    "message": {"role": "assistant", "content": final_content_for_user},
                    "finish_reason": "stop",
                }],
                "usage": {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0},
            }
            return JSONResponse(content=response_payload)

    except PlaywrightAsyncError as e:
        print(f"[{req_id}] âŒ Playwright å¤„ç†æœŸé—´å‡ºé”™: {e}") # ä¸­æ–‡
        await save_error_snapshot(f"playwright_error_{req_id}") # Pass req_id here
        raise HTTPException(status_code=500, detail=f"[{req_id}] Playwright é”™è¯¯: {e}") # ä¸­æ–‡
    except HTTPException:
         raise
    except Exception as e:
        print(f"[{req_id}] âŒ å¤„ç†æœŸé—´æ„å¤–é”™è¯¯: {e}") # ä¸­æ–‡
        await save_error_snapshot(f"unexpected_error_{req_id}") # Pass req_id here
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"[{req_id}] æ„å¤–æœåŠ¡å™¨é”™è¯¯: {e}") # ä¸­æ–‡
    finally:
         if disconnect_task and not disconnect_task.done():
              disconnect_task.cancel()
              try: await disconnect_task
              except asyncio.CancelledError: pass
         print(f"[{req_id}] --- å®Œæˆå¤„ç†èŠå¤©è¯·æ±‚ --- ") # ä¸­æ–‡


@app.post("/v1/chat/completions")
async def chat_completions(request: ChatCompletionRequest, http_request: Request):
    req_id = ''.join(random.choices('abcdefghijklmnopqrstuvwxyz0123456789', k=7))
    print(f"[{req_id}] === æ”¶åˆ° /v1/chat/completions è¯·æ±‚ === æ¨¡å¼: {'æµå¼' if request.stream else 'éæµå¼'}") # ä¸­æ–‡

    if is_initializing:
        print(f"[{req_id}] â³ æœåŠ¡ä»åœ¨åˆå§‹åŒ–ã€‚è¯·æ±‚å¯èƒ½å»¶è¿Ÿæˆ–å¤±è´¥ã€‚") # ä¸­æ–‡
        raise HTTPException(status_code=503, detail=f"[{req_id}] æœåŠ¡åˆå§‹åŒ–ä¸­ï¼Œè¯·ç¨åé‡è¯•ã€‚") # ä¸­æ–‡
    if not is_playwright_ready or not is_browser_connected or not is_page_ready:
         print(f"[{req_id}] âŒ è¯·æ±‚å¤±è´¥: æœåŠ¡æœªå®Œå…¨å°±ç»ª (Playwright:{is_playwright_ready}, Browser:{is_browser_connected}, Page:{is_page_ready}).") # ä¸­æ–‡
         raise HTTPException(status_code=503, detail=f"[{req_id}] ä¸ Camoufox æµè§ˆå™¨/é¡µé¢çš„è¿æ¥æœªæ¿€æ´»ã€‚è¯·ç¡®ä¿ camoufox æœåŠ¡å™¨æ­£åœ¨è¿è¡Œå¹¶é‡è¯•ã€‚") # ä¸­æ–‡

    try:
        return await asyncio.wait_for(
             process_chat_request(req_id, request, http_request),
             timeout=RESPONSE_COMPLETION_TIMEOUT / 1000
        )
    except asyncio.TimeoutError:
        print(f"[{req_id}] âŒ æ•´ä½“è¯·æ±‚åœ¨ {RESPONSE_COMPLETION_TIMEOUT / 1000} ç§’åè¶…æ—¶ã€‚") # ä¸­æ–‡
        if request.stream:
            error_chunk = generate_sse_error_chunk("æ•´ä½“è¯·æ±‚è¶…æ—¶ã€‚", req_id, "timeout_error") # ä¸­æ–‡
            done_chunk = "data: [DONE]\n\n"
            return StreamingResponse(iter([error_chunk, done_chunk]), media_type="text/event-stream", status_code=504)
        else:
            raise HTTPException(status_code=504, detail=f"[{req_id}] æ•´ä½“è¯·æ±‚å¤„ç†è¶…æ—¶ã€‚") # ä¸­æ–‡
    except HTTPException as http_exc:
         raise http_exc
    except Exception as e:
         print(f"[{req_id}] âŒ å®Œæˆç«¯ç‚¹çº§åˆ«å‘ç”Ÿæ„å¤–é”™è¯¯: {e}") # ä¸­æ–‡
         raise HTTPException(status_code=500, detail=f"[{req_id}] è¯·æ±‚å¤„ç†æœŸé—´æ„å¤–çš„æœåŠ¡å™¨é”™è¯¯ã€‚") # ä¸­æ–‡

# --- __main__ block --- (Translate print statements)
if __name__ == "__main__":
    check_dependencies()

    SERVER_PORT = 2048
    print(f"--- æ­¥éª¤ 2: å‡†å¤‡å¯åŠ¨ FastAPI/Uvicorn (ç«¯å£: {SERVER_PORT}) ---") # ä¸­æ–‡
    import uvicorn

    try:
        uvicorn.run(
            "server:app",
            host="127.0.0.1",
            port=SERVER_PORT,
            log_level="info",
            workers=1,
            use_colors=False
        )
    except OSError as e:
        if e.errno == 48:
            print(f"\nâŒ é”™è¯¯ï¼šç«¯å£ {SERVER_PORT} å·²è¢«å ç”¨ï¼") # ä¸­æ–‡ (Keep f-string correction)
            print("   Uvicorn æ— æ³•ç»‘å®šåˆ°è¯¥ç«¯å£ã€‚") # ä¸­æ–‡
            print("   è¯·æ‰‹åŠ¨æŸ¥æ‰¾å¹¶ç»“æŸå ç”¨è¯¥ç«¯å£çš„è¿›ç¨‹:") # ä¸­æ–‡
            print(f"     1. æŸ¥æ‰¾è¿›ç¨‹ PID: lsof -t -i:{SERVER_PORT}")
            print(f"     2. ç»“æŸè¿›ç¨‹ (æ›¿æ¢ <PID>): kill -9 <PID>")
            print("   ç„¶åé‡æ–°è¿è¡Œæ­¤è„šæœ¬ã€‚") # ä¸­æ–‡
            sys.exit(1)
        else:
            print(f"âŒ å‘ç”Ÿæœªå¤„ç†çš„ OS é”™è¯¯: {e}") # ä¸­æ–‡
            raise e
    except Exception as e:
         print(f"âŒ å¯åŠ¨æœåŠ¡å™¨æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}") # ä¸­æ–‡
         traceback.print_exc()
         sys.exit(1) 