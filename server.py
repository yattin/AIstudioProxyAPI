import asyncio
import random
import time
import json
from typing import List, Optional, Dict, Any, Union, AsyncGenerator, Tuple, Callable, Set
import os
import traceback
from contextlib import asynccontextmanager
import sys
import platform
import logging
import logging.handlers
import socket # ä¿ç•™ socket ä»¥ä¾¿åœ¨ __main__ ä¸­è¿›è¡Œç®€å•çš„ç›´æ¥è¿è¡Œæç¤º
from asyncio import Queue, Lock, Future, Task, Event

from fastapi import FastAPI, Request, HTTPException
from fastapi.responses import JSONResponse, StreamingResponse, FileResponse
from fastapi import WebSocket, WebSocketDisconnect
from pydantic import BaseModel # Field æœªä½¿ç”¨ï¼Œå¯ä»¥ç§»é™¤
from playwright.async_api import Page as AsyncPage, Browser as AsyncBrowser, Playwright as AsyncPlaywright, Error as PlaywrightAsyncError, expect as expect_async, BrowserContext as AsyncBrowserContext, Locator
from playwright.async_api import async_playwright
from urllib.parse import urljoin, urlparse
import uuid
import datetime

# --- å…¨å±€æ·»åŠ æ ‡è®°å¸¸é‡ ---
# è¿™äº›æ ‡è®°ä¸»è¦ç”¨äº server.py å†…éƒ¨ print å’Œ input çš„åè°ƒã€‚
# å¦‚æœ print è¾“å‡ºåˆ°æ§åˆ¶å° (SERVER_REDIRECT_PRINT='false')ï¼Œlaunch_camoufox.py ä¸éœ€è¦å…³å¿ƒå®ƒä»¬ã€‚
# å¦‚æœ print è¢«é‡å®šå‘åˆ°æ—¥å¿—ï¼Œè¿™äº›æ ‡è®°ä¹Ÿä¼šè¿›å…¥æ—¥å¿—ã€‚
USER_INPUT_START_MARKER_SERVER = "__USER_INPUT_START__"
USER_INPUT_END_MARKER_SERVER = "__USER_INPUT_END__"

# --- å…¨å±€æ—¥å¿—æ§åˆ¶é…ç½® (è¿™äº›ä¸»è¦å½±å“ lifespan ä¸­çš„è¡Œä¸º) ---
DEBUG_LOGS_ENABLED = os.environ.get('DEBUG_LOGS_ENABLED', 'false').lower() in ('true', '1', 'yes')
TRACE_LOGS_ENABLED = os.environ.get('TRACE_LOGS_ENABLED', 'false').lower() in ('true', '1', 'yes')
# LOG_INTERVAL = int(os.environ.get('LOG_INTERVAL', '20')) # è¿™äº›ä¼¼ä¹æœªåœ¨ server.py ä¸­ä½¿ç”¨
# LOG_TIME_INTERVAL = float(os.environ.get('LOG_TIME_INTERVAL', '3.0'))

# --- Configuration ---
AI_STUDIO_URL_PATTERN = 'aistudio.google.com/'
RESPONSE_COMPLETION_TIMEOUT = 300000 # 5 minutes total timeout (in ms)
POLLING_INTERVAL = 300 # ms
POLLING_INTERVAL_STREAM = 180 # ms
SILENCE_TIMEOUT_MS = 10000 # ms
POST_SPINNER_CHECK_DELAY_MS = 500
FINAL_STATE_CHECK_TIMEOUT_MS = 1500
SPINNER_CHECK_TIMEOUT_MS = 1000
POST_COMPLETION_BUFFER = 700
CLEAR_CHAT_VERIFY_TIMEOUT_MS = 5000
CLEAR_CHAT_VERIFY_INTERVAL_MS = 400
CLICK_TIMEOUT_MS = 5000
CLIPBOARD_READ_TIMEOUT_MS = 5000
PSEUDO_STREAM_DELAY = 0.001 # å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´è¿™ä¸ªå€¼
EDIT_MESSAGE_BUTTON_SELECTOR = 'ms-chat-turn:last-child .actions-container button.toggle-edit-button'
MESSAGE_TEXTAREA_SELECTOR = 'ms-chat-turn:last-child ms-text-chunk ms-autosize-textarea'
FINISH_EDIT_BUTTON_SELECTOR = 'ms-chat-turn:last-child .actions-container button.toggle-edit-button[aria-label="Stop editing"]'

AUTH_PROFILES_DIR = os.path.join(os.path.dirname(__file__), 'auth_profiles')
ACTIVE_AUTH_DIR = os.path.join(AUTH_PROFILES_DIR, 'active')
SAVED_AUTH_DIR = os.path.join(AUTH_PROFILES_DIR, 'saved')
LOG_DIR = os.path.join(os.path.dirname(__file__), 'logs')
APP_LOG_FILE_PATH = os.path.join(LOG_DIR, 'app.log') # server.py çš„æ—¥å¿—æ–‡ä»¶

# --- å…¨å±€ä»£ç†è®¾ç½® (å°†åœ¨ lifespan ä¸­é€šè¿‡ logger è¾“å‡º) ---
PROXY_SERVER_ENV = os.environ.get('HTTPS_PROXY') or os.environ.get('HTTP_PROXY')
NO_PROXY_ENV = os.environ.get('NO_PROXY')
# --- æ–°å¢: ç¯å¢ƒå˜é‡æ§åˆ¶æ˜¯å¦è‡ªåŠ¨ä¿å­˜è®¤è¯ ---
AUTO_SAVE_AUTH = os.environ.get('AUTO_SAVE_AUTH', '').lower() in ('1', 'true', 'yes')
AUTH_SAVE_TIMEOUT = int(os.environ.get('AUTH_SAVE_TIMEOUT', '30'))  # é»˜è®¤30ç§’è¶…æ—¶

PLAYWRIGHT_PROXY_SETTINGS: Optional[Dict[str, str]] = None
if PROXY_SERVER_ENV:
    PLAYWRIGHT_PROXY_SETTINGS = {'server': PROXY_SERVER_ENV}
    if NO_PROXY_ENV:
        PLAYWRIGHT_PROXY_SETTINGS['bypass'] = NO_PROXY_ENV.replace(',', ';')
# ç§»é™¤è¿™é‡Œçš„ print è¯­å¥

# --- Constants ---
MODEL_NAME = 'AI-Studio_Camoufox-Proxy'
CHAT_COMPLETION_ID_PREFIX = 'chatcmpl-'
MODELS_ENDPOINT_URL_CONTAINS = "MakerSuiteService/ListModels" # ç›®æ ‡è¯·æ±‚URLçš„ä¸€éƒ¨åˆ†
DEFAULT_FALLBACK_MODEL_ID = "gemini-pro" # å¦‚æœæ— æ³•è·å–åˆ—è¡¨ï¼Œä½¿ç”¨çš„é»˜è®¤æ¨¡å‹

# --- Selectors ---
INPUT_SELECTOR = 'ms-prompt-input-wrapper textarea'
SUBMIT_BUTTON_SELECTOR = 'button[aria-label="Run"]'
RESPONSE_CONTAINER_SELECTOR = 'ms-chat-turn .chat-turn-container.model'
RESPONSE_TEXT_SELECTOR = 'ms-cmark-node.cmark-node'
LOADING_SPINNER_SELECTOR = 'button[aria-label="Run"] svg .stoppable-spinner'
ERROR_TOAST_SELECTOR = 'div.toast.warning, div.toast.error'
CLEAR_CHAT_BUTTON_SELECTOR = 'button[aria-label="Clear chat"][data-test-clear="outside"]:has(span.material-symbols-outlined:has-text("refresh"))'
CLEAR_CHAT_CONFIRM_BUTTON_SELECTOR = 'button.mdc-button:has-text("Continue")'
MORE_OPTIONS_BUTTON_SELECTOR = 'div.actions-container div ms-chat-turn-options div > button'
COPY_MARKDOWN_BUTTON_SELECTOR = 'div[class*="mat-menu"] div > button:nth-child(4)'
COPY_MARKDOWN_BUTTON_SELECTOR_ALT = 'div[role="menu"] button:has-text("Copy Markdown")'
TEMPERATURE_INPUT_SELECTOR = 'div[data-test-id="temperatureSliderContainer"] input[type="number"].slider-input'
MAX_OUTPUT_TOKENS_SELECTOR = '#mat-input-0' # æ–°å¢: æœ€å¤§è¾“å‡ºTokenè¾“å…¥æ¡†é€‰æ‹©å™¨
STOP_SEQUENCE_INPUT_SELECTOR = '#mat-mdc-chip-list-input-0' # æ–°å¢: åœæ­¢åºåˆ—è¾“å…¥æ¡†é€‰æ‹©å™¨
MAT_CHIP_REMOVE_BUTTON_SELECTOR = 'mat-chip-set mat-chip-row button[aria-label*="Remove"]' # æ–°å¢: Material Chip ç§»é™¤æŒ‰é’®é€šç”¨é€‰æ‹©å™¨
TOP_P_INPUT_SELECTOR = 'div.settings-item-column:has(h3:text-is("Top P")) input[type="number"].slider-input'


# --- Global State (ç”± lifespan ç®¡ç†åˆå§‹åŒ–å’Œæ¸…ç†) ---
playwright_manager: Optional[AsyncPlaywright] = None
browser_instance: Optional[AsyncBrowser] = None
page_instance: Optional[AsyncPage] = None
is_playwright_ready = False
is_browser_connected = False
is_page_ready = False
is_initializing = False # è¿™ä¸ªçŠ¶æ€ç”± lifespan æ§åˆ¶

# æ–°å¢ï¼šç”¨äºæ¨¡å‹åˆ—è¡¨çš„å…¨å±€å˜é‡
global_model_list_raw_json: Optional[List[Any]] = None
parsed_model_list: List[Dict[str, Any]] = [] # å­˜å‚¨è§£æåçš„æ¨¡å‹åˆ—è¡¨ [{id: "model_id", ...}, ...]
model_list_fetch_event = asyncio.Event() # ç”¨äºæŒ‡ç¤ºæ¨¡å‹åˆ—è¡¨æ˜¯å¦å·²è·å–

# æ–°å¢: æ¨¡å‹åˆ‡æ¢ç›¸å…³çš„å…¨å±€å˜é‡
current_ai_studio_model_id: Optional[str] = None  # å½“å‰åœ¨AI Studioé¡µé¢ä¸Šè®¾ç½®çš„æ¨¡å‹ID (å¯ä»¥æ˜¯åç§°æˆ–ID)
model_switching_lock: Optional[Lock] = None  # æ¨¡å‹åˆ‡æ¢æ“ä½œçš„é”

# æ–°å¢: æ¨¡å‹æ’é™¤åˆ—è¡¨
excluded_model_ids: Set[str] = set()
EXCLUDED_MODELS_FILENAME = "excluded_models.txt" # æ’é™¤åˆ—è¡¨æ–‡ä»¶å

request_queue: Optional[Queue] = None
processing_lock: Optional[Lock] = None
worker_task: Optional[Task] = None

logger = logging.getLogger("AIStudioProxyServer") # server.py ä½¿ç”¨çš„ logger
log_ws_manager = None # å°†åœ¨ lifespan ä¸­åˆå§‹åŒ–

# --- StreamToLogger, WebSocketConnectionManager, WebSocketLogHandler ---
class StreamToLogger:
    """
    ä¼ªæ–‡ä»¶æµå¯¹è±¡ï¼Œå°†å†™å…¥é‡å®šå‘åˆ°æ—¥å¿—å®ä¾‹ã€‚
    """
    def __init__(self, logger_instance, log_level=logging.INFO):
        self.logger = logger_instance
        self.log_level = log_level
        self.linebuf = ''

    def write(self, buf):
        try:
            temp_linebuf = self.linebuf + buf
            self.linebuf = ''
            for line in temp_linebuf.splitlines(True):
                if line.endswith(('\n', '\r')): # å…¼å®¹ä¸åŒç³»ç»Ÿçš„æ¢è¡Œç¬¦
                    self.logger.log(self.log_level, line.rstrip())
                else:
                    self.linebuf += line # ä¿ç•™ä¸å®Œæ•´è¡Œ
        except Exception as e:
            # å¦‚æœæ—¥å¿—å¤±è´¥ï¼Œå›é€€åˆ°åŸå§‹ stderr
            print(f"StreamToLogger é”™è¯¯: {e}", file=sys.__stderr__)

    def flush(self):
        try:
            if self.linebuf != '':
                self.logger.log(self.log_level, self.linebuf.rstrip())
            self.linebuf = ''
        except Exception as e:
            print(f"StreamToLogger Flush é”™è¯¯: {e}", file=sys.__stderr__)

    def isatty(self):
        # ä¸€äº›åº“æ£€æŸ¥è¿™ä¸ªï¼Œè¿”å› False é¿å…é—®é¢˜
        return False

class WebSocketConnectionManager:
    """ç®¡ç†æ‰€æœ‰æ´»åŠ¨çš„ WebSocket æ—¥å¿—è¿æ¥ã€‚"""
    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}

    async def connect(self, client_id: str, websocket: WebSocket):
        """æ¥å—å¹¶æ³¨å†Œä¸€ä¸ªæ–°çš„ WebSocket è¿æ¥ã€‚"""
        await websocket.accept() # é¦–å…ˆæ¥å—è¿æ¥
        self.active_connections[client_id] = websocket
        logger.info(f"WebSocket æ—¥å¿—å®¢æˆ·ç«¯å·²è¿æ¥: {client_id}")
        # å‘é€æ¬¢è¿/è¿æ¥æˆåŠŸæ¶ˆæ¯
        try:
            await websocket.send_text(json.dumps({
                "type": "connection_status",
                "status": "connected",
                "message": "å·²è¿æ¥åˆ°å®æ—¶æ—¥å¿—æµã€‚",
                "timestamp": datetime.datetime.now().isoformat()
            }))
        except Exception as e: # å¤„ç†å‘é€æ¬¢è¿æ¶ˆæ¯æ—¶å¯èƒ½å‘ç”Ÿçš„é”™è¯¯
            logger.warning(f"å‘ WebSocket å®¢æˆ·ç«¯ {client_id} å‘é€æ¬¢è¿æ¶ˆæ¯å¤±è´¥: {e}")
            # å³ä½¿å‘é€æ¬¢è¿æ¶ˆæ¯å¤±è´¥ï¼Œè¿æ¥ä»ç„¶è¢«è®¤ä¸ºæ˜¯å»ºç«‹çš„

    def disconnect(self, client_id: str):
        """æ³¨é”€ä¸€ä¸ª WebSocket è¿æ¥ã€‚"""
        if client_id in self.active_connections:
            del self.active_connections[client_id]
            logger.info(f"WebSocket æ—¥å¿—å®¢æˆ·ç«¯å·²æ–­å¼€: {client_id}")

    async def broadcast(self, message: str):
        """å‘æ‰€æœ‰æ´»åŠ¨çš„ WebSocket è¿æ¥å¹¿æ’­æ¶ˆæ¯ã€‚"""
        if not self.active_connections:
            return

        disconnected_clients = []
        # åˆ›å»ºè¿æ¥å­—å…¸çš„å‰¯æœ¬è¿›è¡Œè¿­ä»£ï¼Œä»¥å…è®¸åœ¨è¿­ä»£è¿‡ç¨‹ä¸­å®‰å…¨åœ°ä¿®æ”¹åŸå§‹å­—å…¸
        active_conns_copy = list(self.active_connections.items())

        for client_id, connection in active_conns_copy:
            try:
                await connection.send_text(message)
            except WebSocketDisconnect:
                logger.info(f"[WS Broadcast] å®¢æˆ·ç«¯ {client_id} åœ¨å¹¿æ’­æœŸé—´æ–­å¼€è¿æ¥ã€‚")
                disconnected_clients.append(client_id)
            except RuntimeError as e: # ä¾‹å¦‚ "Connection is closed"
                 if "Connection is closed" in str(e):
                     logger.info(f"[WS Broadcast] å®¢æˆ·ç«¯ {client_id} çš„è¿æ¥å·²å…³é—­ã€‚")
                     disconnected_clients.append(client_id)
                 else:
                     logger.error(f"å¹¿æ’­åˆ° WebSocket {client_id} æ—¶å‘ç”Ÿè¿è¡Œæ—¶é”™è¯¯: {e}")
                     disconnected_clients.append(client_id) # ä¹Ÿå°†æ­¤ç±»é”™è¯¯è§†ä¸ºæ–­å¼€è¿æ¥
            except Exception as e:
                logger.error(f"å¹¿æ’­åˆ° WebSocket {client_id} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
                disconnected_clients.append(client_id) # ä¹Ÿå°†æ­¤ç±»é”™è¯¯è§†ä¸ºæ–­å¼€è¿æ¥

        # æ¸…ç†åœ¨å¹¿æ’­è¿‡ç¨‹ä¸­å‘ç°å·²æ–­å¼€çš„è¿æ¥
        if disconnected_clients:
             # logger.info(f"[WS Broadcast] æ­£åœ¨æ¸…ç†å·²æ–­å¼€çš„å®¢æˆ·ç«¯: {disconnected_clients}") # disconnect æ–¹æ³•ä¼šè®°å½•
             for client_id_to_remove in disconnected_clients:
                 self.disconnect(client_id_to_remove) # ä½¿ç”¨è‡ªèº«çš„ disconnect æ–¹æ³•

class WebSocketLogHandler(logging.Handler):
    """
    ä¸€ä¸ª logging.Handler å­ç±»ï¼Œç”¨äºå°†æ—¥å¿—è®°å½•å¹¿æ’­åˆ°æ‰€æœ‰é€šè¿‡ WebSocket è¿æ¥çš„å®¢æˆ·ç«¯ã€‚
    """
    def __init__(self, manager: WebSocketConnectionManager):
        super().__init__()
        self.manager = manager
        # ä¸º WebSocket æ—¥å¿—æ¡ç›®å®šä¹‰ä¸€ä¸ªç®€å•çš„æ ¼å¼
        self.formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')

    def emit(self, record: logging.LogRecord):
        """æ ¼å¼åŒ–æ—¥å¿—è®°å½•å¹¶é€šè¿‡ WebSocket ç®¡ç†å™¨å¹¿æ’­å®ƒã€‚"""
        # ä»…å½“ manager æœ‰æ•ˆä¸”æœ‰æ´»åŠ¨è¿æ¥æ—¶æ‰å°è¯•å¹¿æ’­
        if self.manager and self.manager.active_connections:
            try:
                log_entry_str = self.format(record)
                # ä½¿ç”¨ asyncio.create_task åœ¨äº‹ä»¶å¾ªç¯ä¸­å¼‚æ­¥å‘é€ï¼Œé¿å…é˜»å¡æ—¥å¿—è®°å½•å™¨
                try:
                     current_loop = asyncio.get_running_loop()
                     current_loop.create_task(self.manager.broadcast(log_entry_str))
                except RuntimeError: # å¦‚æœæ²¡æœ‰æ­£åœ¨è¿è¡Œçš„äº‹ä»¶å¾ªç¯ (ä¾‹å¦‚åœ¨å…³é—­æœŸé—´)
                     # å¯ä»¥é€‰æ‹©åœ¨æ­¤å¤„è®°å½•ä¸€ä¸ªæ™®é€š print é”™è¯¯ï¼Œæˆ–é™é»˜å¤±è´¥
                     # print(f"WebSocketLogHandler: æ²¡æœ‰æ­£åœ¨è¿è¡Œçš„äº‹ä»¶å¾ªç¯æ¥å¹¿æ’­æ—¥å¿—ã€‚", file=sys.__stderr__)
                     pass
            except Exception as e:
                # å¦‚æœæ ¼å¼åŒ–æˆ–å¹¿æ’­ä»»åŠ¡åˆ›å»ºå¤±è´¥ï¼Œæ‰“å°é”™è¯¯åˆ°åŸå§‹ stderr
                print(f"WebSocketLogHandler é”™è¯¯: å¹¿æ’­æ—¥å¿—å¤±è´¥ - {e}", file=sys.__stderr__)

# --- æ—¥å¿—è®¾ç½®å‡½æ•° (å°†åœ¨ lifespan ä¸­è°ƒç”¨) ---
def setup_server_logging(log_level_name: str = "INFO", redirect_print_str: str = "false"):
    """é…ç½® AIStudioProxyServer çš„æ—¥å¿—è®°å½•ã€‚ç”± lifespan è°ƒç”¨ã€‚"""
    global logger, log_ws_manager # ç¡®ä¿å¼•ç”¨å…¨å±€å˜é‡

    log_level = getattr(logging, log_level_name.upper(), logging.INFO)
    redirect_print = redirect_print_str.lower() in ('true', '1', 'yes')

    # ç¡®ä¿æ—¥å¿—ç›¸å…³ç›®å½•å­˜åœ¨
    os.makedirs(LOG_DIR, exist_ok=True)
    os.makedirs(ACTIVE_AUTH_DIR, exist_ok=True) # è®¤è¯ç›®å½•ä¹Ÿåœ¨æ­¤ç¡®ä¿
    os.makedirs(SAVED_AUTH_DIR, exist_ok=True)

    file_log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - [%(name)s:%(funcName)s:%(lineno)d] - %(message)s')

    # logger å·²åœ¨å…¨å±€å®šä¹‰: logger = logging.getLogger("AIStudioProxyServer")
    if logger.hasHandlers(): # æ¸…ç†æ—§çš„å¤„ç†å™¨ï¼Œä»¥é˜²é‡å¤é…ç½®
        logger.handlers.clear()
    logger.setLevel(log_level)
    logger.propagate = False # é€šå¸¸ä¸å¸Œæœ›æ­¤ logger çš„æ¶ˆæ¯å‘ä¸Šä¼ æ’­åˆ°æ ¹ loggerï¼Œä»¥é¿å…é‡å¤å¤„ç†

    # 1. æ–‡ä»¶å¤„ç†å™¨ (RotatingFileHandler)
    if os.path.exists(APP_LOG_FILE_PATH):
        try:
            os.remove(APP_LOG_FILE_PATH)
        except OSError as e:
            print(f"è­¦å‘Š (setup_server_logging): å°è¯•ç§»é™¤æ—§çš„ app.log æ–‡ä»¶ '{APP_LOG_FILE_PATH}' å¤±è´¥: {e}ã€‚å°†ä¾èµ– mode='w' è¿›è¡Œæˆªæ–­ã€‚", file=sys.__stderr__)
    file_handler = logging.handlers.RotatingFileHandler(
        APP_LOG_FILE_PATH, maxBytes=5*1024*1024, backupCount=5, encoding='utf-8', mode='w'
    )
    file_handler.setFormatter(file_log_formatter)
    logger.addHandler(file_handler)

    # 2. WebSocket å¤„ç†å™¨
    if log_ws_manager is None: # log_ws_manager åº”åœ¨ lifespan ä¸­åˆå§‹åŒ–å¹¶ä¼ é€’åˆ°è¿™é‡Œï¼Œæˆ–é€šè¿‡å…¨å±€å˜é‡è®¿é—®
        # å¦‚æœåœ¨æ­¤é˜¶æ®µ log_ws_manager ä»ä¸º Noneï¼Œè¯´æ˜åˆå§‹åŒ–æµç¨‹æœ‰é—®é¢˜
        print("ä¸¥é‡è­¦å‘Š (setup_server_logging): log_ws_manager æœªåˆå§‹åŒ–ï¼WebSocket æ—¥å¿—åŠŸèƒ½å°†ä¸å¯ç”¨ã€‚", file=sys.__stderr__)
    else:
        ws_handler = WebSocketLogHandler(log_ws_manager)
        ws_handler.setLevel(logging.INFO) # WebSocket æ—¥å¿—å¯ä»¥æœ‰è‡ªå·±çš„çº§åˆ«ï¼Œä¾‹å¦‚åªå‘é€ INFO åŠä»¥ä¸Š
        logger.addHandler(ws_handler)

    # æ–°å¢: 3. æ§åˆ¶å°å¤„ç†å™¨ (StreamHandler) - å°† server.py çš„ logger è¾“å‡ºåˆ°æ§åˆ¶å°
    # è¿™æ · logger.info ç­‰è°ƒç”¨ä¹Ÿä¼šæ˜¾ç¤ºåœ¨ç»ˆç«¯ã€‚
    # ä¸ºäº†ä¸ launch_camoufox.py çš„æ—¥å¿—æœ‰æ‰€åŒºåˆ†ï¼Œæ ¼å¼ä¸­æ·»åŠ  [SERVER] æ ‡è®°ã€‚
    console_server_log_formatter = logging.Formatter('%(asctime)s - %(levelname)s [SERVER] - %(message)s')
    console_handler = logging.StreamHandler(sys.stderr) # è¾“å‡ºåˆ°æ ‡å‡†é”™è¯¯æµ
    console_handler.setFormatter(console_server_log_formatter)
    console_handler.setLevel(log_level) # ä½¿ç”¨ä¸ logger ç›¸åŒçš„æ—¥å¿—çº§åˆ«
    logger.addHandler(console_handler)

    # 4. æŒ‰éœ€é‡å®šå‘ print è¾“å‡º (åŸä¸ºç¬¬3ç‚¹)
    original_stdout = sys.stdout # ä¿å­˜åŸå§‹æµï¼Œä»¥ä¾¿åç»­æ¢å¤
    original_stderr = sys.stderr

    if redirect_print:
        # ä½¿ç”¨åŸå§‹ stderr æ‰“å°æ­¤æç¤ºï¼Œç¡®ä¿ç”¨æˆ·èƒ½çœ‹åˆ°ï¼Œå³ä½¿ logger å¯èƒ½ä¹Ÿé…ç½®äº† StreamHandler åˆ° stderr
        print("--- æ³¨æ„ï¼šserver.py æ­£åœ¨å°†å…¶ print è¾“å‡ºé‡å®šå‘åˆ°æ—¥å¿—ç³»ç»Ÿ (æ–‡ä»¶ã€WebSocket å’Œæ§åˆ¶å°è®°å½•å™¨) ---", file=original_stderr)
        
        # åˆ›å»ºç‰¹å®šçš„ logger å®ä¾‹æ¥å¤„ç†é‡å®šå‘çš„ stdout å’Œ stderr
        # è¿™äº› logger å°†ç»§æ‰¿ AIStudioProxyServer logger çš„å¤„ç†å™¨
        stdout_redirect_logger = logging.getLogger("AIStudioProxyServer.stdout")
        stdout_redirect_logger.setLevel(logging.INFO) # stdout å†…å®¹é€šå¸¸æ˜¯ INFO çº§åˆ«
        stdout_redirect_logger.propagate = True # å…è®¸ä¼ æ’­åˆ° AIStudioProxyServer logger
        sys.stdout = StreamToLogger(stdout_redirect_logger, logging.INFO)

        stderr_redirect_logger = logging.getLogger("AIStudioProxyServer.stderr")
        stderr_redirect_logger.setLevel(logging.ERROR) # stderr å†…å®¹é€šå¸¸æ˜¯ ERROR çº§åˆ«
        stderr_redirect_logger.propagate = True
        sys.stderr = StreamToLogger(stderr_redirect_logger, logging.ERROR)
    else:
        # å³ä½¿ä¸é‡å®šå‘ï¼Œä¹Ÿé€šè¿‡åŸå§‹ stderr è®°å½•è¿™ä¸ªçŠ¶æ€ï¼Œä»¥æ˜ç¡®å‘ŠçŸ¥ç”¨æˆ·
        print("--- server.py çš„ print è¾“å‡ºæœªè¢«é‡å®šå‘åˆ°æ—¥å¿—ç³»ç»Ÿ (å°†ä½¿ç”¨åŸå§‹ stdout/stderr) ---", file=original_stderr)


    # è®¾ç½®å…¶ä»–ç›¸å…³åº“çš„æ—¥å¿—çº§åˆ«ï¼Œä»¥å‡å°‘ä¸å¿…è¦çš„æ—¥å¿—å¹²æ‰°
    logging.getLogger("uvicorn").setLevel(logging.WARNING)
    logging.getLogger("uvicorn.error").setLevel(logging.INFO) # ä¿ç•™ Uvicorn çš„é”™è¯¯ä¿¡æ¯
    logging.getLogger("uvicorn.access").setLevel(logging.WARNING) # Access æ—¥å¿—é€šå¸¸å¾ˆå†—ä½™
    logging.getLogger("websockets").setLevel(logging.WARNING)
    logging.getLogger("playwright").setLevel(logging.WARNING) # Playwright æ—¥å¿—ä¹Ÿéå¸¸å¤š

    # é€šè¿‡é…ç½®å¥½çš„ logger è®°å½•åˆå§‹åŒ–å®Œæˆä¿¡æ¯
    logger.info("=" * 5 + " AIStudioProxyServer æ—¥å¿—ç³»ç»Ÿå·²åœ¨ lifespan ä¸­åˆå§‹åŒ– " + "=" * 5)
    logger.info(f"æ—¥å¿—çº§åˆ«è®¾ç½®ä¸º: {logging.getLevelName(log_level)}")
    logger.info(f"æ—¥å¿—æ–‡ä»¶è·¯å¾„: {APP_LOG_FILE_PATH}")
    logger.info(f"æ§åˆ¶å°æ—¥å¿—å¤„ç†å™¨å·²æ·»åŠ ã€‚") # æ–°å¢æç¤º
    logger.info(f"Print é‡å®šå‘ (ç”± SERVER_REDIRECT_PRINT ç¯å¢ƒå˜é‡æ§åˆ¶): {'å¯ç”¨' if redirect_print else 'ç¦ç”¨'}")
    
    return original_stdout, original_stderr # è¿”å›åŸå§‹æµï¼Œä»¥ä¾¿åœ¨ lifespan ç»“æŸæ—¶æ¢å¤

def restore_original_streams(original_stdout, original_stderr):
    """æ¢å¤åŸå§‹çš„ stdout å’Œ stderr æµã€‚"""
    sys.stdout = original_stdout
    sys.stderr = original_stderr
    # æ­¤æ—¶ logger å¯èƒ½å·²å…³é—­æˆ–å…¶å¤„ç†å™¨å·²ç§»é™¤ï¼Œæ‰€ä»¥ä½¿ç”¨åŸå§‹ stderr æ‰“å°
    print("å·²æ¢å¤ server.py çš„åŸå§‹ stdout å’Œ stderr æµã€‚", file=sys.__stderr__)


# --- Pydantic Models ---
class MessageContentItem(BaseModel):
    type: str
    text: Optional[str] = None

class Message(BaseModel):
    role: str
    content: Union[str, List[MessageContentItem]]

class ChatCompletionRequest(BaseModel):
    messages: List[Message]
    model: Optional[str] = MODEL_NAME
    stream: Optional[bool] = False
    temperature: Optional[float] = None # æ–°å¢: æ¸©åº¦å‚æ•°
    max_output_tokens: Optional[int] = None # æ–°å¢: æœ€å¤§è¾“å‡ºTokenå‚æ•°
    stop: Optional[Union[str, List[str]]] = None # æ–°å¢: åœæ­¢åºåˆ—å‚æ•°
    top_p: Optional[float] = None # æ–°å¢: Top P å‚æ•°

# --- Custom Exception ---
class ClientDisconnectedError(Exception):
    pass

# --- Helper Functions ---
def prepare_combined_prompt(messages: List[Message], req_id: str) -> str:
    # logger.info(f"[{req_id}] (å‡†å¤‡æç¤º) æ­£åœ¨ä» {len(messages)} æ¡æ¶ˆæ¯å‡†å¤‡ç»„åˆæç¤º (åŒ…æ‹¬å†å²)ã€‚")
    # ä½¿ç”¨ print æ˜¯å› ä¸ºè¿™ä¸ªå‡½æ•°å¯èƒ½åœ¨æ—¥å¿—ç³»ç»Ÿå®Œå…¨é…ç½®å¥½ä¹‹å‰è¢«è°ƒç”¨ï¼Œæˆ–è€… print é‡å®šå‘çŠ¶æ€æœªçŸ¥
    # å¦‚æœ SERVER_REDIRECT_PRINT ä¸º true, print ä¼šè¿›å…¥æ—¥å¿—ï¼›å¦åˆ™è¿›å…¥æ§åˆ¶å°ã€‚
    # è¿™æ˜¯ä¸€ä¸ªè®¾è®¡æƒè¡¡ã€‚å¦‚æœä¸¥æ ¼è¦æ±‚æ‰€æœ‰è¾“å‡ºéƒ½é€šè¿‡ loggerï¼Œåˆ™æ­¤å‡½æ•°å†…éƒ¨çš„ print ä¹Ÿåº”æ”¹ä¸º logger.infoã€‚
    # ä½†è€ƒè™‘åˆ°å®ƒåœ¨è¯·æ±‚å¤„ç†æµç¨‹ä¸­ï¼Œä¸”å…¶è¾“å‡ºå¯¹è°ƒè¯•é‡è¦ï¼Œä¿ç•™ print å¹¶ä¾èµ– SERVER_REDIRECT_PRINT æ§åˆ¶å…¶å»å‘ã€‚
    print(f"[{req_id}] (å‡†å¤‡æç¤º) æ­£åœ¨ä» {len(messages)} æ¡æ¶ˆæ¯å‡†å¤‡ç»„åˆæç¤º (åŒ…æ‹¬å†å²)ã€‚", flush=True)
    combined_parts = []
    system_prompt_content = None
    processed_indices = set()

    first_system_msg_index = -1
    for i, msg in enumerate(messages):
        if msg.role == 'system':
            if isinstance(msg.content, str) and msg.content.strip():
                system_prompt_content = msg.content.strip()
                processed_indices.add(i)
                first_system_msg_index = i
                print(f"[{req_id}] (å‡†å¤‡æç¤º) åœ¨ç´¢å¼• {i} æ‰¾åˆ°ç³»ç»Ÿæç¤º: '{system_prompt_content[:80]}...'")
            else:
                 print(f"[{req_id}] (å‡†å¤‡æç¤º) åœ¨ç´¢å¼• {i} å¿½ç•¥éå­—ç¬¦ä¸²æˆ–ç©ºçš„ç³»ç»Ÿæ¶ˆæ¯ã€‚")
                 processed_indices.add(i)
            break

    if system_prompt_content:
        separator = "\\n\\n" if any(idx not in processed_indices for idx in range(len(messages))) else ""
        system_instr_prefix = "ç³»ç»ŸæŒ‡ä»¤:\\n" # ä¸­æ–‡
        combined_parts.append(f"{system_instr_prefix}{system_prompt_content}{separator}")
    else:
        print(f"[{req_id}] (å‡†å¤‡æç¤º) æœªæ‰¾åˆ°æœ‰æ•ˆçš„ç³»ç»Ÿæç¤ºï¼Œç»§ç»­å¤„ç†å…¶ä»–æ¶ˆæ¯ã€‚")

    turn_separator = "\\n---\\n"
    is_first_turn_after_system = True
    for i, msg in enumerate(messages):
        if i in processed_indices:
            continue
        role = msg.role.capitalize()
        if role == 'System': # åç»­çš„ System æ¶ˆæ¯è¢«å¿½ç•¥
            print(f"[{req_id}] (å‡†å¤‡æç¤º) è·³è¿‡åœ¨ç´¢å¼• {i} çš„åç»­ç³»ç»Ÿæ¶ˆæ¯ã€‚")
            continue
        content_str = ""
        if isinstance(msg.content, str):
            content_str = msg.content
        elif isinstance(msg.content, list):
            text_parts = []
            for item_model in msg.content:
                 if isinstance(item_model, MessageContentItem):
                     if item_model.type == 'text' and isinstance(item_model.text, str):
                          text_parts.append(item_model.text)
                     else:
                           print(f"[{req_id}] (å‡†å¤‡æç¤º) è­¦å‘Š: åœ¨ç´¢å¼• {i} çš„æ¶ˆæ¯ä¸­å¿½ç•¥éæ–‡æœ¬éƒ¨åˆ†: ç±»å‹={item_model.type}")
                 else: # Pydantic åº”è¯¥å·²ç»è½¬æ¢äº†ï¼Œä½†ä½œä¸ºåå¤‡
                      item_dict = dict(item_model)
                      if item_dict.get('type') == 'text' and isinstance(item_dict.get('text'), str):
                           text_parts.append(item_dict['text'])
                      else:
                           print(f"[{req_id}] (å‡†å¤‡æç¤º) è­¦å‘Š: åœ¨ç´¢å¼• {i} çš„æ¶ˆæ¯åˆ—è¡¨ä¸­é‡åˆ°æ„å¤–çš„é¡¹ç›®æ ¼å¼ã€‚é¡¹ç›®: {item_model}")
            content_str = "\\n".join(text_parts)
        else:
            print(f"[{req_id}] (å‡†å¤‡æç¤º) è­¦å‘Š: è§’è‰² {role} åœ¨ç´¢å¼• {i} çš„å†…å®¹ç±»å‹æ„å¤– ({type(msg.content)})ã€‚å°†è½¬æ¢ä¸ºå­—ç¬¦ä¸²ã€‚")
            content_str = str(msg.content)

        content_str = content_str.strip()
        if content_str:
            if not is_first_turn_after_system:
                 combined_parts.append(turn_separator)
            # æ ¹æ®è§’è‰²æ·»åŠ ä¸­æ–‡å‰ç¼€
            role_map = {"User": "ç”¨æˆ·", "Assistant": "åŠ©æ‰‹", "System": "ç³»ç»Ÿ"} # System ç†è®ºä¸Šä¸ä¼šåˆ°è¿™é‡Œ
            role_prefix_zh = f"{role_map.get(role, role)}:\\n"
            combined_parts.append(f"{role_prefix_zh}{content_str}")
            is_first_turn_after_system = False
        else:
            print(f"[{req_id}] (å‡†å¤‡æç¤º) è·³è¿‡è§’è‰² {role} åœ¨ç´¢å¼• {i} çš„ç©ºæ¶ˆæ¯ã€‚")

    final_prompt = "".join(combined_parts)
    preview_text = final_prompt[:200].replace('\\n', '\\\\n')
    print(f"[{req_id}] (å‡†å¤‡æç¤º) ç»„åˆæç¤ºé•¿åº¦: {len(final_prompt)}ã€‚é¢„è§ˆ: '{preview_text}...'")
    final_newline = "\\n"
    return final_prompt + final_newline if final_prompt else ""

def validate_chat_request(messages: List[Message], req_id: str) -> Dict[str, Optional[str]]:
    if not messages:
        raise ValueError(f"[{req_id}] æ— æ•ˆè¯·æ±‚: 'messages' æ•°ç»„ç¼ºå¤±æˆ–ä¸ºç©ºã€‚")
    if not any(msg.role != 'system' for msg in messages):
        raise ValueError(f"[{req_id}] æ— æ•ˆè¯·æ±‚: æœªæ‰¾åˆ°ç”¨æˆ·æˆ–åŠ©æ‰‹æ¶ˆæ¯ã€‚")
    logger.info(f"[{req_id}] (æ ¡éªŒ) å¯¹ {len(messages)} æ¡æ¶ˆæ¯çš„åŸºæœ¬æ ¡éªŒé€šè¿‡ã€‚")
    return {}

async def get_raw_text_content(response_element: Locator, previous_text: str, req_id: str) -> str:
    # (æ­¤å‡½æ•°å®ç°ä¸ä¹‹å‰ç‰ˆæœ¬ç›¸åŒï¼Œå…¶å†…éƒ¨çš„ logger è°ƒç”¨ä¼šæŒ‰æ–°é…ç½®å·¥ä½œ)
    raw_text = previous_text
    try:
        await response_element.wait_for(state='attached', timeout=1000)
        pre_element = response_element.locator('pre').last
        pre_found_and_visible = False
        try:
            await pre_element.wait_for(state='visible', timeout=250)
            pre_found_and_visible = True
        except PlaywrightAsyncError: pass

        if pre_found_and_visible:
            try:
                raw_text = await pre_element.inner_text(timeout=500)
            except PlaywrightAsyncError as pre_err:
                if DEBUG_LOGS_ENABLED:
                    error_message_first_line = pre_err.message.split('\n')[0]
                    logger.warning(f"[{req_id}] ä»å¯è§çš„ <pre> è·å– innerText å¤±è´¥: {error_message_first_line}")
                try:
                     raw_text = await response_element.inner_text(timeout=1000)
                except PlaywrightAsyncError as e_parent:
                     if DEBUG_LOGS_ENABLED:
                         logger.warning(f"[{req_id}] åœ¨ <pre> è·å–å¤±è´¥åï¼Œä»çˆ¶å…ƒç´ è·å– inner_text å¤±è´¥: {e_parent}ã€‚è¿”å›å…ˆå‰æ–‡æœ¬ã€‚")
                     raw_text = previous_text # ä¿ç•™ä¹‹å‰çš„å€¼
        else: # pre å…ƒç´ ä¸å¯è§æˆ–ä¸å­˜åœ¨
            try:
                 raw_text = await response_element.inner_text(timeout=1500)
            except PlaywrightAsyncError as e_parent:
                 if DEBUG_LOGS_ENABLED:
                     logger.warning(f"[{req_id}] ä»çˆ¶å…ƒç´ è·å– inner_text å¤±è´¥ (æ—  pre å…ƒç´ ): {e_parent}ã€‚è¿”å›å…ˆå‰æ–‡æœ¬ã€‚")
                 raw_text = previous_text # ä¿ç•™ä¹‹å‰çš„å€¼

        if raw_text and isinstance(raw_text, str): # ç¡®ä¿ raw_text æ˜¯å­—ç¬¦ä¸²
            replacements = {
                "IGNORE_WHEN_COPYING_START": "", "content_copy": "", "download": "",
                "Use code with caution.": "", "IGNORE_WHEN_COPYING_END": ""
            }
            cleaned_text = raw_text
            found_junk = False
            for junk, replacement in replacements.items():
                if junk in cleaned_text:
                    cleaned_text = cleaned_text.replace(junk, replacement)
                    found_junk = True
            if found_junk:
                # æ¸…ç†å¤šä½™çš„ç©ºè¡Œ
                cleaned_text = "\n".join([line.strip() for line in cleaned_text.splitlines() if line.strip()])
                if DEBUG_LOGS_ENABLED:
                     logger.debug(f"[{req_id}] (æ¸…ç†) å·²ç§»é™¤å“åº”æ–‡æœ¬ä¸­çš„å·²çŸ¥UIå…ƒç´ ã€‚")
                raw_text = cleaned_text
        return raw_text
    except PlaywrightAsyncError: # å¦‚æœ response_element.wait_for å¤±è´¥ç­‰
        return previous_text
    except Exception as e_general:
         logger.warning(f"[{req_id}] getRawTextContent ä¸­å‘ç”Ÿæ„å¤–é”™è¯¯: {e_general}ã€‚è¿”å›å…ˆå‰æ–‡æœ¬ã€‚")
         return previous_text

def generate_sse_chunk(delta: str, req_id: str, model: str) -> str:
    # (ä»£ç ä¸å˜)
    chunk = {
        "id": f"{CHAT_COMPLETION_ID_PREFIX}{req_id}-{int(time.time())}-{random.randint(100, 999)}",
        "object": "chat.completion.chunk", "created": int(time.time()), "model": model,
        "choices": [{"index": 0, "delta": {"content": delta}, "finish_reason": None}]
    }
    return f"data: {json.dumps(chunk)}\n\n"

def generate_sse_stop_chunk(req_id: str, model: str, reason: str = "stop") -> str:
    # (ä»£ç ä¸å˜)
    chunk = {
        "id": f"{CHAT_COMPLETION_ID_PREFIX}{req_id}-{int(time.time())}-{random.randint(100, 999)}",
        "object": "chat.completion.chunk", "created": int(time.time()), "model": model,
        "choices": [{"index": 0, "delta": {}, "finish_reason": reason}]
    }
    return f"data: {json.dumps(chunk)}\n\n"

def generate_sse_error_chunk(message: str, req_id: str, error_type: str = "server_error") -> str:
    # (ä»£ç ä¸å˜)
    error_payload = {"error": {"message": f"[{req_id}] {message}", "type": error_type}}
    return f"data: {json.dumps(error_payload)}\n\n"

async def _initialize_page_logic(browser: AsyncBrowser):
    # (æ­¤å‡½æ•°å®ç°ä¸ä¹‹å‰ç‰ˆæœ¬ç›¸åŒï¼Œå…¶å†…éƒ¨çš„ print å’Œ input ä¼šå— SERVER_REDIRECT_PRINT å½±å“)
    # æ³¨æ„ï¼šæ­¤å‡½æ•°ä¸­çš„ print è¯­å¥ï¼Œå¦‚æœ SERVER_REDIRECT_PRINT ä¸º falseï¼Œä¼šç›´æ¥è¾“å‡ºåˆ°è¿è¡Œ
    # launch_camoufox.py çš„æ§åˆ¶å°ã€‚å¦‚æœä¸º trueï¼Œä¼šè¿›å…¥æ—¥å¿—ã€‚
    # input() è°ƒç”¨ä¼šç›´æ¥ä½œç”¨äº launch_camoufox.py çš„æ§åˆ¶å°ã€‚
    # USER_INPUT_START/END_MARKER_SERVER æ ‡è®°ä»ç„¶æœ‰ç”¨ï¼Œä»¥ä¾¿åœ¨ print æœªé‡å®šå‘æ—¶ï¼Œ
    # å¦‚æœ launch_camoufox.py ä»éœ€æŸç§æ–¹å¼è¯†åˆ«è¾“å…¥æ®µï¼ˆå°½ç®¡åœ¨æ­¤é›†æˆæ¨¡å‹ä¸­å®ƒä¸å†ç›´æ¥è§£æè¿™äº›æ ‡è®°ï¼‰ã€‚
    logger.info("--- åˆå§‹åŒ–é¡µé¢é€»è¾‘ (è¿æ¥åˆ°ç°æœ‰æµè§ˆå™¨) ---") # ä½¿ç”¨ logger
    temp_context: Optional[AsyncBrowserContext] = None # ç±»å‹æç¤º
    storage_state_path_to_use: Optional[str] = None
    # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
    launch_mode = os.environ.get('LAUNCH_MODE', 'debug') # é»˜è®¤ä¸º debug
    # active_auth_json_path = os.environ.get('ACTIVE_AUTH_JSON_PATH') # åœ¨ headless æ¨¡å¼ä¸‹ä½¿ç”¨
    # AUTO_SAVE_AUTH å’Œ AUTH_SAVE_TIMEOUT å·²åœ¨å…¨å±€å®šä¹‰

    logger.info(f"   æ£€æµ‹åˆ°å¯åŠ¨æ¨¡å¼: {launch_mode}")
    loop = asyncio.get_running_loop()

    if launch_mode == 'headless':
        auth_filename = os.environ.get('ACTIVE_AUTH_JSON_PATH')
        if auth_filename: # ç¡®ä¿ auth_filename ä¸æ˜¯ None æˆ–ç©ºå­—ç¬¦ä¸²
            # å‡è®¾ ACTIVE_AUTH_JSON_PATH å·²ç»æ˜¯å®Œæ•´è·¯å¾„æˆ–ç›¸å¯¹äº server.py çš„è·¯å¾„
            # å¦‚æœå®ƒæ˜¯ç›¸å¯¹äº auth_profiles/active çš„æ–‡ä»¶åï¼Œåˆ™éœ€è¦è°ƒæ•´
            # ä» launch_camoufox.py çš„ä¿®æ”¹æ¥çœ‹ï¼Œå®ƒä¼ é€’çš„æ˜¯å®Œæ•´è·¯å¾„
            constructed_path = auth_filename 
            if os.path.exists(constructed_path):
                storage_state_path_to_use = constructed_path
                logger.info(f"   æ— å¤´æ¨¡å¼å°†ä½¿ç”¨çš„è®¤è¯æ–‡ä»¶: {constructed_path}")
            else:
                logger.error(f"æ— å¤´æ¨¡å¼è®¤è¯æ–‡ä»¶æ— æ•ˆæˆ–ä¸å­˜åœ¨: '{constructed_path}'")
                raise RuntimeError(f"æ— å¤´æ¨¡å¼è®¤è¯æ–‡ä»¶æ— æ•ˆ: '{constructed_path}'")
        else:
            logger.error("æ— å¤´æ¨¡å¼éœ€è¦ ACTIVE_AUTH_JSON_PATH ç¯å¢ƒå˜é‡ï¼Œä½†æœªè®¾ç½®æˆ–ä¸ºç©ºã€‚")
            # å¦‚æœ launch_camoufox.py ç¡®ä¿æ€»ä¼šè®¾ç½®ï¼ˆå³ä½¿æ˜¯ç©ºï¼‰ï¼Œé‚£è¿™ä¸ªé”™è¯¯å¯èƒ½ä¸ä¼šè§¦å‘
            # ä½†ä»¥é˜²ä¸‡ä¸€ï¼Œä¿ç•™æ£€æŸ¥
            raise RuntimeError("æ— å¤´æ¨¡å¼éœ€è¦ ACTIVE_AUTH_JSON_PATHã€‚")
    elif launch_mode == 'debug':
        logger.info(f"   è°ƒè¯•æ¨¡å¼: å°è¯•ä»ç¯å¢ƒå˜é‡ ACTIVE_AUTH_JSON_PATH åŠ è½½è®¤è¯æ–‡ä»¶...")
        auth_filepath_from_env = os.environ.get('ACTIVE_AUTH_JSON_PATH')
        if auth_filepath_from_env and os.path.exists(auth_filepath_from_env):
            storage_state_path_to_use = auth_filepath_from_env
            logger.info(f"   è°ƒè¯•æ¨¡å¼å°†ä½¿ç”¨çš„è®¤è¯æ–‡ä»¶ (æ¥è‡ªç¯å¢ƒå˜é‡): {storage_state_path_to_use}")
            # ç”¨æˆ·äº¤äº’å·²åœ¨ launch_camoufox.py ä¸­å®Œæˆï¼Œè¿™é‡Œä¸å†éœ€è¦ input
        elif auth_filepath_from_env: # ç¯å¢ƒå˜é‡è®¾ç½®äº†ï¼Œä½†æ–‡ä»¶ä¸å­˜åœ¨
            logger.warning(f"   è°ƒè¯•æ¨¡å¼ä¸‹ç¯å¢ƒå˜é‡ ACTIVE_AUTH_JSON_PATH æŒ‡å‘çš„æ–‡ä»¶ä¸å­˜åœ¨: '{auth_filepath_from_env}'ã€‚ä¸åŠ è½½è®¤è¯æ–‡ä»¶ã€‚")
        else: # ç¯å¢ƒå˜é‡æœªè®¾ç½®æˆ–ä¸ºç©ºï¼Œæ„å‘³ç€ç”¨æˆ·åœ¨å¯åŠ¨å™¨ä¸­é€‰æ‹©ä¸åŠ è½½
            logger.info("   è°ƒè¯•æ¨¡å¼ä¸‹æœªé€šè¿‡ç¯å¢ƒå˜é‡æä¾›è®¤è¯æ–‡ä»¶ã€‚å°†ä½¿ç”¨æµè§ˆå™¨å½“å‰çŠ¶æ€ã€‚")
            # æ­¤å¤„ storage_state_path_to_use å°†ä¿æŒä¸º None

    elif launch_mode == "direct_debug_no_browser":
        logger.info("   direct_debug_no_browser æ¨¡å¼ï¼šä¸åŠ è½½ storage_stateï¼Œä¸è¿›è¡Œæµè§ˆå™¨æ“ä½œã€‚")
    else: # æœªçŸ¥æ¨¡å¼
        logger.warning(f"   âš ï¸ è­¦å‘Š: æœªçŸ¥çš„å¯åŠ¨æ¨¡å¼ '{launch_mode}'ã€‚ä¸åŠ è½½ storage_stateã€‚")

    try:
        logger.info("åˆ›å»ºæ–°çš„æµè§ˆå™¨ä¸Šä¸‹æ–‡...")
        context_options: Dict[str, Any] = {'viewport': {'width': 460, 'height': 800}}
        if storage_state_path_to_use:
            context_options['storage_state'] = storage_state_path_to_use
            logger.info(f"   (ä½¿ç”¨ storage_state='{os.path.basename(storage_state_path_to_use)}')")
        else:
            logger.info("   (ä¸ä½¿ç”¨ storage_state)")

        if PLAYWRIGHT_PROXY_SETTINGS:
            context_options['proxy'] = PLAYWRIGHT_PROXY_SETTINGS
            logger.info(f"   (æµè§ˆå™¨ä¸Šä¸‹æ–‡å°†ä½¿ç”¨ä»£ç†: {PLAYWRIGHT_PROXY_SETTINGS['server']})")
        else:
            logger.info("   (æµè§ˆå™¨ä¸Šä¸‹æ–‡ä¸ä½¿ç”¨æ˜¾å¼ä»£ç†é…ç½®)")

        temp_context = await browser.new_context(**context_options)

        found_page: Optional[AsyncPage] = None
        pages = temp_context.pages
        target_url_base = f"https://{AI_STUDIO_URL_PATTERN}"
        target_full_url = f"{target_url_base}prompts/new_chat" # ç›®æ ‡æ˜¯æ–°èŠå¤©é¡µé¢
        login_url_pattern = 'accounts.google.com' # Google ç™»å½•é¡µé¢çš„ URL ç‰¹å¾
        current_url = ""

        # æŸ¥æ‰¾å·²æ‰“å¼€çš„ç¬¦åˆæ¡ä»¶çš„ AI Studio é¡µé¢
        for p_iter in pages: # ä½¿ç”¨ä¸åŒå˜é‡å
            try:
                page_url_to_check = p_iter.url # è·å–é¡µé¢ URL
                # æ£€æŸ¥é¡µé¢æ˜¯å¦æœªå…³é—­ï¼Œä¸” URL åŒ…å« AI Studio çš„åŸºç¡€è·¯å¾„å’Œ /prompts/ è·¯å¾„æ®µ
                if not p_iter.is_closed() and target_url_base in page_url_to_check and "/prompts/" in page_url_to_check:
                    found_page = p_iter
                    current_url = page_url_to_check
                    logger.info(f"   æ‰¾åˆ°å·²æ‰“å¼€çš„ AI Studio é¡µé¢: {current_url}")
                    # ç«‹å³ä¸ºæ‰¾åˆ°çš„é¡µé¢æ·»åŠ ç›‘å¬å™¨
                    if found_page: # ç¡®ä¿ found_page æœ‰æ•ˆ
                        logger.info(f"   ä¸ºå·²å­˜åœ¨çš„é¡µé¢ {found_page.url} æ·»åŠ æ¨¡å‹åˆ—è¡¨å“åº”ç›‘å¬å™¨ã€‚")
                        found_page.on("response", _handle_model_list_response)
                    break
            except PlaywrightAsyncError as pw_err_url: # Playwright æ“ä½œå¯èƒ½å¼•å‘çš„é”™è¯¯
                logger.warning(f"   æ£€æŸ¥é¡µé¢ URL æ—¶å‡ºç° Playwright é”™è¯¯: {pw_err_url}")
            except AttributeError as attr_err_url: # ä¾‹å¦‚é¡µé¢å¯¹è±¡çŠ¶æ€å¼‚å¸¸
                logger.warning(f"   æ£€æŸ¥é¡µé¢ URL æ—¶å‡ºç°å±æ€§é”™è¯¯: {attr_err_url}")
            except Exception as e_url_check: # å…¶ä»–æœªçŸ¥é”™è¯¯
                logger.warning(f"   æ£€æŸ¥é¡µé¢ URL æ—¶å‡ºç°å…¶ä»–æœªé¢„æœŸé”™è¯¯: {e_url_check} (ç±»å‹: {type(e_url_check).__name__})")


        if not found_page: # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„å·²æ‰“å¼€é¡µé¢
            logger.info(f"-> æœªæ‰¾åˆ°åˆé€‚çš„ç°æœ‰é¡µé¢ï¼Œæ­£åœ¨æ‰“å¼€æ–°é¡µé¢å¹¶å¯¼èˆªåˆ° {target_full_url}...")
            found_page = await temp_context.new_page()
            # ç«‹å³ä¸ºæ–°é¡µé¢æ·»åŠ ç›‘å¬å™¨ï¼Œåœ¨ goto ä¹‹å‰
            if found_page: # ç¡®ä¿ found_page æœ‰æ•ˆ
                logger.info(f"   ä¸ºæ–°åˆ›å»ºçš„é¡µé¢æ·»åŠ æ¨¡å‹åˆ—è¡¨å“åº”ç›‘å¬å™¨ (å¯¼èˆªå‰)ã€‚")
                found_page.on("response", _handle_model_list_response)
            try:
                # ç­‰å¾… DOM å†…å®¹åŠ è½½å®Œæˆï¼Œè®¾ç½®è¾ƒé•¿è¶…æ—¶æ—¶é—´
                await found_page.goto(target_full_url, wait_until="domcontentloaded", timeout=90000)
                current_url = found_page.url
                logger.info(f"-> æ–°é¡µé¢å¯¼èˆªå°è¯•å®Œæˆã€‚å½“å‰ URL: {current_url}")
            except Exception as new_page_nav_err:
                await save_error_snapshot("init_new_page_nav_fail") # ä¿å­˜é”™è¯¯å¿«ç…§
                error_str = str(new_page_nav_err)
                # é’ˆå¯¹ç‰¹å®šç½‘ç»œé”™è¯¯ç»™å‡ºæ›´å‹å¥½çš„æç¤º
                if "NS_ERROR_NET_INTERRUPT" in error_str: # Firefox ç‰¹æœ‰çš„ç½‘ç»œä¸­æ–­é”™è¯¯
                    logger.error("\n" + "="*30 + " ç½‘ç»œå¯¼èˆªé”™è¯¯æç¤º " + "="*30)
                    logger.error(f"âŒ å¯¼èˆªåˆ° '{target_full_url}' å¤±è´¥ï¼Œå‡ºç°ç½‘ç»œä¸­æ–­é”™è¯¯ (NS_ERROR_NET_INTERRUPT)ã€‚")
                    logger.error("   è¿™é€šå¸¸è¡¨ç¤ºæµè§ˆå™¨åœ¨å°è¯•åŠ è½½é¡µé¢æ—¶è¿æ¥è¢«æ„å¤–æ–­å¼€ã€‚")
                    logger.error("   å¯èƒ½çš„åŸå› åŠæ’æŸ¥å»ºè®®:")
                    logger.error("     1. ç½‘ç»œè¿æ¥: è¯·æ£€æŸ¥ä½ çš„æœ¬åœ°ç½‘ç»œè¿æ¥æ˜¯å¦ç¨³å®šï¼Œå¹¶å°è¯•åœ¨æ™®é€šæµè§ˆå™¨ä¸­è®¿é—®ç›®æ ‡ç½‘å€ã€‚")
                    logger.error("     2. AI Studio æœåŠ¡: ç¡®è®¤ aistudio.google.com æœåŠ¡æœ¬èº«æ˜¯å¦å¯ç”¨ã€‚")
                    logger.error("     3. é˜²ç«å¢™/ä»£ç†/VPN: æ£€æŸ¥æœ¬åœ°é˜²ç«å¢™ã€æ€æ¯’è½¯ä»¶ã€ä»£ç†æˆ– VPN è®¾ç½®ã€‚")
                    logger.error("     4. Camoufox æœåŠ¡: ç¡®è®¤ launch_camoufox.py è„šæœ¬æ˜¯å¦æ­£å¸¸è¿è¡Œã€‚")
                    logger.error("     5. ç³»ç»Ÿèµ„æºé—®é¢˜: ç¡®ä¿ç³»ç»Ÿæœ‰è¶³å¤Ÿçš„å†…å­˜å’Œ CPU èµ„æºã€‚")
                    logger.error("="*74 + "\n")
                raise RuntimeError(f"å¯¼èˆªæ–°é¡µé¢å¤±è´¥: {new_page_nav_err}") from new_page_nav_err

        # å¤„ç†ç™»å½•é‡å®šå‘
        if login_url_pattern in current_url:
            if launch_mode == 'headless':
                logger.error("æ— å¤´æ¨¡å¼ä¸‹æ£€æµ‹åˆ°é‡å®šå‘è‡³ç™»å½•é¡µé¢ï¼Œè®¤è¯å¯èƒ½å·²å¤±æ•ˆã€‚è¯·æ›´æ–°è®¤è¯æ–‡ä»¶ã€‚")
                raise RuntimeError("æ— å¤´æ¨¡å¼è®¤è¯å¤±è´¥ï¼Œéœ€è¦æ›´æ–°è®¤è¯æ–‡ä»¶ã€‚")
            else: # è°ƒè¯•æ¨¡å¼ï¼Œæç¤ºç”¨æˆ·æ‰‹åŠ¨ç™»å½•
                print(f"\n{'='*20} éœ€è¦æ“ä½œ {'='*20}", flush=True)
                # USER_INPUT_START_MARKER_SERVER ç›¸å…³çš„ input å·²ç§»è‡³ launch_camoufox.py
                # print(USER_INPUT_START_MARKER_SERVER, flush=True) 
                login_prompt = "   æ£€æµ‹åˆ°å¯èƒ½éœ€è¦ç™»å½•ã€‚å¦‚æœæµè§ˆå™¨æ˜¾ç¤ºç™»å½•é¡µé¢ï¼Œè¯·åœ¨æµè§ˆå™¨çª—å£ä¸­å®Œæˆ Google ç™»å½•ï¼Œç„¶ååœ¨æ­¤å¤„æŒ‰ Enter é”®ç»§ç»­..."
                # è¿™é‡Œçš„ input ä»ç„¶æ˜¯å¿…è¦çš„ï¼Œç”¨äºç­‰å¾…ç”¨æˆ·åœ¨æµè§ˆå™¨ä¸­æ“ä½œ
                # ä½†å®ƒä¸å†æ˜¯é€‰æ‹©è®¤è¯æ–‡ä»¶ï¼Œè€Œæ˜¯ç¡®è®¤ç™»å½•æ“ä½œ
                print(USER_INPUT_START_MARKER_SERVER, flush=True) # ä¿ç•™æ­¤æ ‡è®°ä»¥å…¼å®¹å¯èƒ½çš„å¤–éƒ¨è§£æå™¨
                await loop.run_in_executor(None, input, login_prompt)
                print(USER_INPUT_END_MARKER_SERVER, flush=True) # ä¿ç•™æ­¤æ ‡è®°
                logger.info("   ç”¨æˆ·å·²æ“ä½œï¼Œæ­£åœ¨æ£€æŸ¥ç™»å½•çŠ¶æ€...")
                try:
                    # ç­‰å¾… URL å˜ä¸º AI Studio çš„ URLï¼Œè¶…æ—¶æ—¶é—´è®¾ä¸º3åˆ†é’Ÿ
                    await found_page.wait_for_url(f"**/{AI_STUDIO_URL_PATTERN}**", timeout=180000)
                    current_url = found_page.url # æ›´æ–°å½“å‰ URL
                    if login_url_pattern in current_url: # å¦‚æœä»åœ¨ç™»å½•é¡µ
                        logger.error("æ‰‹åŠ¨ç™»å½•å°è¯•åï¼Œé¡µé¢ä¼¼ä¹ä»åœç•™åœ¨ç™»å½•é¡µé¢ã€‚")
                        raise RuntimeError("æ‰‹åŠ¨ç™»å½•å°è¯•åä»åœ¨ç™»å½•é¡µé¢ã€‚")
                    logger.info("   âœ… ç™»å½•æˆåŠŸï¼è¯·ä¸è¦æ“ä½œæµè§ˆå™¨çª—å£ï¼Œç­‰å¾…åç»­æç¤ºã€‚")

                    # è¯¢é—®æ˜¯å¦ä¿å­˜è®¤è¯çŠ¶æ€
                    print("\n" + "="*50, flush=True)
                    print("   ã€ç”¨æˆ·äº¤äº’ã€‘éœ€è¦æ‚¨çš„è¾“å…¥!", flush=True)
                    
                    save_auth_prompt = "   æ˜¯å¦è¦å°†å½“å‰çš„æµè§ˆå™¨è®¤è¯çŠ¶æ€ä¿å­˜åˆ°æ–‡ä»¶ï¼Ÿ (y/N): "
                    should_save_auth_choice = ''
                    if AUTO_SAVE_AUTH and launch_mode == 'debug': # è‡ªåŠ¨ä¿å­˜ä»…åœ¨è°ƒè¯•æ¨¡å¼ä¸‹æœ‰æ„ä¹‰
                        logger.info("   è‡ªåŠ¨ä¿å­˜è®¤è¯æ¨¡å¼å·²å¯ç”¨ï¼Œå°†è‡ªåŠ¨ä¿å­˜è®¤è¯çŠ¶æ€...")
                        should_save_auth_choice = 'y'
                    else:
                        # print(USER_INPUT_START_MARKER_SERVER, flush=True) # æ ‡è®°ç›¸å…³çš„ input ä¹Ÿç§»é™¤äº†
                        print(USER_INPUT_START_MARKER_SERVER, flush=True) # ä¿ç•™æ­¤æ ‡è®°
                        try:
                            auth_save_input_future = loop.run_in_executor(None, input, save_auth_prompt)
                            should_save_auth_choice = await asyncio.wait_for(auth_save_input_future, timeout=AUTH_SAVE_TIMEOUT)
                        except asyncio.TimeoutError:
                            print(f"   è¾“å…¥ç­‰å¾…è¶…æ—¶({AUTH_SAVE_TIMEOUT}ç§’)ã€‚é»˜è®¤ä¸ä¿å­˜è®¤è¯çŠ¶æ€ã€‚", flush=True)
                            should_save_auth_choice = 'n' # æˆ– ''ï¼Œä¸‹é¢ä¼šå¤„ç†
                        finally: # ç¡®ä¿ç»“æŸæ ‡è®°è¢«æ‰“å°
                            # print(USER_INPUT_END_MARKER_SERVER, flush=True)
                            print(USER_INPUT_END_MARKER_SERVER, flush=True) # ä¿ç•™æ­¤æ ‡è®°
                    
                    if should_save_auth_choice.strip().lower() == 'y':
                        os.makedirs(SAVED_AUTH_DIR, exist_ok=True) # ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
                        default_auth_filename = f"auth_state_{int(time.time())}.json"
                        
                        # print(USER_INPUT_START_MARKER_SERVER, flush=True) # ç›¸å…³çš„ input ä¹Ÿç§»é™¤äº†
                        print(USER_INPUT_START_MARKER_SERVER, flush=True) # ä¿ç•™æ­¤æ ‡è®°
                        filename_prompt_str = f"   è¯·è¾“å…¥ä¿å­˜çš„æ–‡ä»¶å (é»˜è®¤ä¸º: {default_auth_filename}): "
                        chosen_auth_filename = ''
                        try:
                            filename_input_future = loop.run_in_executor(None, input, filename_prompt_str)
                            chosen_auth_filename = await asyncio.wait_for(filename_input_future, timeout=AUTH_SAVE_TIMEOUT)
                        except asyncio.TimeoutError:
                            print(f"   è¾“å…¥æ–‡ä»¶åç­‰å¾…è¶…æ—¶({AUTH_SAVE_TIMEOUT}ç§’)ã€‚å°†ä½¿ç”¨é»˜è®¤æ–‡ä»¶å: {default_auth_filename}", flush=True)
                        finally:
                            # print(USER_INPUT_END_MARKER_SERVER, flush=True)
                            print(USER_INPUT_END_MARKER_SERVER, flush=True) # ä¿ç•™æ­¤æ ‡è®°

                        final_auth_filename = chosen_auth_filename.strip() or default_auth_filename
                        if not final_auth_filename.endswith(".json"):
                            final_auth_filename += ".json"
                        
                        auth_save_path = os.path.join(SAVED_AUTH_DIR, final_auth_filename)
                        try:
                            await temp_context.storage_state(path=auth_save_path)
                            print(f"   âœ… è®¤è¯çŠ¶æ€å·²æˆåŠŸä¿å­˜åˆ°: {auth_save_path}", flush=True)
                        except Exception as save_state_err:
                            logger.error(f"   âŒ ä¿å­˜è®¤è¯çŠ¶æ€å¤±è´¥: {save_state_err}", exc_info=True)
                            print(f"   âŒ ä¿å­˜è®¤è¯çŠ¶æ€å¤±è´¥: {save_state_err}", flush=True)
                    else:
                        print("   å¥½çš„ï¼Œä¸ä¿å­˜è®¤è¯çŠ¶æ€ã€‚", flush=True)
                    print("="*50 + "\n", flush=True)

                except Exception as wait_login_err:
                    await save_error_snapshot("init_login_wait_fail")
                    logger.error(f"ç™»å½•æç¤ºåæœªèƒ½æ£€æµ‹åˆ° AI Studio URL æˆ–ä¿å­˜çŠ¶æ€æ—¶å‡ºé”™: {wait_login_err}", exc_info=True)
                    raise RuntimeError(f"ç™»å½•æç¤ºåæœªèƒ½æ£€æµ‹åˆ° AI Studio URL: {wait_login_err}") from wait_login_err

        elif target_url_base not in current_url or "/prompts/" not in current_url: # ä¸åœ¨ç™»å½•é¡µï¼Œä½†ä¹Ÿä¸åœ¨ç›®æ ‡é¡µ
            await save_error_snapshot("init_unexpected_page")
            logger.error(f"åˆå§‹å¯¼èˆªåé¡µé¢ URL æ„å¤–: {current_url}ã€‚æœŸæœ›åŒ…å« '{target_url_base}' å’Œ '/prompts/'ã€‚")
            raise RuntimeError(f"åˆå§‹å¯¼èˆªåå‡ºç°æ„å¤–é¡µé¢: {current_url}ã€‚")

        logger.info(f"-> ç¡®è®¤å½“å‰ä½äº AI Studio å¯¹è¯é¡µé¢: {current_url}")
        await found_page.bring_to_front() # å°†é¡µé¢å¸¦åˆ°æœ€å‰
        try:
            # ç­‰å¾…æ ¸å¿ƒ UI å…ƒç´ åŠ è½½å®Œæˆ
            input_wrapper_locator = found_page.locator('ms-prompt-input-wrapper')
            await expect_async(input_wrapper_locator).to_be_visible(timeout=35000)
            await expect_async(found_page.locator(INPUT_SELECTOR)).to_be_visible(timeout=10000)
            logger.info("-> âœ… æ ¸å¿ƒè¾“å…¥åŒºåŸŸå¯è§ã€‚")

            model_wrapper_locator = found_page.locator('#mat-select-value-0 mat-select-trigger').first
            model_name_on_page = await model_wrapper_locator.inner_text(timeout=5000) # å¢åŠ è¶…æ—¶
            logger.info(f"-> ğŸ¤– é¡µé¢æ£€æµ‹åˆ°çš„å½“å‰æ¨¡å‹: {model_name_on_page}")
            
            result_page_instance = found_page
            result_page_ready = True
            logger.info(f"âœ… é¡µé¢é€»è¾‘åˆå§‹åŒ–æˆåŠŸã€‚")
            return result_page_instance, result_page_ready
        except Exception as input_visible_err:
             await save_error_snapshot("init_fail_input_timeout")
             logger.error(f"é¡µé¢åˆå§‹åŒ–å¤±è´¥ï¼šæ ¸å¿ƒè¾“å…¥åŒºåŸŸæœªåœ¨é¢„æœŸæ—¶é—´å†…å˜ä¸ºå¯è§ã€‚æœ€åçš„ URL æ˜¯ {found_page.url}", exc_info=True)
             raise RuntimeError(f"é¡µé¢åˆå§‹åŒ–å¤±è´¥ï¼šæ ¸å¿ƒè¾“å…¥åŒºåŸŸæœªåœ¨é¢„æœŸæ—¶é—´å†…å˜ä¸ºå¯è§ã€‚æœ€åçš„ URL æ˜¯ {found_page.url}") from input_visible_err

    except Exception as e_init_page: # æ•è· _initialize_page_logic å†…éƒ¨æ‰€æœ‰æœªå¤„ç†çš„å¼‚å¸¸
        logger.critical(f"âŒ é¡µé¢é€»è¾‘åˆå§‹åŒ–æœŸé—´å‘ç”Ÿä¸¥é‡æ„å¤–é”™è¯¯: {e_init_page}", exc_info=True)
        if temp_context and not temp_context.is_closed(): # ç¡®ä¿ä¸Šä¸‹æ–‡å­˜åœ¨ä¸”æœªå…³é—­
            try: await temp_context.close()
            except Exception: pass # å¿½ç•¥å…³é—­æ—¶çš„é”™è¯¯
        await save_error_snapshot("init_unexpected_error") # å°è¯•ä¿å­˜å¿«ç…§
        raise RuntimeError(f"é¡µé¢åˆå§‹åŒ–æ„å¤–é”™è¯¯: {e_init_page}") from e_init_page
    # temp_context åœ¨æˆåŠŸæ—¶ä¸å…³é—­ï¼Œå› ä¸º result_page_instance å±äºå®ƒã€‚
    # å®ƒå°†åœ¨æµè§ˆå™¨è¿æ¥å…³é—­æ—¶ï¼ˆåœ¨ lifespan çš„ finally å—ä¸­ï¼‰è¢«å…³é—­ã€‚

async def _close_page_logic():
    # (ä»£ç ä¸ä¹‹å‰ç‰ˆæœ¬ç›¸åŒ)
    global page_instance, is_page_ready
    logger.info("--- è¿è¡Œé¡µé¢é€»è¾‘å…³é—­ --- ") # ä½¿ç”¨ logger
    if page_instance and not page_instance.is_closed():
        try:
            await page_instance.close()
            logger.info("   âœ… é¡µé¢å·²å…³é—­")
        except PlaywrightAsyncError as pw_err:
            logger.warning(f"   âš ï¸ å…³é—­é¡µé¢æ—¶å‡ºç°Playwrighté”™è¯¯: {pw_err}")
        except asyncio.TimeoutError as timeout_err: # asyncio.TimeoutError
            logger.warning(f"   âš ï¸ å…³é—­é¡µé¢æ—¶è¶…æ—¶: {timeout_err}")
        except Exception as other_err:
            logger.error(f"   âš ï¸ å…³é—­é¡µé¢æ—¶å‡ºç°æ„å¤–é”™è¯¯: {other_err} (ç±»å‹: {type(other_err).__name__})", exc_info=True)
    page_instance = None
    is_page_ready = False
    logger.info("é¡µé¢é€»è¾‘çŠ¶æ€å·²é‡ç½®ã€‚")
    return None, False

async def _handle_model_list_response(response: Any):
    global global_model_list_raw_json, parsed_model_list, model_list_fetch_event, logger, MODELS_ENDPOINT_URL_CONTAINS, DEBUG_LOGS_ENABLED, excluded_model_ids # Ensuring excluded_model_ids is the one used globally

    if MODELS_ENDPOINT_URL_CONTAINS in response.url and response.ok:
        logger.info(f"æ•è·åˆ°æ½œåœ¨çš„æ¨¡å‹åˆ—è¡¨å“åº”æ¥è‡ª: {response.url} (çŠ¶æ€: {response.status})")
        try:
            data = await response.json()
            models_array_container = None
            if isinstance(data, list) and data: # ç¡®ä¿ data éç©º
                # é’ˆå¯¹ [[[fields...]]] ç»“æ„
                if isinstance(data[0], list) and data[0] and isinstance(data[0][0], list):
                    logger.info("æ£€æµ‹åˆ°ä¸‰å±‚åˆ—è¡¨ç»“æ„ data[0][0] is list. models_array_container è®¾ç½®ä¸º data[0]ã€‚")
                    models_array_container = data[0]
                # é’ˆå¯¹ [[fields...], [fields...]] ç»“æ„
                elif isinstance(data[0], list) and data[0] and isinstance(data[0][0], str): # å‡è®¾å­—æ®µæ˜¯å­—ç¬¦ä¸²
                    logger.info("æ£€æµ‹åˆ°ä¸¤å±‚åˆ—è¡¨ç»“æ„ data[0][0] is str. models_array_container è®¾ç½®ä¸º dataã€‚")
                    models_array_container = data
                # é’ˆå¯¹ [{"id":...}, {"id":...}] ç»“æ„ (OpenAI é£æ ¼)
                elif isinstance(data[0], dict):
                    logger.info("æ£€æµ‹åˆ°æ ¹åˆ—è¡¨ï¼Œå…ƒç´ ä¸ºå­—å…¸ã€‚ç›´æ¥ä½¿ç”¨ data ä½œä¸º models_array_containerã€‚")
                    models_array_container = data
                else:
                    logger.warning(f"æœªçŸ¥çš„åˆ—è¡¨åµŒå¥—ç»“æ„ã€‚data[0] ç±»å‹: {type(data[0]) if data else 'N/A'}ã€‚data[0] é¢„è§ˆ: {str(data[0])[:200] if data else 'N/A'}")
                    # å¯ä»¥è€ƒè™‘å°† data ç›´æ¥èµ‹ç»™ models_array_container ä½œä¸ºæœ€åçš„å°è¯•ï¼Œæˆ–è€…ç›´æ¥è¿”å›
                    # models_array_container = data # è°¨æ…ä½¿ç”¨ï¼Œå¯èƒ½å¯¼è‡´åç»­è§£æé—®é¢˜
            elif isinstance(data, dict):
                if 'data' in data and isinstance(data['data'], list):
                    models_array_container = data['data']
                elif 'models' in data and isinstance(data['models'], list):
                    models_array_container = data['models']
                else:
                    for key, value in data.items():
                        if isinstance(value, list) and len(value) > 0 and isinstance(value[0], (dict, list)):
                            models_array_container = value
                            logger.info(f"æ¨¡å‹åˆ—è¡¨æ•°æ®åœ¨ '{key}' é”®ä¸‹é€šè¿‡å¯å‘å¼æœç´¢æ‰¾åˆ°ã€‚")
                            break
                    if models_array_container is None:
                        logger.warning("åœ¨å­—å…¸å“åº”ä¸­æœªèƒ½è‡ªåŠ¨å®šä½æ¨¡å‹åˆ—è¡¨æ•°ç»„ã€‚")
                        if not model_list_fetch_event.is_set(): model_list_fetch_event.set()
                        return
            else:
                logger.warning(f"æ¥æ”¶åˆ°çš„æ¨¡å‹åˆ—è¡¨æ•°æ®æ—¢ä¸æ˜¯åˆ—è¡¨ä¹Ÿä¸æ˜¯å­—å…¸: {type(data)}")
                if not model_list_fetch_event.is_set(): model_list_fetch_event.set()
                return

            if models_array_container is not None:
                new_parsed_list = []
                for entry_in_container in models_array_container:
                    model_fields_list = None
                    if isinstance(entry_in_container, dict):
                        potential_id = entry_in_container.get('id', entry_in_container.get('model_id', entry_in_container.get('modelId')))
                        if potential_id: model_fields_list = entry_in_container
                        else: model_fields_list = list(entry_in_container.values())
                    elif isinstance(entry_in_container, list):
                        model_fields_list = entry_in_container
                    else: 
                        logger.debug(f"Skipping entry of unknown type: {type(entry_in_container)}")
                        continue
                    
                    if not model_fields_list: 
                        logger.debug("Skipping entry because model_fields_list is empty or None.")
                        continue

                    model_id_path_str = None
                    display_name_candidate = ""
                    description_candidate = "N/A"
                    default_max_output_tokens_val = None
                    default_top_p_val = None
                    default_temperature_val = 1.0 
                    supported_max_output_tokens_val = None 

                    current_model_id_for_log = "UnknownModelYet"
                    try:
                        if isinstance(model_fields_list, list):
                            if not (len(model_fields_list) > 0 and isinstance(model_fields_list[0], (str, int, float))):
                                logger.debug(f"Skipping list-based model_fields due to invalid first element: {str(model_fields_list)[:100]}")
                                continue
                            model_id_path_str = str(model_fields_list[0])
                            current_model_id_for_log = model_id_path_str.split('/')[-1] if model_id_path_str and '/' in model_id_path_str else model_id_path_str
                            display_name_candidate = str(model_fields_list[3]) if len(model_fields_list) > 3 else ""
                            description_candidate = str(model_fields_list[4]) if len(model_fields_list) > 4 else "N/A"
                            
                            if len(model_fields_list) > 6 and model_fields_list[6] is not None:
                                try: 
                                    val_int = int(model_fields_list[6])
                                    default_max_output_tokens_val = val_int
                                    supported_max_output_tokens_val = val_int
                                except (ValueError, TypeError):
                                    logger.warning(f"æ¨¡å‹ {current_model_id_for_log}: æ— æ³•å°†åˆ—è¡¨ç´¢å¼•6çš„å€¼ '{model_fields_list[6]}' è§£æä¸º max_output_tokensã€‚")
                            
                            if len(model_fields_list) > 9 and model_fields_list[9] is not None:
                                try: 
                                    raw_top_p = float(model_fields_list[9])
                                    if not (0.0 <= raw_top_p <= 1.0):
                                        logger.warning(f"æ¨¡å‹ {current_model_id_for_log}: åŸå§‹ top_på€¼ {raw_top_p} (æ¥è‡ªåˆ—è¡¨ç´¢å¼•9) è¶…å‡º [0,1] èŒƒå›´ï¼Œå°†è£å‰ªã€‚")
                                        default_top_p_val = max(0.0, min(1.0, raw_top_p))
                                    else:
                                        default_top_p_val = raw_top_p
                                except (ValueError, TypeError):
                                    logger.warning(f"æ¨¡å‹ {current_model_id_for_log}: æ— æ³•å°†åˆ—è¡¨ç´¢å¼•9çš„å€¼ '{model_fields_list[9]}' è§£æä¸º top_pã€‚")

                        elif isinstance(model_fields_list, dict):
                            model_id_path_str = str(model_fields_list.get('id', model_fields_list.get('model_id', model_fields_list.get('modelId'))))
                            current_model_id_for_log = model_id_path_str.split('/')[-1] if model_id_path_str and '/' in model_id_path_str else model_id_path_str
                            display_name_candidate = str(model_fields_list.get('displayName', model_fields_list.get('display_name', model_fields_list.get('name', ''))))
                            description_candidate = str(model_fields_list.get('description', "N/A"))
                            
                            mot_parsed = model_fields_list.get('maxOutputTokens', model_fields_list.get('defaultMaxOutputTokens', model_fields_list.get('outputTokenLimit')))
                            if mot_parsed is not None:
                                try: 
                                    val_int = int(mot_parsed)
                                    default_max_output_tokens_val = val_int
                                    supported_max_output_tokens_val = val_int
                                except (ValueError, TypeError):
                                     logger.warning(f"æ¨¡å‹ {current_model_id_for_log}: æ— æ³•å°†å­—å…¸å€¼ '{mot_parsed}' è§£æä¸º max_output_tokensã€‚")

                            top_p_parsed = model_fields_list.get('topP', model_fields_list.get('defaultTopP'))
                            if top_p_parsed is not None:
                                try: 
                                    raw_top_p = float(top_p_parsed)
                                    if not (0.0 <= raw_top_p <= 1.0):
                                        logger.warning(f"æ¨¡å‹ {current_model_id_for_log}: åŸå§‹ top_på€¼ {raw_top_p} (æ¥è‡ªå­—å…¸) è¶…å‡º [0,1] èŒƒå›´ï¼Œå°†è£å‰ªã€‚")
                                        default_top_p_val = max(0.0, min(1.0, raw_top_p))
                                    else:
                                        default_top_p_val = raw_top_p
                                except (ValueError, TypeError):
                                    logger.warning(f"æ¨¡å‹ {current_model_id_for_log}: æ— æ³•å°†å­—å…¸å€¼ '{top_p_parsed}' è§£æä¸º top_pã€‚")
                            
                            temp_parsed = model_fields_list.get('temperature', model_fields_list.get('defaultTemperature'))
                            if temp_parsed is not None:
                                try: default_temperature_val = float(temp_parsed)
                                except (ValueError, TypeError):
                                    logger.warning(f"æ¨¡å‹ {current_model_id_for_log}: æ— æ³•å°†å­—å…¸å€¼ '{temp_parsed}' è§£æä¸º temperatureã€‚")
                        else: 
                            logger.debug(f"Skipping entry because model_fields_list is not list or dict: {type(model_fields_list)}")
                            continue
                    except Exception as e_parse_fields:
                        logger.error(f"è§£ææ¨¡å‹å­—æ®µæ—¶å‡ºé”™ for entry {str(entry_in_container)[:100]}: {e_parse_fields}")
                        continue 

                    if model_id_path_str and model_id_path_str.lower() != "none":
                        simple_model_id_str = model_id_path_str.split('/')[-1] if '/' in model_id_path_str else model_id_path_str
                        if simple_model_id_str in excluded_model_ids: # Using excluded_model_ids as per assumption
                            logger.info(f"æ¨¡å‹ '{simple_model_id_str}' åœ¨æ’é™¤åˆ—è¡¨ excluded_model_ids ä¸­ï¼Œå·²è·³è¿‡ã€‚")
                            continue
                        
                        final_display_name_str = display_name_candidate if display_name_candidate else simple_model_id_str.replace("-", " ").title()
                        
                        model_entry_dict = {
                            "id": simple_model_id_str, "object": "model", "created": int(time.time()),
                            "owned_by": "ai_studio", "display_name": final_display_name_str,
                            "description": description_candidate, "raw_model_path": model_id_path_str,
                            "default_temperature": default_temperature_val,
                            "default_max_output_tokens": default_max_output_tokens_val,
                            "supported_max_output_tokens": supported_max_output_tokens_val,
                            "default_top_p": default_top_p_val
                        }
                        new_parsed_list.append(model_entry_dict)
                    else:
                        logger.debug(f"Skipping entry due to invalid model_id_path: {model_id_path_str} from entry {str(entry_in_container)[:100]}")
                
                if new_parsed_list:
                    parsed_model_list = sorted(new_parsed_list, key=lambda m: m.get('display_name', '').lower())
                    global_model_list_raw_json = json.dumps({"data": parsed_model_list, "object": "list"})
                    if DEBUG_LOGS_ENABLED:
                        log_output = f"æˆåŠŸè§£æå’Œæ›´æ–°æ¨¡å‹åˆ—è¡¨ã€‚æ€»å…±è§£ææ¨¡å‹æ•°: {len(parsed_model_list)}.\n"
                        for i, item in enumerate(parsed_model_list[:min(3, len(parsed_model_list))]):
                            log_output += f"  Model {i+1}: ID={item.get('id')}, Name={item.get('display_name')}, Temp={item.get('default_temperature')}, MaxTokDef={item.get('default_max_output_tokens')}, MaxTokSup={item.get('supported_max_output_tokens')}, TopP={item.get('default_top_p')}\n"
                        logger.info(log_output)
                    if not model_list_fetch_event.is_set(): model_list_fetch_event.set()
                elif not parsed_model_list: 
                    logger.warning("è§£æåæ¨¡å‹åˆ—è¡¨ä»ç„¶ä¸ºç©ºã€‚")
                    if not model_list_fetch_event.is_set(): model_list_fetch_event.set()
            else: 
                logger.warning("models_array_container ä¸º Noneï¼Œæ— æ³•è§£ææ¨¡å‹åˆ—è¡¨ã€‚")
                if not model_list_fetch_event.is_set(): model_list_fetch_event.set()

        except json.JSONDecodeError as json_err:
            logger.error(f"è§£ææ¨¡å‹åˆ—è¡¨JSONå¤±è´¥: {json_err}. å“åº” (å‰500å­—): {await response.text()[:500]}")
        except Exception as e_handle_list_resp:
            logger.exception(f"å¤„ç†æ¨¡å‹åˆ—è¡¨å“åº”æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e_handle_list_resp}")
        finally:
            if not model_list_fetch_event.is_set():
                logger.info("å¤„ç†æ¨¡å‹åˆ—è¡¨å“åº”ç»“æŸï¼Œå¼ºåˆ¶è®¾ç½® model_list_fetch_eventã€‚")
                model_list_fetch_event.set()

async def signal_camoufox_shutdown():
    # (æ­¤å‡½æ•°åœ¨ server.py ä¸­å¯èƒ½ä¸å†éœ€è¦ï¼Œåº”ç”± launch_camoufox.py æ§åˆ¶ Camoufox è¿›ç¨‹)
    # ä½†å¦‚æœ Camoufox æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„å¤–éƒ¨æœåŠ¡ï¼Œåˆ™æ­¤é€»è¾‘å¯èƒ½ä»ç„¶ç›¸å…³ã€‚
    # å½“å‰å‡è®¾ Camoufox æ˜¯ç”± launch_camoufox.py ç®¡ç†çš„å†…éƒ¨è¿›ç¨‹ã€‚
    logger.info("   å°è¯•å‘é€å…³é—­ä¿¡å·åˆ° Camoufox æœåŠ¡å™¨ (æ­¤åŠŸèƒ½å¯èƒ½å·²ç”±çˆ¶è¿›ç¨‹å¤„ç†)...")
    ws_endpoint = os.environ.get('CAMOUFOX_WS_ENDPOINT')
    if not ws_endpoint:
        logger.warning("   âš ï¸ æ— æ³•å‘é€å…³é—­ä¿¡å·ï¼šæœªæ‰¾åˆ° CAMOUFOX_WS_ENDPOINT ç¯å¢ƒå˜é‡ã€‚")
        return
    if not browser_instance or not browser_instance.is_connected():
        logger.warning("   âš ï¸ æµè§ˆå™¨å®ä¾‹å·²æ–­å¼€æˆ–æœªåˆå§‹åŒ–ï¼Œè·³è¿‡å…³é—­ä¿¡å·å‘é€ã€‚")
        return
    # å®é™…çš„å…³é—­ä¿¡å·å‘é€é€»è¾‘å–å†³äº Camoufox å¦‚ä½•æ¥æ”¶å…³é—­æŒ‡ä»¤ã€‚
    # è¿™é‡Œåªæ˜¯ä¸€ä¸ªå ä½ç¬¦ã€‚
    try:
        # ä¾‹å¦‚ï¼Œå¦‚æœ Camoufox æœ‰ä¸€ä¸ªç‰¹æ®Šçš„ WebSocket æ¶ˆæ¯æˆ– HTTP ç«¯ç‚¹ç”¨äºå…³é—­ï¼š
        # await send_shutdown_command_to_camoufox(ws_endpoint)
        await asyncio.sleep(0.2) # æ¨¡æ‹Ÿæ“ä½œ
        logger.info("   âœ… (æ¨¡æ‹Ÿ) å…³é—­ä¿¡å·å·²å¤„ç†ã€‚")
    except Exception as e:
        logger.error(f"   âš ï¸ å‘é€å…³é—­ä¿¡å·è¿‡ç¨‹ä¸­æ•è·å¼‚å¸¸: {e}", exc_info=True)


# --- Lifespan Context Manager (è´Ÿè´£åˆå§‹åŒ–å’Œæ¸…ç†) ---
@asynccontextmanager
async def lifespan(app_param: FastAPI): # app_param æœªä½¿ç”¨
    global playwright_manager, browser_instance, page_instance, worker_task
    global is_playwright_ready, is_browser_connected, is_page_ready, is_initializing
    global logger, log_ws_manager, model_list_fetch_event, current_ai_studio_model_id, excluded_model_ids
    global request_queue, processing_lock, model_switching_lock # å°†è¿™äº›ä¹Ÿå£°æ˜ä¸º global ä»¥ä¾¿èµ‹å€¼

    true_original_stdout, true_original_stderr = sys.stdout, sys.stderr
    initial_stdout_before_redirect, initial_stderr_before_redirect = sys.stdout, sys.stderr

    # ç¡®ä¿ log_ws_manager åœ¨æ—¥å¿—è®¾ç½®å‰åˆå§‹åŒ–
    if log_ws_manager is None:
        log_ws_manager = WebSocketConnectionManager()

    log_level_env = os.environ.get('SERVER_LOG_LEVEL', 'INFO')
    redirect_print_env = os.environ.get('SERVER_REDIRECT_PRINT', 'false')
    
    initial_stdout_before_redirect, initial_stderr_before_redirect = setup_server_logging(
        log_level_name=log_level_env,
        redirect_print_str=redirect_print_env
    )

    # åœ¨æ­¤å¤„åˆå§‹åŒ– asyncio åŒæ­¥åŸè¯­ï¼Œä»¥ç¡®ä¿å®ƒä»¬ç»‘å®šåˆ°æ­£ç¡®çš„äº‹ä»¶å¾ªç¯
    request_queue = asyncio.Queue()
    processing_lock = asyncio.Lock()
    model_switching_lock = asyncio.Lock()
    model_list_fetch_event = asyncio.Event()

    if PLAYWRIGHT_PROXY_SETTINGS:
        logger.info(f"--- ä»£ç†é…ç½®æ£€æµ‹åˆ° (ç”± server.py çš„ lifespan è®°å½•) ---")
        logger.info(f"   å°†ä½¿ç”¨ä»£ç†æœåŠ¡å™¨: {PLAYWRIGHT_PROXY_SETTINGS['server']}")
        if 'bypass' in PLAYWRIGHT_PROXY_SETTINGS:
            logger.info(f"   ç»•è¿‡ä»£ç†çš„ä¸»æœº: {PLAYWRIGHT_PROXY_SETTINGS['bypass']}")
        logger.info(f"-----------------------")
    else:
        logger.info("--- æœªæ£€æµ‹åˆ° HTTP_PROXY æˆ– HTTPS_PROXY ç¯å¢ƒå˜é‡ï¼Œä¸ä½¿ç”¨ä»£ç† (ç”± server.py çš„ lifespan è®°å½•) ---")

    # æ–°å¢: åŠ è½½æ¨¡å‹æ’é™¤åˆ—è¡¨
    load_excluded_models(EXCLUDED_MODELS_FILENAME)

    is_initializing = True
    logger.info("\n" + "="*60 + "\n          ğŸš€ AI Studio Proxy Server (FastAPI App Lifespan) ğŸš€\n" + "="*60)
    logger.info(f"FastAPI åº”ç”¨ç”Ÿå‘½å‘¨æœŸ: å¯åŠ¨ä¸­...")
    try:
        logger.info(f"   å¯åŠ¨ Playwright...")
        playwright_manager = await async_playwright().start()
        is_playwright_ready = True
        logger.info(f"   âœ… Playwright å·²å¯åŠ¨ã€‚")

        ws_endpoint = os.environ.get('CAMOUFOX_WS_ENDPOINT')
        launch_mode = os.environ.get('LAUNCH_MODE', 'unknown')

        if not ws_endpoint:
            if launch_mode == "direct_debug_no_browser":
                logger.warning("CAMOUFOX_WS_ENDPOINT æœªè®¾ç½®ï¼Œä½† LAUNCH_MODE è¡¨æ˜ä¸éœ€è¦æµè§ˆå™¨ã€‚è·³è¿‡æµè§ˆå™¨è¿æ¥ã€‚")
                is_browser_connected = False
                is_page_ready = False
                model_list_fetch_event.set() # æ²¡æœ‰é¡µé¢ï¼Œæ— æ³•è·å–ï¼Œç›´æ¥è®¾ç½®äº‹ä»¶
            else:
                logger.error("æœªæ‰¾åˆ° CAMOUFOX_WS_ENDPOINT ç¯å¢ƒå˜é‡ã€‚Playwright å°†æ— æ³•è¿æ¥åˆ°æµè§ˆå™¨ã€‚")
                raise ValueError("CAMOUFOX_WS_ENDPOINT ç¯å¢ƒå˜é‡ç¼ºå¤±ã€‚")
        else:
            logger.info(f"   è¿æ¥åˆ° Camoufox æœåŠ¡å™¨ (æµè§ˆå™¨ WebSocket ç«¯ç‚¹) äº: {ws_endpoint}")
            try:
                browser_instance = await playwright_manager.firefox.connect(ws_endpoint, timeout=30000)
                is_browser_connected = True
                logger.info(f"   âœ… å·²è¿æ¥åˆ°æµè§ˆå™¨å®ä¾‹: ç‰ˆæœ¬ {browser_instance.version}")
                
                # _initialize_page_logic è¿”å› page å®ä¾‹ï¼Œå¹¶å°†å…¶èµ‹å€¼ç»™å…¨å±€ page_instance
                temp_page_instance, temp_is_page_ready = await _initialize_page_logic(browser_instance)
                if temp_page_instance and temp_is_page_ready:
                    page_instance = temp_page_instance
                    is_page_ready = temp_is_page_ready
                    
                    # æ£€æŸ¥å¹¶å¤„ç†åˆå§‹ localStorage å’Œæ¨¡å‹çŠ¶æ€
                    await _handle_initial_model_state_and_storage(page_instance)

                else: # _initialize_page_logic å¤±è´¥
                    is_page_ready = False
                    if not model_list_fetch_event.is_set(): model_list_fetch_event.set()


            except Exception as connect_err:
                logger.error(f"æœªèƒ½è¿æ¥åˆ° Camoufox æœåŠ¡å™¨ (æµè§ˆå™¨) æˆ–åˆå§‹åŒ–é¡µé¢å¤±è´¥: {connect_err}", exc_info=True)
                if launch_mode != "direct_debug_no_browser":
                    raise RuntimeError(f"æœªèƒ½è¿æ¥åˆ° Camoufox æˆ–åˆå§‹åŒ–é¡µé¢: {connect_err}") from connect_err
                else:
                    is_browser_connected = False
                    is_page_ready = False
                    if not model_list_fetch_event.is_set(): model_list_fetch_event.set() # æ²¡æœ‰é¡µé¢ï¼Œç›´æ¥è®¾ç½®

        # ç­‰å¾…æ¨¡å‹åˆ—è¡¨æ•è·æˆ–è¶…æ—¶
        if is_page_ready and is_browser_connected and not model_list_fetch_event.is_set():
            logger.info("ç­‰å¾…æ¨¡å‹åˆ—è¡¨æ•è· (æœ€å¤šç­‰å¾…15ç§’)...")
            try:
                await asyncio.wait_for(model_list_fetch_event.wait(), timeout=15.0) # å¢åŠ ç­‰å¾…æ—¶é—´
                if model_list_fetch_event.is_set():
                    logger.info("æ¨¡å‹åˆ—è¡¨äº‹ä»¶å·²è§¦å‘ã€‚")
                else: # è¶…æ—¶ä½†äº‹ä»¶æœªè®¾ç½®ï¼ˆç†è®ºä¸Šwait_forä¼šæŠ›TimeoutErrorï¼‰
                    logger.warning("æ¨¡å‹åˆ—è¡¨äº‹ä»¶ç­‰å¾…åä»æœªè®¾ç½®ã€‚")
            except asyncio.TimeoutError:
                logger.warning("ç­‰å¾…æ¨¡å‹åˆ—è¡¨æ•è·è¶…æ—¶ã€‚å°†ä½¿ç”¨é»˜è®¤æˆ–ç©ºåˆ—è¡¨ã€‚")
            finally: # ç¡®ä¿äº‹ä»¶æœ€ç»ˆè¢«è®¾ç½®ï¼Œé¿å…åç»­é˜»å¡
                if not model_list_fetch_event.is_set():
                    model_list_fetch_event.set()
        elif not (is_page_ready and is_browser_connected): # å¦‚æœé¡µé¢/æµè§ˆå™¨æ²¡å‡†å¤‡å¥½ï¼Œä¹Ÿè®¾ç½®äº‹ä»¶
             if not model_list_fetch_event.is_set(): model_list_fetch_event.set()


        if (is_page_ready and is_browser_connected) or launch_mode == "direct_debug_no_browser":
             logger.info(f"   å¯åŠ¨è¯·æ±‚å¤„ç† Worker...")
             worker_task = asyncio.create_task(queue_worker())
             logger.info(f"   âœ… è¯·æ±‚å¤„ç† Worker å·²å¯åŠ¨ã€‚")
        elif launch_mode == "direct_debug_no_browser":
            logger.warning("æµè§ˆå™¨å’Œé¡µé¢æœªå°±ç»ª (direct_debug_no_browser æ¨¡å¼)ï¼Œè¯·æ±‚å¤„ç† Worker æœªå¯åŠ¨ã€‚API å¯èƒ½åŠŸèƒ½å—é™ã€‚")
        else:
             logger.error("é¡µé¢æˆ–æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œæ— æ³•å¯åŠ¨ Workerã€‚")
             if not model_list_fetch_event.is_set(): model_list_fetch_event.set() # ç¡®ä¿äº‹ä»¶è®¾ç½®
             raise RuntimeError("é¡µé¢æˆ–æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œæ— æ³•å¯åŠ¨ Workerã€‚")

        logger.info(f"âœ… FastAPI åº”ç”¨ç”Ÿå‘½å‘¨æœŸ: å¯åŠ¨å®Œæˆã€‚æœåŠ¡å·²å°±ç»ªã€‚")
        is_initializing = False
        yield

    except Exception as startup_err:
        logger.critical(f"âŒ FastAPI åº”ç”¨ç”Ÿå‘½å‘¨æœŸ: å¯åŠ¨æœŸé—´å‘ç”Ÿä¸¥é‡é”™è¯¯: {startup_err}", exc_info=True)
        if not model_list_fetch_event.is_set(): model_list_fetch_event.set() # é”™è¯¯æƒ…å†µä¸‹ä¹Ÿè®¾ç½®
        if worker_task and not worker_task.done(): worker_task.cancel()
        if browser_instance and browser_instance.is_connected():
            try: await browser_instance.close()
            except: pass
        if playwright_manager:
            try: await playwright_manager.stop()
            except: pass
        raise RuntimeError(f"åº”ç”¨ç¨‹åºå¯åŠ¨å¤±è´¥: {startup_err}") from startup_err
    finally:
        is_initializing = False # é‡ç½®çŠ¶æ€
        logger.info(f"\nFastAPI åº”ç”¨ç”Ÿå‘½å‘¨æœŸ: å…³é—­ä¸­...")
        if worker_task and not worker_task.done():
             logger.info(f"   æ­£åœ¨å–æ¶ˆè¯·æ±‚å¤„ç† Worker...")
             worker_task.cancel()
             try:
                 await asyncio.wait_for(worker_task, timeout=5.0)
                 logger.info(f"   âœ… è¯·æ±‚å¤„ç† Worker å·²åœæ­¢/å–æ¶ˆã€‚")
             except asyncio.TimeoutError: logger.warning(f"   âš ï¸ Worker ç­‰å¾…è¶…æ—¶ã€‚")
             except asyncio.CancelledError: logger.info(f"   âœ… è¯·æ±‚å¤„ç† Worker å·²ç¡®è®¤å–æ¶ˆã€‚")
             except Exception as wt_err: logger.error(f"   âŒ ç­‰å¾… Worker åœæ­¢æ—¶å‡ºé”™: {wt_err}", exc_info=True)

        if page_instance and not page_instance.is_closed(): # åœ¨å…³é—­é¡µé¢å‰ï¼Œç¡®ä¿ç§»é™¤ç›‘å¬å™¨
            try:
                # å°è¯•ç§»é™¤ï¼Œä»¥é˜² _handle_model_list_response æœªæˆåŠŸæ‰§è¡Œæˆ–æœªç§»é™¤
                # page_instance.remove_listener("response", _handle_model_list_response) # åŸæœ‰ä»£ç 
                # logger.info("Lifespan æ¸…ç†ï¼šå°è¯•ç§»é™¤æ¨¡å‹åˆ—è¡¨å“åº”ç›‘å¬å™¨ã€‚") # åŸæœ‰ä»£ç 
                logger.info("Lifespan æ¸…ç†ï¼šç§»é™¤æ¨¡å‹åˆ—è¡¨å“åº”ç›‘å¬å™¨ã€‚")
                page_instance.remove_listener("response", _handle_model_list_response)
            except Exception as e: # æ¯”å¦‚ç›‘å¬å™¨ä¸å­˜åœ¨çš„é”™è¯¯
                logger.debug(f"Lifespan æ¸…ç†ï¼šç§»é™¤ç›‘å¬å™¨æ—¶å‘ç”Ÿéä¸¥é‡é”™è¯¯æˆ–ç›‘å¬å™¨æœ¬ä¸å­˜åœ¨: {e}")
        
        if page_instance: 
            await _close_page_logic() # è¿™ä¼šè®¾ç½® page_instance = None

        if browser_instance:
            logger.info(f"   æ­£åœ¨å…³é—­ä¸æµè§ˆå™¨å®ä¾‹çš„è¿æ¥...")
            try:
                if browser_instance.is_connected():
                    await browser_instance.close()
                    logger.info(f"   âœ… æµè§ˆå™¨è¿æ¥å·²å…³é—­ã€‚")
                else: logger.info(f"   â„¹ï¸ æµè§ˆå™¨å…ˆå‰å·²æ–­å¼€è¿æ¥ã€‚")
            except Exception as close_err: logger.error(f"   âŒ å…³é—­æµè§ˆå™¨è¿æ¥æ—¶å‡ºé”™: {close_err}", exc_info=True)
            finally: browser_instance = None; is_browser_connected = False; is_page_ready = False

        if playwright_manager:
            logger.info(f"   åœæ­¢ Playwright...")
            try:
                await playwright_manager.stop()
                logger.info(f"   âœ… Playwright å·²åœæ­¢ã€‚")
            except Exception as stop_err: logger.error(f"   âŒ åœæ­¢ Playwright æ—¶å‡ºé”™: {stop_err}", exc_info=True)
            finally: playwright_manager = None; is_playwright_ready = False
        
        restore_original_streams(initial_stdout_before_redirect, initial_stderr_before_redirect)
        restore_original_streams(true_original_stdout, true_original_stderr) # å†æ¬¡ç¡®ä¿æ¢å¤åˆ°æœ€åŸå§‹çš„
        logger.info(f"âœ… FastAPI åº”ç”¨ç”Ÿå‘½å‘¨æœŸ: å…³é—­å®Œæˆã€‚")


# --- FastAPI App å®šä¹‰ ---
app = FastAPI(
    title="AI Studio Proxy Server (é›†æˆæ¨¡å¼)",
    description="é€šè¿‡ Playwrightä¸ AI Studio äº¤äº’çš„ä»£ç†æœåŠ¡å™¨ã€‚",
    version="0.6.0-integrated",
    lifespan=lifespan
)

# --- API Endpoints ---
@app.get("/", response_class=FileResponse)
async def read_index():
    index_html_path = os.path.join(os.path.dirname(__file__), "index.html")
    if not os.path.exists(index_html_path):
        logger.error(f"index.html not found at {index_html_path}")
        raise HTTPException(status_code=404, detail="index.html not found")
    return FileResponse(index_html_path)

@app.get("/webui.css")
async def get_css():
    css_path = os.path.join(os.path.dirname(__file__), "webui.css")
    if not os.path.exists(css_path):
        logger.error(f"webui.css not found at {css_path}")
        raise HTTPException(status_code=404, detail="webui.css not found")
    return FileResponse(css_path, media_type="text/css")

@app.get("/webui.js")
async def get_js():
    js_path = os.path.join(os.path.dirname(__file__), "webui.js")
    if not os.path.exists(js_path):
        logger.error(f"webui.js not found at {js_path}")
        raise HTTPException(status_code=404, detail="webui.js not found")
    return FileResponse(js_path, media_type="application/javascript")

@app.get("/api/info")
async def get_api_info(request: Request):
    server_port = request.url.port
    if not server_port and hasattr(request.app.state, 'server_port'):
        server_port = request.app.state.server_port
    if not server_port: # æœ€ç»ˆåå¤‡
        # å°è¯•ä»ç¯å¢ƒå˜é‡è·å–ï¼Œå¦‚æœ launch_camoufox.py è®¾ç½®äº†å®ƒ
        server_port = os.environ.get('SERVER_PORT_INFO', '8000')


    host = request.headers.get('host') or f"127.0.0.1:{server_port}"
    scheme = request.headers.get('x-forwarded-proto', 'http')
    base_url = f"{scheme}://{host}"
    api_base = f"{base_url}/v1"

    # ä½¿ç”¨å…¨å±€ current_ai_studio_model_id (å¦‚æœæœ‰æ•ˆ) ä½œä¸ºæ¨¡å‹åç§°ï¼Œå¦åˆ™å›é€€åˆ° MODEL_NAME
    effective_model_name = current_ai_studio_model_id if current_ai_studio_model_id else MODEL_NAME
    
    return JSONResponse(content={
        "model_name": effective_model_name, # ä½¿ç”¨è·å–åˆ°çš„æˆ–é»˜è®¤çš„æ¨¡å‹åç§°
        "api_base_url": api_base,
        "server_base_url": base_url,
        "api_key_required": False,
        "message": "API Key is not required."
    })

@app.get("/health")
async def health_check():
    is_worker_running = bool(worker_task and not worker_task.done())
    launch_mode = os.environ.get('LAUNCH_MODE', 'unknown')
    browser_page_critical = launch_mode != "direct_debug_no_browser"

    core_ready_conditions = [not is_initializing, is_playwright_ready]
    if browser_page_critical:
        core_ready_conditions.extend([is_browser_connected, is_page_ready])
    
    is_core_ready = all(core_ready_conditions)
    status_val = "OK" if is_core_ready and is_worker_running else "Error"
    q_size = request_queue.qsize() if request_queue else -1
    
    status_message_parts = []
    if is_initializing: status_message_parts.append("åˆå§‹åŒ–è¿›è¡Œä¸­")
    if not is_playwright_ready: status_message_parts.append("Playwright æœªå°±ç»ª")
    if browser_page_critical:
        if not is_browser_connected: status_message_parts.append("æµè§ˆå™¨æœªè¿æ¥")
        if not is_page_ready: status_message_parts.append("é¡µé¢æœªå°±ç»ª")
    if not is_worker_running: status_message_parts.append("Worker æœªè¿è¡Œ")

    status = {
        "status": status_val,
        "message": "",
        "details": {
            "playwrightReady": is_playwright_ready,
            "browserConnected": is_browser_connected,
            "pageReady": is_page_ready,
            "initializing": is_initializing,
            "workerRunning": is_worker_running,
            "queueLength": q_size,
            "launchMode": launch_mode,
            "browserAndPageCritical": browser_page_critical
        }
    }
    if status_val == "OK":
        status["message"] = f"æœåŠ¡è¿è¡Œä¸­;é˜Ÿåˆ—é•¿åº¦: {q_size}ã€‚"
        return JSONResponse(content=status, status_code=200)
    else:
        status["message"] = f"æœåŠ¡ä¸å¯ç”¨;é—®é¢˜: {(', '.join(status_message_parts) if status_message_parts else 'æœªçŸ¥åŸå› ')}. é˜Ÿåˆ—é•¿åº¦: {q_size}."
        return JSONResponse(content=status, status_code=503)

@app.get("/v1/models")
async def list_models():
    logger.info("[API] æ”¶åˆ° /v1/models è¯·æ±‚ã€‚")
    # å¦‚æœäº‹ä»¶æœªè®¾ç½®ä¸”é¡µé¢å®ä¾‹å­˜åœ¨ï¼Œå°è¯•è§¦å‘ä¸€æ¬¡è·å–
    if not model_list_fetch_event.is_set() and page_instance and not page_instance.is_closed():
        logger.info("/v1/models: æ¨¡å‹åˆ—è¡¨äº‹ä»¶æœªè®¾ç½®æˆ–åˆ—è¡¨ä¸ºç©ºï¼Œå°è¯•é¡µé¢åˆ·æ–°ä»¥è§¦å‘æ•è·...")
        try:
            # æ£€æŸ¥ç›‘å¬å™¨æ˜¯å¦å·²é™„åŠ ï¼Œå¦‚æœæœªé™„åŠ ï¼Œåˆ™æ·»åŠ ã€‚
            listener_attached = False
            # Playwrightçš„äº‹ä»¶ç›‘å¬å™¨å­˜å‚¨æ–¹å¼å¯èƒ½å› ç‰ˆæœ¬è€Œå¼‚
            # _events å±æ€§æ˜¯éå…¬å¼€APIï¼Œä½†å¯ç”¨äºè°ƒè¯•æˆ–æ­¤ç§æ£€æŸ¥
            if hasattr(page_instance, '_events') and "response" in page_instance._events:
                for handler_slot_or_func in page_instance._events["response"]:
                    # åœ¨Playwright 1.30+ç‰ˆæœ¬ä¸­ï¼Œç›‘å¬å™¨è¢«åŒ…è£…åœ¨HandlerSlotå¯¹è±¡ä¸­
                    actual_handler = getattr(handler_slot_or_func, 'handler', handler_slot_or_func)
                    if actual_handler == _handle_model_list_response:
                        listener_attached = True
                        break
            
            if not listener_attached:
                logger.info("/v1/models: å“åº”ç›‘å¬å™¨ä¼¼ä¹ä¸å­˜åœ¨æˆ–å·²è¢«ç§»é™¤ï¼Œå°è¯•é‡æ–°æ·»åŠ ã€‚")
                page_instance.on("response", _handle_model_list_response)


            await page_instance.reload(wait_until="domcontentloaded", timeout=20000)
            logger.info(f"é¡µé¢å·²åˆ·æ–°ã€‚ç­‰å¾…æ¨¡å‹åˆ—è¡¨äº‹ä»¶ (æœ€å¤š10ç§’)...")
            await asyncio.wait_for(model_list_fetch_event.wait(), timeout=10.0)
        except asyncio.TimeoutError:
            logger.warning("/v1/models: åˆ·æ–°åç­‰å¾…æ¨¡å‹åˆ—è¡¨äº‹ä»¶è¶…æ—¶ã€‚")
        except PlaywrightAsyncError as reload_err:
            logger.error(f"/v1/models: åˆ·æ–°é¡µé¢å¤±è´¥: {reload_err}")
        except Exception as e: 
            logger.error(f"/v1/models: å°è¯•è§¦å‘æ¨¡å‹åˆ—è¡¨æ•è·æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        finally: # æ— è®ºå¦‚ä½•ï¼Œç¡®ä¿äº‹ä»¶æœ€ç»ˆè¢«è®¾ç½®ï¼Œé¿å…åç»­è¯·æ±‚å¡ä½
            if not model_list_fetch_event.is_set():
                logger.info("/v1/models: å°è¯•æ•è·åï¼Œå¼ºåˆ¶è®¾ç½®æ¨¡å‹åˆ—è¡¨äº‹ä»¶ã€‚")
                model_list_fetch_event.set()


    if parsed_model_list:
        # è¿‡æ»¤æ‰æ’é™¤åˆ—è¡¨ä¸­çš„æ¨¡å‹
        final_model_list = [m for m in parsed_model_list if m.get("id") not in excluded_model_ids]
        logger.info(f"è¿”å›è¿‡æ»¤åçš„ {len(final_model_list)} ä¸ªæ¨¡å‹ (åŸç¼“å­˜ {len(parsed_model_list)} ä¸ª)ã€‚æ’é™¤çš„æœ‰: {excluded_model_ids.intersection(set(m.get('id') for m in parsed_model_list))}")
        return {"object": "list", "data": final_model_list}
    else:
        logger.warning("æ¨¡å‹åˆ—è¡¨ä¸ºç©ºæˆ–æœªæˆåŠŸè·å–ã€‚è¿”å›é»˜è®¤åå¤‡æ¨¡å‹ã€‚")
        # è¿”å›ç¬¦åˆ OpenAI API é£æ ¼çš„åˆ—è¡¨ï¼Œå³ä½¿æ˜¯åå¤‡
        fallback_model_obj = {
            "id": DEFAULT_FALLBACK_MODEL_ID, 
            "object": "model",
            "created": int(time.time()), 
            "owned_by": "camoufox-proxy-fallback",
            "display_name": DEFAULT_FALLBACK_MODEL_ID.replace("-", " ").title(),
            "description": "Default fallback model.",
            "raw_model_path": f"models/{DEFAULT_FALLBACK_MODEL_ID}"
        }
        return {"object": "list", "data": [fallback_model_obj]}

# --- Helper: Detect Error ---
async def detect_and_extract_page_error(page: AsyncPage, req_id: str) -> Optional[str]:
    error_toast_locator = page.locator(ERROR_TOAST_SELECTOR).last
    try:
        await error_toast_locator.wait_for(state='visible', timeout=500)
        message_locator = error_toast_locator.locator('span.content-text')
        error_message = await message_locator.text_content(timeout=500)
        if error_message:
             # print(f"[{req_id}]    æ£€æµ‹åˆ°å¹¶æå–é”™è¯¯æ¶ˆæ¯: {error_message}")
             logger.error(f"[{req_id}]    æ£€æµ‹åˆ°å¹¶æå–é”™è¯¯æ¶ˆæ¯: {error_message}") # logger
             return error_message.strip()
        else:
             # print(f"[{req_id}]    è­¦å‘Š: æ£€æµ‹åˆ°é”™è¯¯æç¤ºæ¡†ï¼Œä½†æ— æ³•æå–æ¶ˆæ¯ã€‚")
             logger.warning(f"[{req_id}]    æ£€æµ‹åˆ°é”™è¯¯æç¤ºæ¡†ï¼Œä½†æ— æ³•æå–æ¶ˆæ¯ã€‚") # logger
             return "æ£€æµ‹åˆ°é”™è¯¯æç¤ºæ¡†ï¼Œä½†æ— æ³•æå–ç‰¹å®šæ¶ˆæ¯ã€‚"
    except PlaywrightAsyncError: return None
    except Exception as e:
        # print(f"[{req_id}]    è­¦å‘Š: æ£€æŸ¥é¡µé¢é”™è¯¯æ—¶å‡ºé”™: {e}")
        logger.warning(f"[{req_id}]    æ£€æŸ¥é¡µé¢é”™è¯¯æ—¶å‡ºé”™: {e}") # logger
        return None

# --- Snapshot Helper --- (Simplified)
async def save_error_snapshot(error_name: str = 'error'):
    # ... (Existing implementation) ...
    name_parts = error_name.split('_')
    req_id = name_parts[-1] if len(name_parts) > 1 and len(name_parts[-1]) == 7 else None
    base_error_name = error_name if not req_id else '_'.join(name_parts[:-1])
    log_prefix = f"[{req_id}]" if req_id else "[æ— è¯·æ±‚ID]"
    page_to_snapshot = page_instance
    if not browser_instance or not browser_instance.is_connected() or not page_to_snapshot or page_to_snapshot.is_closed():
        # print(f"{log_prefix} æ— æ³•ä¿å­˜å¿«ç…§ ({base_error_name})ï¼Œæµè§ˆå™¨/é¡µé¢ä¸å¯ç”¨ã€‚")
        logger.warning(f"{log_prefix} æ— æ³•ä¿å­˜å¿«ç…§ ({base_error_name})ï¼Œæµè§ˆå™¨/é¡µé¢ä¸å¯ç”¨ã€‚") # logger
        return
    # print(f"{log_prefix} å°è¯•ä¿å­˜é”™è¯¯å¿«ç…§ ({base_error_name})...")
    logger.info(f"{log_prefix} å°è¯•ä¿å­˜é”™è¯¯å¿«ç…§ ({base_error_name})...") # logger
    timestamp = int(time.time() * 1000)
    error_dir = os.path.join(os.path.dirname(__file__), 'errors_py')
    try:
        os.makedirs(error_dir, exist_ok=True)
        filename_suffix = f"{req_id}_{timestamp}" if req_id else f"{timestamp}"
        filename_base = f"{base_error_name}_{filename_suffix}"
        screenshot_path = os.path.join(error_dir, f"{filename_base}.png")
        html_path = os.path.join(error_dir, f"{filename_base}.html")
        try:
            await page_to_snapshot.screenshot(path=screenshot_path, full_page=True, timeout=15000)
            # print(f"{log_prefix}   å¿«ç…§å·²ä¿å­˜åˆ°: {screenshot_path}")
            logger.info(f"{log_prefix}   å¿«ç…§å·²ä¿å­˜åˆ°: {screenshot_path}") # logger
        except Exception as ss_err:
            # print(f"{log_prefix}   ä¿å­˜å±å¹•æˆªå›¾å¤±è´¥ ({base_error_name}): {ss_err}")
            logger.error(f"{log_prefix}   ä¿å­˜å±å¹•æˆªå›¾å¤±è´¥ ({base_error_name}): {ss_err}") # logger
        try:
            content = await page_to_snapshot.content()
            f = None
            try:
                f = open(html_path, 'w', encoding='utf-8')
                f.write(content)
                # print(f"{log_prefix}   HTML å·²ä¿å­˜åˆ°: {html_path}")
                logger.info(f"{log_prefix}   HTML å·²ä¿å­˜åˆ°: {html_path}") # logger
            except Exception as write_err:
                # print(f"{log_prefix}   ä¿å­˜ HTML å¤±è´¥ ({base_error_name}): {write_err}")
                logger.error(f"{log_prefix}   ä¿å­˜ HTML å¤±è´¥ ({base_error_name}): {write_err}") # logger
            finally:
                if f:
                    try:
                        f.close()
                        # print(f"{log_prefix}   HTML æ–‡ä»¶å·²æ­£ç¡®å…³é—­")
                        logger.debug(f"{log_prefix}   HTML æ–‡ä»¶å·²æ­£ç¡®å…³é—­") # logger debug
                    except Exception as close_err:
                        # print(f"{log_prefix}   å…³é—­ HTML æ–‡ä»¶æ—¶å‡ºé”™: {close_err}")
                        logger.error(f"{log_prefix}   å…³é—­ HTML æ–‡ä»¶æ—¶å‡ºé”™: {close_err}") # logger
        except Exception as html_err:
            # print(f"{log_prefix}   è·å–é¡µé¢å†…å®¹å¤±è´¥ ({base_error_name}): {html_err}")
            logger.error(f"{log_prefix}   è·å–é¡µé¢å†…å®¹å¤±è´¥ ({base_error_name}): {html_err}") # logger
    except Exception as dir_err:
        # print(f"{log_prefix}   åˆ›å»ºé”™è¯¯ç›®å½•æˆ–ä¿å­˜å¿«ç…§æ—¶å‡ºé”™: {dir_err}")
            print(f"{log_prefix}   è·å–é¡µé¢å†…å®¹å¤±è´¥ ({base_error_name}): {html_err}")
    except Exception as dir_err: print(f"{log_prefix}   åˆ›å»ºé”™è¯¯ç›®å½•æˆ–ä¿å­˜å¿«ç…§æ—¶å‡ºé”™: {dir_err}")

# --- V4: New Helper - Get response via Edit Button ---
async def get_response_via_edit_button(
    page: AsyncPage,
    req_id: str,
    check_client_disconnected: Callable
) -> Optional[str]:
    """Attempts to get the response content using the edit button.
       Implementation mirrors original stream logic closely.
    """
    logger.info(f"[{req_id}] (Helper) å°è¯•é€šè¿‡ç¼–è¾‘æŒ‰é’®è·å–å“åº”...") # logger
    edit_button = page.locator(EDIT_MESSAGE_BUTTON_SELECTOR)
    textarea = page.locator(MESSAGE_TEXTAREA_SELECTOR)
    finish_edit_button = page.locator(FINISH_EDIT_BUTTON_SELECTOR)

    try:
        # 1. Click the Edit button
        logger.info(f"[{req_id}]   - å®šä½å¹¶ç‚¹å‡»ç¼–è¾‘æŒ‰é’®...") # logger
        try:
            # Direct Playwright calls with timeout
            await expect_async(edit_button).to_be_visible(timeout=CLICK_TIMEOUT_MS)
            check_client_disconnected("ç¼–è¾‘å“åº” - ç¼–è¾‘æŒ‰é’®å¯è§å: ")
            await edit_button.click(timeout=CLICK_TIMEOUT_MS)
            logger.info(f"[{req_id}]   - ç¼–è¾‘æŒ‰é’®å·²ç‚¹å‡»ã€‚") # logger
        except Exception as edit_btn_err:
            logger.error(f"[{req_id}]   - ç¼–è¾‘æŒ‰é’®ä¸å¯è§æˆ–ç‚¹å‡»å¤±è´¥: {edit_btn_err}") # logger
            await save_error_snapshot(f"edit_response_edit_button_failed_{req_id}")
            return None

        check_client_disconnected("ç¼–è¾‘å“åº” - ç‚¹å‡»ç¼–è¾‘æŒ‰é’®å: ")
        await asyncio.sleep(0.3) # Use asyncio.sleep
        check_client_disconnected("ç¼–è¾‘å“åº” - ç‚¹å‡»ç¼–è¾‘æŒ‰é’®åå»¶æ—¶å: ")

        # 2. Get content from textarea
        logger.info(f"[{req_id}]   - ä»æ–‡æœ¬åŒºåŸŸè·å–å†…å®¹...") # logger
        response_content = None
        textarea_failed = False # Flag to track if textarea read failed
        try:
            # Direct Playwright call with timeout
            await expect_async(textarea).to_be_visible(timeout=CLICK_TIMEOUT_MS)
            check_client_disconnected("ç¼–è¾‘å“åº” - æ–‡æœ¬åŒºåŸŸå¯è§å: ")

            # Try getting content from data-value attribute first
            try:
                # Direct evaluate call (no specific timeout in Playwright evaluate)
                data_value_content = await textarea.evaluate('el => el.getAttribute("data-value")')
                check_client_disconnected("ç¼–è¾‘å“åº” - evaluate data-value å: ")
                if data_value_content is not None:
                    response_content = str(data_value_content)
            except Exception as data_val_err:
                logger.warning(f"[{req_id}]   - è·å– data-value å¤±è´¥: {data_val_err}") # logger warning
                check_client_disconnected("ç¼–è¾‘å“åº” - evaluate data-value é”™è¯¯å: ")

            # If data-value failed or returned empty, try input_value
            if not response_content:
                try:
                    # Direct input_value call with timeout
                    input_val_content = await textarea.input_value(timeout=CLICK_TIMEOUT_MS)
                    check_client_disconnected("ç¼–è¾‘å“åº” - input_value å: ")
                    if input_val_content is not None:
                        response_content = str(input_val_content)
                except Exception as input_val_err:
                     logger.warning(f"[{req_id}]   - è·å– input_value å¤±è´¥: {input_val_err}") # logger warning
                     check_client_disconnected("ç¼–è¾‘å“åº” - input_value é”™è¯¯å: ")

            # Now check the final result from either method
            if response_content is not None and response_content.strip():
                response_content = response_content.strip()
                content_preview = response_content[:100].replace('\\n', '\\\\n')
                logger.info(f"[{req_id}]   - âœ… æœ€ç»ˆæˆåŠŸè·å–å†…å®¹ (é•¿åº¦={len(response_content)}): '{content_preview}...'") # logger
            else:
                if response_content is None:
                    logger.warning(f"[{req_id}]   - æ‰€æœ‰æ–¹æ³• (data-value, input_value) å†…å®¹è·å–å‡å¤±è´¥æˆ–è¿”å› Noneã€‚") # logger
                else:
                    logger.warning(f"[{req_id}]   - æ‰€æœ‰æ–¹æ³• (data-value, input_value) å†…å®¹è·å–è¿”å›ç©ºå­—ç¬¦ä¸²ã€‚") # logger
                textarea_failed = True
                response_content = None

        except Exception as textarea_err:
            logger.error(f"[{req_id}]   - å®šä½æˆ–å¤„ç†æ–‡æœ¬åŒºåŸŸæ—¶å¤±è´¥: {textarea_err}") # logger
            textarea_failed = True
            response_content = None
            check_client_disconnected("ç¼–è¾‘å“åº” - è·å–æ–‡æœ¬åŒºåŸŸé”™è¯¯å: ")

        # 3. Click the Finish Editing button
        if not textarea_failed:
            logger.info(f"[{req_id}]   - å®šä½å¹¶ç‚¹å‡»å®Œæˆç¼–è¾‘æŒ‰é’®...") # logger
            try:
                # Direct Playwright calls with timeout
                await expect_async(finish_edit_button).to_be_visible(timeout=CLICK_TIMEOUT_MS)
                check_client_disconnected("ç¼–è¾‘å“åº” - å®ŒæˆæŒ‰é’®å¯è§å: ")
                await finish_edit_button.click(timeout=CLICK_TIMEOUT_MS)
                logger.info(f"[{req_id}]   - å®Œæˆç¼–è¾‘æŒ‰é’®å·²ç‚¹å‡»ã€‚") # logger
            except Exception as finish_btn_err:
                logger.warning(f"[{req_id}]   - å®Œæˆç¼–è¾‘æŒ‰é’®ä¸å¯è§æˆ–ç‚¹å‡»å¤±è´¥: {finish_btn_err}") # logger
                await save_error_snapshot(f"edit_response_finish_button_failed_{req_id}")

            check_client_disconnected("ç¼–è¾‘å“åº” - ç‚¹å‡»å®Œæˆç¼–è¾‘å: ")
            await asyncio.sleep(0.2) # Use asyncio.sleep
            check_client_disconnected("ç¼–è¾‘å“åº” - ç‚¹å‡»å®Œæˆç¼–è¾‘åå»¶æ—¶å: ")
        else:
             logger.info(f"[{req_id}]   - è·³è¿‡ç‚¹å‡»å®Œæˆç¼–è¾‘æŒ‰é’®ï¼Œå› ä¸ºæ–‡æœ¬åŒºåŸŸè¯»å–å¤±è´¥ã€‚") # logger

        return response_content if not textarea_failed else None

    except ClientDisconnectedError:
        logger.info(f"[{req_id}] (Helper Edit) å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ã€‚") # logger
        raise
    except Exception as e:
        logger.exception(f"[{req_id}] é€šè¿‡ç¼–è¾‘æŒ‰é’®è·å–å“åº”è¿‡ç¨‹ä¸­å‘ç”Ÿæ„å¤–é”™è¯¯") # logger
        await save_error_snapshot(f"edit_response_unexpected_error_{req_id}")
        return None

# --- V4: New Helper - Get response via Copy Button ---
async def get_response_via_copy_button(
    page: AsyncPage,
    req_id: str,
    check_client_disconnected: Callable
) -> Optional[str]:
    """Attempts to get the response content using the copy markdown button.
       Implementation mirrors original stream logic closely.
    """
    logger.info(f"[{req_id}] (Helper) å°è¯•é€šè¿‡å¤åˆ¶æŒ‰é’®è·å–å“åº”...") # logger
    more_options_button = page.locator(MORE_OPTIONS_BUTTON_SELECTOR).last # Target last message
    copy_button_primary = page.locator(COPY_MARKDOWN_BUTTON_SELECTOR)
    copy_button_alt = page.locator(COPY_MARKDOWN_BUTTON_SELECTOR_ALT)

    try:
        # 1. Hover over the last message to reveal options
        logger.info(f"[{req_id}]   - å°è¯•æ‚¬åœæœ€åä¸€æ¡æ¶ˆæ¯ä»¥æ˜¾ç¤ºé€‰é¡¹...") # logger
        last_message_container = page.locator('ms-chat-turn').last
        try:
            # Direct hover call with timeout
            await last_message_container.hover(timeout=CLICK_TIMEOUT_MS)
            check_client_disconnected("å¤åˆ¶å“åº” - æ‚¬åœå: ")
            await asyncio.sleep(0.5) # Use asyncio.sleep
            check_client_disconnected("å¤åˆ¶å“åº” - æ‚¬åœåå»¶æ—¶å: ")
            logger.info(f"[{req_id}]   - å·²æ‚¬åœã€‚") # logger
        except Exception as hover_err:
            logger.warning(f"[{req_id}]   - æ‚¬åœå¤±è´¥: {hover_err}ã€‚å°è¯•ç›´æ¥æŸ¥æ‰¾æŒ‰é’®...") # logger
            check_client_disconnected("å¤åˆ¶å“åº” - æ‚¬åœå¤±è´¥å: ")
            # Continue, maybe buttons are already visible

        # 2. Click "More options" button
        logger.info(f"[{req_id}]   - å®šä½å¹¶ç‚¹å‡» 'æ›´å¤šé€‰é¡¹' æŒ‰é’®...") # logger
        try:
            # Direct Playwright calls with timeout
            await expect_async(more_options_button).to_be_visible(timeout=CLICK_TIMEOUT_MS)
            check_client_disconnected("å¤åˆ¶å“åº” - æ›´å¤šé€‰é¡¹æŒ‰é’®å¯è§å: ")
            await more_options_button.click(timeout=CLICK_TIMEOUT_MS)
            logger.info(f"[{req_id}]   - 'æ›´å¤šé€‰é¡¹' å·²ç‚¹å‡»ã€‚") # logger
        except Exception as more_opts_err:
            logger.error(f"[{req_id}]   - 'æ›´å¤šé€‰é¡¹' æŒ‰é’®ä¸å¯è§æˆ–ç‚¹å‡»å¤±è´¥: {more_opts_err}") # logger
            await save_error_snapshot(f"copy_response_more_options_failed_{req_id}")
            return None

        check_client_disconnected("å¤åˆ¶å“åº” - ç‚¹å‡»æ›´å¤šé€‰é¡¹å: ")
        await asyncio.sleep(0.5) # Use asyncio.sleep
        check_client_disconnected("å¤åˆ¶å“åº” - ç‚¹å‡»æ›´å¤šé€‰é¡¹åå»¶æ—¶å: ")

        # 3. Find and click "Copy Markdown" button (try primary, then alt)
        logger.info(f"[{req_id}]   - å®šä½å¹¶ç‚¹å‡» 'å¤åˆ¶ Markdown' æŒ‰é’®...") # logger
        copy_success = False
        try:
            # Try primary selector
            await expect_async(copy_button_primary).to_be_visible(timeout=CLICK_TIMEOUT_MS)
            check_client_disconnected("å¤åˆ¶å“åº” - ä¸»å¤åˆ¶æŒ‰é’®å¯è§å: ")
            await copy_button_primary.click(timeout=CLICK_TIMEOUT_MS, force=True)
            copy_success = True
            logger.info(f"[{req_id}]   - å·²ç‚¹å‡» 'å¤åˆ¶ Markdown' (ä¸»é€‰æ‹©å™¨)ã€‚") # logger
        except Exception as primary_copy_err:
            logger.warning(f"[{req_id}]   - ä¸»å¤åˆ¶æŒ‰é’®é€‰æ‹©å™¨å¤±è´¥ ({primary_copy_err})ï¼Œå°è¯•å¤‡é€‰...") # logger
            check_client_disconnected("å¤åˆ¶å“åº” - ä¸»å¤åˆ¶æŒ‰é’®å¤±è´¥å: ")
            try:
                # Try alternative selector
                await expect_async(copy_button_alt).to_be_visible(timeout=CLICK_TIMEOUT_MS)
                check_client_disconnected("å¤åˆ¶å“åº” - å¤‡é€‰å¤åˆ¶æŒ‰é’®å¯è§å: ")
                await copy_button_alt.click(timeout=CLICK_TIMEOUT_MS, force=True)
                copy_success = True
                logger.info(f"[{req_id}]   - å·²ç‚¹å‡» 'å¤åˆ¶ Markdown' (å¤‡é€‰é€‰æ‹©å™¨)ã€‚") # logger
            except Exception as alt_copy_err:
                logger.error(f"[{req_id}]   - å¤‡é€‰ 'å¤åˆ¶ Markdown' æŒ‰é’®å¤±è´¥: {alt_copy_err}") # logger
                await save_error_snapshot(f"copy_response_copy_button_failed_{req_id}")
                return None

        if not copy_success:
             logger.error(f"[{req_id}]   - æœªèƒ½ç‚¹å‡»ä»»ä½• 'å¤åˆ¶ Markdown' æŒ‰é’®ã€‚") # logger
             return None

        check_client_disconnected("å¤åˆ¶å“åº” - ç‚¹å‡»å¤åˆ¶æŒ‰é’®å: ")
        await asyncio.sleep(0.5) # Use asyncio.sleep
        check_client_disconnected("å¤åˆ¶å“åº” - ç‚¹å‡»å¤åˆ¶æŒ‰é’®åå»¶æ—¶å: ")

        # 4. Read clipboard content
        logger.info(f"[{req_id}]   - æ­£åœ¨è¯»å–å‰ªè´´æ¿å†…å®¹...") # logger
        try:
            # Direct evaluate call (no specific timeout needed)
            clipboard_content = await page.evaluate('navigator.clipboard.readText()')
            check_client_disconnected("å¤åˆ¶å“åº” - è¯»å–å‰ªè´´æ¿å: ")

            if clipboard_content:
                content_preview = clipboard_content[:100].replace('\n', '\\\\n')
                logger.info(f"[{req_id}]   - âœ… æˆåŠŸè·å–å‰ªè´´æ¿å†…å®¹ (é•¿åº¦={len(clipboard_content)}): '{content_preview}...'") # logger
                return clipboard_content
            else:
                logger.error(f"[{req_id}]   - å‰ªè´´æ¿å†…å®¹ä¸ºç©ºã€‚") # logger
                return None
        except Exception as clipboard_err:
            if "clipboard-read" in str(clipboard_err):
                 logger.error(f"[{req_id}]   - è¯»å–å‰ªè´´æ¿å¤±è´¥: å¯èƒ½æ˜¯æƒé™é—®é¢˜ã€‚é”™è¯¯: {clipboard_err}") # logger
            else:
                 logger.error(f"[{req_id}]   - è¯»å–å‰ªè´´æ¿å¤±è´¥: {clipboard_err}") # logger
            await save_error_snapshot(f"copy_response_clipboard_read_failed_{req_id}")
            return None

    except ClientDisconnectedError:
        logger.info(f"[{req_id}] (Helper Copy) å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ã€‚") # logger
        raise
    except Exception as e:
        logger.exception(f"[{req_id}] å¤åˆ¶å“åº”è¿‡ç¨‹ä¸­å‘ç”Ÿæ„å¤–é”™è¯¯") # logger
        await save_error_snapshot(f"copy_response_unexpected_error_{req_id}")
        return None

# --- V5: New Helper - Wait for Response Completion --- (Based on Stream Logic)
async def _wait_for_response_completion(
    page: AsyncPage,
    req_id: str,
    response_element: Locator, # Pass the located response element
    interruptible_wait_for: Callable, # This argument is no longer used, can be removed later
    check_client_disconnected: Callable,
    interruptible_sleep: Callable # This argument is no longer used, can be removed later
) -> bool:
    """Waits for the AI Studio response to complete, primarily checking for the edit button.
       Implementation mirrors original stream logic closely.
    """
    logger.info(f"[{req_id}] (Helper Wait) å¼€å§‹ç­‰å¾…å“åº”å®Œæˆ... (è¶…æ—¶: {RESPONSE_COMPLETION_TIMEOUT}ms)") # logger
    start_time_ns = time.time()
    spinner_locator = page.locator(LOADING_SPINNER_SELECTOR)
    input_field = page.locator(INPUT_SELECTOR)
    submit_button = page.locator(SUBMIT_BUTTON_SELECTOR)
    edit_button = page.locator(EDIT_MESSAGE_BUTTON_SELECTOR)

    while time.time() - start_time_ns < RESPONSE_COMPLETION_TIMEOUT / 1000:
        check_client_disconnected("ç­‰å¾…å®Œæˆå¾ªç¯å¼€å§‹: ")

        # --- Check Base Final State Conditions (Mirroring original stream checks) ---
        spinner_hidden = False
        input_empty = False
        button_disabled = False
        state_check_error = None

        try:
            # Check Spinner hidden
            try:
                # Direct Playwright call with timeout
                await expect_async(spinner_locator).to_be_hidden(timeout=SPINNER_CHECK_TIMEOUT_MS)
                spinner_hidden = True
            except (PlaywrightAsyncError, asyncio.TimeoutError, AssertionError) as e:
                spinner_hidden = False
                state_check_error = e # Store last error for logging

            check_client_disconnected("ç­‰å¾…å®Œæˆ - Spinneræ£€æŸ¥å: ")

            # Only check others if spinner IS hidden
            if spinner_hidden:
                 # Use standard asyncio.sleep
                 await asyncio.sleep(POST_SPINNER_CHECK_DELAY_MS / 1000)
                 check_client_disconnected("ç­‰å¾…å®Œæˆ - Spinneræ¶ˆå¤±åå»¶æ—¶å: ")

                 # Check Input empty
                 try:
                     await expect_async(input_field).to_have_value('', timeout=FINAL_STATE_CHECK_TIMEOUT_MS)
                     input_empty = True
                 except (PlaywrightAsyncError, asyncio.TimeoutError, AssertionError) as e:
                      input_empty = False
                      state_check_error = e
                 check_client_disconnected("ç­‰å¾…å®Œæˆ - è¾“å…¥æ¡†æ£€æŸ¥å: ")

                 # Check Button disabled
                 try:
                     await expect_async(submit_button).to_be_disabled(timeout=FINAL_STATE_CHECK_TIMEOUT_MS)
                     button_disabled = True
                 except (PlaywrightAsyncError, asyncio.TimeoutError, AssertionError) as e:
                     button_disabled = False
                     state_check_error = e
                 check_client_disconnected("ç­‰å¾…å®Œæˆ - æäº¤æŒ‰é’®æ£€æŸ¥å: ")
            # else: spinner not hidden, skip other checks

        # --- Exception Handling for State Checks (Only for truly unexpected errors) ---
        except ClientDisconnectedError: raise
        except Exception as unexpected_state_err:
             logger.exception(f"[{req_id}] (Helper Wait) çŠ¶æ€æ£€æŸ¥ä¸­å‘ç”Ÿæ„å¤–é”™è¯¯") # logger
             await save_error_snapshot(f"wait_completion_state_check_unexpected_{req_id}")
             await asyncio.sleep(POLLING_INTERVAL_STREAM / 1000) # Still use sleep here
             continue

        # --- Logging and Continuation Logic ---
        is_final_state = spinner_hidden and input_empty and button_disabled
        if not is_final_state:
            if DEBUG_LOGS_ENABLED:
                reason = "Spinner not hidden" if not spinner_hidden else ("Input not empty" if not input_empty else "Submit button not disabled")
                error_info = f" (Last Check Error: {type(state_check_error).__name__})" if state_check_error else ""
                logger.debug(f"[{req_id}] (Helper Wait) åŸºç¡€çŠ¶æ€æœªæ»¡è¶³ ({reason}{error_info})ã€‚ç»§ç»­è½®è¯¢...") # logger debug
            # Use standard asyncio.sleep with stream interval
            await asyncio.sleep(POLLING_INTERVAL_STREAM / 1000)
            continue

        # --- If base conditions met, check for Edit Button --- (Mirroring original stream logic)
        logger.info(f"[{req_id}] (Helper Wait) æ£€æµ‹åˆ°åŸºç¡€æœ€ç»ˆçŠ¶æ€ã€‚å¼€å§‹æ£€æŸ¥ç¼–è¾‘æŒ‰é’®å¯è§æ€§ (æœ€é•¿ {SILENCE_TIMEOUT_MS}ms)...") # logger
        edit_button_check_start = time.time()
        edit_button_visible = False
        last_focus_attempt_time = 0

        while time.time() - edit_button_check_start < SILENCE_TIMEOUT_MS / 1000:
            check_client_disconnected("ç­‰å¾…å®Œæˆ - ç¼–è¾‘æŒ‰é’®æ£€æŸ¥å¾ªç¯: ")

            # Focus attempt logic remains similar (using interruptible for safety here is okay, or revert if strictness needed)
            current_time = time.time()
            if current_time - last_focus_attempt_time > 1.0:
                try:
                    if DEBUG_LOGS_ENABLED:
                        logger.debug(f"[{req_id}] (Helper Wait)   - å°è¯•èšç„¦å“åº”å…ƒç´ ...") # logger debug
                    # Revert focus click to direct call if strict matching is required
                    await response_element.click(timeout=1000, position={'x': 10, 'y': 10}, force=True)
                    last_focus_attempt_time = current_time
                    await asyncio.sleep(0.1) # Use asyncio.sleep
                except (PlaywrightAsyncError, asyncio.TimeoutError) as focus_err:
                     if DEBUG_LOGS_ENABLED:
                          logger.debug(f"[{req_id}] (Helper Wait)   - èšç„¦å“åº”å…ƒç´ å¤±è´¥ (å¿½ç•¥): {type(focus_err).__name__}") # logger debug
                except ClientDisconnectedError: raise
                except Exception as unexpected_focus_err:
                     logger.warning(f"[{req_id}] (Helper Wait)   - èšç„¦å“åº”å…ƒç´ æ—¶æ„å¤–é”™è¯¯ (å¿½ç•¥): {unexpected_focus_err}") # logger warning
                check_client_disconnected("ç­‰å¾…å®Œæˆ - ç¼–è¾‘æŒ‰é’®å¾ªç¯èšç„¦å: ")

            # Check Edit button visibility using is_visible() directly
            try:
                is_visible = False
                try:
                    # Direct call to is_visible with timeout
                    is_visible = await edit_button.is_visible(timeout=500)
                except asyncio.TimeoutError:
                    is_visible = False # Treat timeout as not visible
                except PlaywrightAsyncError as pw_vis_err:
                    logger.warning(f"[{req_id}] (Helper Wait)   - is_visible æ£€æŸ¥Playwrighté”™è¯¯(å¿½ç•¥): {pw_vis_err}") # logger warning
                    is_visible = False

                check_client_disconnected("ç­‰å¾…å®Œæˆ - ç¼–è¾‘æŒ‰é’® is_visible æ£€æŸ¥å: ")

                if is_visible:
                    logger.info(f"[{req_id}] (Helper Wait) âœ… ç¼–è¾‘æŒ‰é’®å·²å‡ºç° (is_visible)ï¼Œç¡®è®¤å“åº”å®Œæˆã€‚") # logger
                    edit_button_visible = True
                    return True
                else:
                      if DEBUG_LOGS_ENABLED and (time.time() - edit_button_check_start) > 1.0:
                           logger.debug(f"[{req_id}] (Helper Wait)   - ç¼–è¾‘æŒ‰é’®å°šä¸å¯è§... (is_visible returned False or timed out)") # logger debug

            except ClientDisconnectedError: raise
            except Exception as unexpected_btn_err:
                 logger.warning(f"[{req_id}] (Helper Wait)   - æ£€æŸ¥ç¼–è¾‘æŒ‰é’®æ—¶æ„å¤–é”™è¯¯: {unexpected_btn_err}") # logger warning

            # Wait before next check using asyncio.sleep
            await asyncio.sleep(POLLING_INTERVAL_STREAM / 1000)
        # --- End of Edit Button Check Loop ---

        # If edit button didn't appear within SILENCE_TIMEOUT_MS after base state met
        if not edit_button_visible:
            logger.warning(f"[{req_id}] (Helper Wait) åŸºç¡€çŠ¶æ€æ»¡è¶³åï¼Œç¼–è¾‘æŒ‰é’®æœªåœ¨ {SILENCE_TIMEOUT_MS}ms å†…å‡ºç°ã€‚åˆ¤å®šä¸ºè¶…æ—¶ã€‚") # logger
            await save_error_snapshot(f"wait_completion_edit_button_timeout_{req_id}")
            return False

    # --- End of Main While Loop (Overall Timeout) ---
    logger.error(f"[{req_id}] (Helper Wait) ç­‰å¾…å“åº”å®Œæˆè¶…æ—¶ ({RESPONSE_COMPLETION_TIMEOUT}ms)ã€‚") # logger
    await save_error_snapshot(f"wait_completion_overall_timeout_{req_id}")
    return False # Indicate timeout

# --- V5: New Helper - Get Final Response Content --- (Unified)
async def _get_final_response_content(
    page: AsyncPage,
    req_id: str,
    check_client_disconnected: Callable
) -> Optional[str]:
    """Gets the final response content, trying Edit Button then Copy Button.
       Implementation mirrors original stream logic closely.
    """
    logger.info(f"[{req_id}] (Helper GetContent) å¼€å§‹è·å–æœ€ç»ˆå“åº”å†…å®¹...") # logger

    # 1. Try getting content via Edit Button first (more reliable)
    response_content = await get_response_via_edit_button(
        page, req_id, check_client_disconnected
    )

    if response_content is not None:
        logger.info(f"[{req_id}] (Helper GetContent) âœ… æˆåŠŸé€šè¿‡ç¼–è¾‘æŒ‰é’®è·å–å†…å®¹ã€‚") # logger
        return response_content

    # 2. If Edit Button failed, fall back to Copy Button
    logger.warning(f"[{req_id}] (Helper GetContent) ç¼–è¾‘æŒ‰é’®æ–¹æ³•å¤±è´¥æˆ–è¿”å›ç©ºï¼Œå›é€€åˆ°å¤åˆ¶æŒ‰é’®æ–¹æ³•...") # logger
    response_content = await get_response_via_copy_button(
        page, req_id, check_client_disconnected
    )

    if response_content is not None:
        logger.info(f"[{req_id}] (Helper GetContent) âœ… æˆåŠŸé€šè¿‡å¤åˆ¶æŒ‰é’®è·å–å†…å®¹ã€‚") # logger
        return response_content

    # 3. If both methods failed
    logger.error(f"[{req_id}] (Helper GetContent) æ‰€æœ‰è·å–å“åº”å†…å®¹çš„æ–¹æ³•å‡å¤±è´¥ã€‚") # logger
    await save_error_snapshot(f"get_content_all_methods_failed_{req_id}")
    return None

# --- Queue Worker --- (Enhanced)
async def queue_worker():
    # print("--- é˜Ÿåˆ— Worker å·²å¯åŠ¨ ---")
    logger.info("--- é˜Ÿåˆ— Worker å·²å¯åŠ¨ ---") # logger
    was_last_request_streaming = False
    last_request_completion_time = 0

    while True:
        request_item = None; result_future = None; req_id = "UNKNOWN"; completion_event = None
        try:
            # Check for disconnected clients in queue (simplified)
            # ... (Consider adding back if needed, removed for brevity) ...

            # <<< ADDED: Logic to check queue for disconnected clients (from serveræœªé‡æ„.py) >>>
            queue_size = request_queue.qsize()
            if queue_size > 0:
                checked_count = 0
                # Create a temporary list to hold items while checking
                items_to_requeue = []
                processed_ids = set()
                while checked_count < queue_size and checked_count < 10: # Limit check depth
                    try:
                        item = request_queue.get_nowait()
                        item_req_id = item.get("req_id", "unknown")
                        if item_req_id in processed_ids: # Avoid reprocessing due to requeueing order issues
                             items_to_requeue.append(item)
                             continue
                        processed_ids.add(item_req_id)

                        if not item.get("cancelled", False):
                            item_http_request = item.get("http_request")
                            if item_http_request:
                                try:
                                    if await item_http_request.is_disconnected():
                                        print(f"[{item_req_id}] (Worker Queue Check) æ£€æµ‹åˆ°å®¢æˆ·ç«¯å·²æ–­å¼€ï¼Œæ ‡è®°ä¸ºå–æ¶ˆã€‚", flush=True)
                                        item["cancelled"] = True
                                        item_future = item.get("result_future")
                                        if item_future and not item_future.done():
                                            item_future.set_exception(HTTPException(status_code=499, detail=f"[{item_req_id}] Client disconnected while queued."))
                                except Exception as check_err:
                                    print(f"[{item_req_id}] (Worker Queue Check) Error checking disconnect: {check_err}", flush=True)
                        items_to_requeue.append(item)
                        checked_count += 1
                    except asyncio.QueueEmpty:
                        break # Stop if queue becomes empty during check
                # Put items back into the queue
                for item in items_to_requeue:
                    await request_queue.put(item)
            # <<< END ADDED QUEUE CHECK LOGIC >>>

            request_item = await request_queue.get()
            req_id = request_item["req_id"]
            request_data = request_item["request_data"]
            http_request = request_item["http_request"]
            result_future = request_item["result_future"]

            if request_item.get("cancelled", False):
                print(f"[{req_id}] (Worker) è¯·æ±‚å·²å–æ¶ˆï¼Œè·³è¿‡ã€‚", flush=True)
                if not result_future.done(): result_future.set_exception(HTTPException(status_code=499, detail=f"[{req_id}] è¯·æ±‚å·²è¢«ç”¨æˆ·å–æ¶ˆ"))
                request_queue.task_done(); continue

            is_streaming_request = request_data.stream
            print(f"[{req_id}] (Worker) å–å‡ºè¯·æ±‚ã€‚æ¨¡å¼: {'æµå¼' if is_streaming_request else 'éæµå¼'}", flush=True)

            # Delay between consecutive streaming requests
            current_time = time.time()
            if was_last_request_streaming and is_streaming_request and (current_time - last_request_completion_time < 1.0):
                delay_time = max(0.5, 1.0 - (current_time - last_request_completion_time))
                print(f"[{req_id}] (Worker) è¿ç»­æµå¼è¯·æ±‚ï¼Œæ·»åŠ  {delay_time:.2f}s å»¶è¿Ÿ...", flush=True)
                await asyncio.sleep(delay_time)

            if await http_request.is_disconnected():
                 print(f"[{req_id}] (Worker) å®¢æˆ·ç«¯åœ¨ç­‰å¾…é”æ—¶æ–­å¼€ã€‚å–æ¶ˆã€‚", flush=True)
                 if not result_future.done(): result_future.set_exception(HTTPException(status_code=499, detail=f"[{req_id}] å®¢æˆ·ç«¯å…³é—­äº†è¯·æ±‚"))
                 request_queue.task_done(); continue

            print(f"[{req_id}] (Worker) ç­‰å¾…å¤„ç†é”...", flush=True)
            async with processing_lock:
                print(f"[{req_id}] (Worker) å·²è·å–å¤„ç†é”ã€‚å¼€å§‹æ ¸å¿ƒå¤„ç†...", flush=True)

                if await http_request.is_disconnected():
                     print(f"[{req_id}] (Worker) å®¢æˆ·ç«¯åœ¨è·å–é”åæ–­å¼€ã€‚å–æ¶ˆã€‚", flush=True)
                     if not result_future.done(): result_future.set_exception(HTTPException(status_code=499, detail=f"[{req_id}] å®¢æˆ·ç«¯å…³é—­äº†è¯·æ±‚"))
                elif result_future.done():
                     print(f"[{req_id}] (Worker) Future åœ¨å¤„ç†å‰å·²å®Œæˆ/å–æ¶ˆã€‚è·³è¿‡ã€‚", flush=True)
                else:
                    # <<< V5: Call refactored processing function >>>
                    completion_event = await _process_request_refactored(
                        req_id, request_data, http_request, result_future
                    )

                    # Wait for stream completion event if returned
                    if completion_event:
                         print(f"[{req_id}] (Worker) ç­‰å¾…æµå¼ç”Ÿæˆå™¨å®Œæˆä¿¡å·...", flush=True)
                         try:
                              await asyncio.wait_for(completion_event.wait(), timeout=RESPONSE_COMPLETION_TIMEOUT/1000 + 60) # Add buffer
                              print(f"[{req_id}] (Worker) âœ… æµå¼ç”Ÿæˆå™¨å®Œæˆä¿¡å·æ”¶åˆ°ã€‚", flush=True)
                         except asyncio.TimeoutError:
                              print(f"[{req_id}] (Worker) âš ï¸ ç­‰å¾…æµå¼ç”Ÿæˆå™¨å®Œæˆä¿¡å·è¶…æ—¶ã€‚", flush=True)
                              if not result_future.done(): result_future.set_exception(HTTPException(status_code=504, detail=f"[{req_id}] Stream generation timed out waiting for completion signal."))
                         except Exception as ev_wait_err:
                              print(f"[{req_id}] (Worker) âŒ ç­‰å¾…æµå¼å®Œæˆäº‹ä»¶æ—¶å‡ºé”™: {ev_wait_err}", flush=True)
                              if not result_future.done(): result_future.set_exception(HTTPException(status_code=500, detail=f"[{req_id}] Error waiting for stream completion: {ev_wait_err}"))

            # End of processing lock
            print(f"[{req_id}] (Worker) é‡Šæ”¾å¤„ç†é”ã€‚", flush=True)
            was_last_request_streaming = is_streaming_request
            last_request_completion_time = time.time()

        except asyncio.CancelledError:
            print("--- é˜Ÿåˆ— Worker è¢«å–æ¶ˆ ---", flush=True)
            if result_future and not result_future.done(): result_future.cancel("Worker cancelled")
            break # Exit the loop
        except Exception as e:
            print(f"[{req_id}] (Worker) âŒ å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}", flush=True)
            traceback.print_exc()
            if result_future and not result_future.done():
                result_future.set_exception(HTTPException(status_code=500, detail=f"[{req_id}] æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {e}"))
            await save_error_snapshot(f"worker_loop_error_{req_id}")
        finally:
             if request_item: request_queue.task_done()

    print("--- é˜Ÿåˆ— Worker å·²åœæ­¢ ---", flush=True)


# --- V5: Refactored Core Request Processing Logic --- (Called by Worker)
async def _process_request_refactored(
    req_id: str,
    request: ChatCompletionRequest,
    http_request: Request,
    result_future: Future
) -> Optional[Event]: # Return completion event only for streaming
    """Refactored core logic for processing a single request."""
    logger.info(f"[{req_id}] (Refactored Process) å¼€å§‹å¤„ç†è¯·æ±‚...") # logger
    logger.info(f"[{req_id}]   è¯·æ±‚å‚æ•° - Model: {request.model}, Stream: {request.stream}")
    logger.info(f"[{req_id}]   è¯·æ±‚å‚æ•° - Temperature: {request.temperature}")
    logger.info(f"[{req_id}]   è¯·æ±‚å‚æ•° - Max Output Tokens: {request.max_output_tokens}")
    logger.info(f"[{req_id}]   è¯·æ±‚å‚æ•° - Stop Sequences: {request.stop}")
    logger.info(f"[{req_id}]   è¯·æ±‚å‚æ•° - Top P: {request.top_p}")
    is_streaming = request.stream
    page: Optional[AsyncPage] = page_instance # Use global instance
    completion_event: Optional[Event] = None # For streaming
    
    # --- æ–°å¢: æ¨¡å‹éªŒè¯å’Œåˆ‡æ¢é€»è¾‘ ---
    requested_model = request.model
    model_id_to_use = None
    needs_model_switching = False
    
    if requested_model and requested_model != MODEL_NAME: # å¦‚æœæŒ‡å®šäº†å…·ä½“æ¨¡å‹ä¸”ä¸æ˜¯ä»£ç†æ¨¡å‹å
        # ä»è¯·æ±‚æ¨¡å‹ä¸­æå–çœŸæ­£çš„æ¨¡å‹ID (ä¾‹å¦‚ä» "gemini-1.5-pro-latest" æå–)
        requested_model_parts = requested_model.split('/')
        requested_model_id = requested_model_parts[-1] if len(requested_model_parts) > 1 else requested_model
        
        # å¼ºåˆ¶éªŒè¯æ¨¡å‹
        logger.info(f"[{req_id}] è¯·æ±‚ä½¿ç”¨æ¨¡å‹: {requested_model_id}")
        
        if parsed_model_list: # å¦‚æœæˆ‘ä»¬æœ‰å·²çŸ¥æ¨¡å‹åˆ—è¡¨
            valid_model_ids = [m.get("id") for m in parsed_model_list]
            if requested_model_id not in valid_model_ids:
                logger.error(f"[{req_id}] âŒ æ— æ•ˆçš„æ¨¡å‹ID: {requested_model_id}ã€‚å¯ç”¨æ¨¡å‹: {valid_model_ids}")
                raise HTTPException(status_code=400, detail=f"[{req_id}] Invalid model '{requested_model_id}'. Available models: {', '.join(valid_model_ids)}")
            
        model_id_to_use = requested_model_id
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ‡æ¢æ¨¡å‹
        global current_ai_studio_model_id
        if current_ai_studio_model_id != model_id_to_use:
            needs_model_switching = True
            logger.info(f"[{req_id}] éœ€è¦åˆ‡æ¢æ¨¡å‹: å½“å‰={current_ai_studio_model_id} -> ç›®æ ‡={model_id_to_use}")
        else:
            logger.info(f"[{req_id}] è¯·æ±‚æ¨¡å‹ä¸å½“å‰æ¨¡å‹ç›¸åŒ ({model_id_to_use})ï¼Œæ— éœ€åˆ‡æ¢")
    else:
        logger.info(f"[{req_id}] æœªæŒ‡å®šå…·ä½“æ¨¡å‹æˆ–ä½¿ç”¨ä»£ç†æ¨¡å‹åç§°ï¼Œå°†ä½¿ç”¨å½“å‰æ¨¡å‹: {current_ai_studio_model_id or 'æœªçŸ¥'}")

    # --- Setup Disconnect Handling --- (Same as before)
    client_disconnected_event = Event()
    disconnect_check_task = None
    input_field_locator = page.locator(INPUT_SELECTOR)
    submit_button_locator = page.locator(SUBMIT_BUTTON_SELECTOR)

    async def check_disconnect_periodically():
        while not client_disconnected_event.is_set():
            try:
                if await http_request.is_disconnected():
                    logger.info(f"[{req_id}] (Disco Check Task) å®¢æˆ·ç«¯æ–­å¼€ã€‚è®¾ç½®äº‹ä»¶å¹¶å°è¯•åœæ­¢ã€‚") # logger
                    client_disconnected_event.set()
                    try: # Attempt to click stop button
                        if await submit_button_locator.is_enabled(timeout=1500):
                             if await input_field_locator.input_value(timeout=1500) == '':
                                 logger.info(f"[{req_id}] (Disco Check Task)   ç‚¹å‡»åœæ­¢...") # logger
                                 await submit_button_locator.click(timeout=3000, force=True)
                    except Exception as click_err: logger.warning(f"[{req_id}] (Disco Check Task) åœæ­¢æŒ‰é’®ç‚¹å‡»å¤±è´¥: {click_err}") # logger warning
                    if not result_future.done(): result_future.set_exception(HTTPException(status_code=499, detail=f"[{req_id}] å®¢æˆ·ç«¯åœ¨å¤„ç†æœŸé—´å…³é—­äº†è¯·æ±‚"))
                    break
                await asyncio.sleep(1.0)
            except asyncio.CancelledError: break
            except Exception as e:
                logger.error(f"[{req_id}] (Disco Check Task) é”™è¯¯: {e}") # logger
                client_disconnected_event.set()
                if not result_future.done(): result_future.set_exception(HTTPException(status_code=500, detail=f"[{req_id}] Internal disconnect checker error: {e}"))
                break

    disconnect_check_task = asyncio.create_task(check_disconnect_periodically())

    def check_client_disconnected(msg_prefix=""): # Changed to logger.info
        if client_disconnected_event.is_set():
            logger.info(f"[{req_id}] {msg_prefix}æ£€æµ‹åˆ°å®¢æˆ·ç«¯æ–­å¼€è¿æ¥äº‹ä»¶ã€‚")
            raise ClientDisconnectedError(f"[{req_id}] Client disconnected event set.")
        return False

    try:
        # --- Initial Checks --- (Page Ready)
        if not page or page.is_closed() or not is_page_ready:
            raise HTTPException(status_code=503, detail=f"[{req_id}] AI Studio é¡µé¢ä¸¢å¤±æˆ–æœªå°±ç»ªã€‚", headers={"Retry-After": "30"})
        check_client_disconnected("Initial Page Check: ")
        
        # --- æ–°å¢: æ‰§è¡Œæ¨¡å‹åˆ‡æ¢ ---
        if needs_model_switching and model_id_to_use:
            async with model_switching_lock:  # ä½¿ç”¨é”ç¡®ä¿ä¸€æ¬¡åªæœ‰ä¸€ä¸ªè¯·æ±‚åœ¨åˆ‡æ¢æ¨¡å‹
                model_before_switch_attempt = current_ai_studio_model_id # ç”¨äºæ—¥å¿—å’Œå›é€€
                # å†æ¬¡æ£€æŸ¥å½“å‰æ¨¡å‹ï¼Œå› ä¸ºåœ¨è·å–é”çš„è¿‡ç¨‹ä¸­å¯èƒ½å·²ç»è¢«å…¶ä»–è¯·æ±‚æ›´æ–°
                if current_ai_studio_model_id != model_id_to_use:
                    logger.info(f"[{req_id}] è·å–é”åå‡†å¤‡åˆ‡æ¢: å½“å‰å†…å­˜ä¸­æ¨¡å‹={current_ai_studio_model_id}, ç›®æ ‡={model_id_to_use}")
                    
                    switch_success = await switch_ai_studio_model(page, model_id_to_use, req_id)
                    
                    if switch_success:
                        current_ai_studio_model_id = model_id_to_use # æ›´æ–°å…¨å±€ä¸ºç›®æ ‡æ¨¡å‹ ID
                        logger.info(f"[{req_id}] âœ… æ¨¡å‹åˆ‡æ¢æˆåŠŸã€‚å…¨å±€æ¨¡å‹çŠ¶æ€å·²æ›´æ–°ä¸º: {current_ai_studio_model_id}")
                    else:
                        logger.warning(f"[{req_id}] âŒ æ¨¡å‹åˆ‡æ¢è‡³ {model_id_to_use} å¤±è´¥ (AI Studio æœªæ¥å—æˆ–è¦†ç›–äº†æ›´æ”¹)ã€‚")
                        
                        # ç¡®å®šåˆ‡æ¢å¤±è´¥å localStorage ä¸­çš„å®é™…æ¨¡å‹
                        active_model_id_after_fail = model_before_switch_attempt # é»˜è®¤å›é€€åˆ°å°è¯•åˆ‡æ¢å‰çš„æ¨¡å‹
                        try:
                            final_prefs_str_after_fail = await page.evaluate("() => localStorage.getItem('aiStudioUserPreference')")
                            if final_prefs_str_after_fail:
                                final_prefs_obj_after_fail = json.loads(final_prefs_str_after_fail)
                                model_path_in_final_prefs = final_prefs_obj_after_fail.get("promptModel")
                                if model_path_in_final_prefs and isinstance(model_path_in_final_prefs, str):
                                    active_model_id_after_fail = model_path_in_final_prefs.split('/')[-1]
                        except Exception as read_final_prefs_err:
                            logger.error(f"[{req_id}] åˆ‡æ¢å¤±è´¥åè¯»å–æœ€ç»ˆ localStorage å‡ºé”™: {read_final_prefs_err}")
                        
                        current_ai_studio_model_id = active_model_id_after_fail # æ›´æ–°å…¨å±€çŠ¶æ€ä¸ºå®é™…ç”Ÿæ•ˆçš„æ¨¡å‹
                        logger.info(f"[{req_id}] å…¨å±€æ¨¡å‹çŠ¶æ€åœ¨åˆ‡æ¢å¤±è´¥åè®¾ç½®ä¸º (æˆ–ä¿æŒä¸º): {current_ai_studio_model_id}")

                        # è·å–é¡µé¢å®é™…æ˜¾ç¤ºçš„åç§°ç”¨äºé”™è¯¯æç¤º
                        actual_displayed_model_name = "æœªçŸ¥ (æ— æ³•è¯»å–)"
                        try:
                            model_wrapper_locator = page.locator('#mat-select-value-0 mat-select-trigger').first
                            actual_displayed_model_name = await model_wrapper_locator.inner_text(timeout=3000)
                        except Exception:
                            pass # å…è®¸è¯»å–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
                                        
                        raise HTTPException(
                            status_code=422, # Unprocessable Entity
                            detail=f"[{req_id}] AI Studio æœªèƒ½åº”ç”¨æ‰€è¯·æ±‚çš„æ¨¡å‹ '{model_id_to_use}' æˆ–è¯¥æ¨¡å‹ä¸å—æ”¯æŒã€‚è¯·é€‰æ‹© AI Studio ç½‘é¡µç•Œé¢ä¸­å¯ç”¨çš„æ¨¡å‹ã€‚å½“å‰å®é™…ç”Ÿæ•ˆçš„æ¨¡å‹ ID ä¸º '{current_ai_studio_model_id}', é¡µé¢æ˜¾ç¤ºä¸º '{actual_displayed_model_name}'."
                        )
                else:
                    logger.info(f"[{req_id}] è·å–é”åå‘ç°æ¨¡å‹å·²æ˜¯ç›®æ ‡æ¨¡å‹ {current_ai_studio_model_id}ï¼Œæ— éœ€åˆ‡æ¢")

        # --- 1. Validation & Prompt Prep --- (Use logger for validation message)
        try: validate_chat_request(request.messages, req_id)
        except ValueError as e: raise HTTPException(status_code=400, detail=f"[{req_id}] æ— æ•ˆè¯·æ±‚: {e}")
        # Validation log is already inside validate_chat_request using print, change it there too?
        # For now, assume prepare_combined_prompt handles its own logging via print->logger
        prepared_prompt = prepare_combined_prompt(request.messages, req_id)
        check_client_disconnected("After Prompt Prep: ")

        # --- 2. Clear Chat --- (Revert to direct calls, use logger for messages)
        logger.info(f"[{req_id}] (Refactored Process) å¼€å§‹æ¸…ç©ºèŠå¤©è®°å½•...") # logger
        try:
            clear_chat_button = page.locator(CLEAR_CHAT_BUTTON_SELECTOR)
            confirm_button = page.locator(CLEAR_CHAT_CONFIRM_BUTTON_SELECTOR)
            overlay_locator = page.locator('div.cdk-overlay-backdrop') # Locator for the overlay
            proceed_with_clear_clicks = False
            try:
                # Direct call with timeout
                await expect_async(clear_chat_button).to_be_enabled(timeout=3000) # Increased timeout slightly
                proceed_with_clear_clicks = True
            except Exception as e:
                is_new_chat_url = '/prompts/new_chat' in page.url.rstrip('/')
                if is_new_chat_url:
                    logger.info(f"[{req_id}] æ¸…ç©ºæŒ‰é’®ä¸å¯ç”¨ (é¢„æœŸ)ã€‚") # logger
                else:
                    logger.warning(f"[{req_id}] ç­‰å¾…æ¸…ç©ºæŒ‰é’®å¤±è´¥: {e}ã€‚è·³è¿‡ç‚¹å‡»ã€‚") # logger

            check_client_disconnected("After Clear Button Check: ")

            if proceed_with_clear_clicks:
                # ** ADDED: Wait for potential overlay to disappear BEFORE clicking clear **
                try:
                    # logger.debug(f"[{req_id}] Waiting for overlay to disappear before clicking clear...")
                    await expect_async(overlay_locator).to_be_hidden(timeout=3000) # Wait up to 3s
                except Exception as overlay_err:
                    logger.warning(f"[{req_id}] Overlay did not disappear before clear click (ignored): {overlay_err}")
                check_client_disconnected("After Overlay Check (Before Clear): ")

                # Direct calls with timeout
                await clear_chat_button.click(timeout=5000)
                check_client_disconnected("After Clear Button Click: ")

                # ** ADDED: Wait for confirm button AND wait for overlay to disappear BEFORE clicking confirm **
                try:
                    # logger.debug(f"[{req_id}] Waiting for confirm button and overlay disappearance...")
                    await expect_async(confirm_button).to_be_visible(timeout=5000)
                    # logger.debug(f"[{req_id}] Confirm button visible and overlay hidden. Proceeding to click confirm.")
                except Exception as confirm_wait_err:
                    # Modify error message to be more accurate
                    logger.error(f"[{req_id}] Error waiting for confirm button visibility: {confirm_wait_err}")
                    await save_error_snapshot(f"clear_chat_confirm_wait_error_{req_id}")
                    raise PlaywrightAsyncError(f"Confirm button wait failed: {confirm_wait_err}") from confirm_wait_err

                check_client_disconnected("After Confirm Button/Overlay Wait: ")
                await confirm_button.click(timeout=5000)
                check_client_disconnected("After Confirm Button Click: ")
                logger.info(f"[{req_id}] æ¸…ç©ºç¡®è®¤æŒ‰é’®å·²ç‚¹å‡»ã€‚") # logger

                last_response_container = page.locator(RESPONSE_CONTAINER_SELECTOR).last
                await asyncio.sleep(0.5) # Use asyncio.sleep
                check_client_disconnected("After Clear Post-Delay: ")
                try:
                    # Direct call with timeout
                    await expect_async(last_response_container).to_be_hidden(timeout=CLEAR_CHAT_VERIFY_TIMEOUT_MS - 500)
                    logger.info(f"[{req_id}] âœ… èŠå¤©å·²æˆåŠŸæ¸…ç©º (éªŒè¯é€šè¿‡)ã€‚") # logger
                except Exception as verify_err:
                    logger.warning(f"[{req_id}] âš ï¸ è­¦å‘Š: æ¸…ç©ºèŠå¤©éªŒè¯å¤±è´¥: {verify_err}") # logger
        except (PlaywrightAsyncError, asyncio.TimeoutError, ClientDisconnectedError) as clear_err:
            if isinstance(clear_err, ClientDisconnectedError): raise
            logger.error(f"[{req_id}] âŒ é”™è¯¯: æ¸…ç©ºèŠå¤©é˜¶æ®µå‡ºé”™: {clear_err}") # logger
            await save_error_snapshot(f"clear_chat_error_{req_id}")
        except Exception as clear_exc:
            logger.exception(f"[{req_id}] âŒ é”™è¯¯: æ¸…ç©ºèŠå¤©é˜¶æ®µæ„å¤–é”™è¯¯") # logger
            await save_error_snapshot(f"clear_chat_unexpected_{req_id}")
        check_client_disconnected("After Clear Chat Logic: ")

        # --- æ–°å¢: è°ƒæ•´æ¸©åº¦è®¾ç½® ---
        if request.temperature is not None and page and not page.is_closed():
            logger.info(f"[{req_id}] (Refactored Process) æ£€æŸ¥å¹¶è°ƒæ•´æ¸©åº¦è®¾ç½®...")
            requested_temp = request.temperature
            
            # å°†æ¸©åº¦é™åˆ¶åœ¨ [0.0, 2.0] èŒƒå›´å†…
            clamped_temp = max(0.0, min(2.0, requested_temp))
            if clamped_temp != requested_temp:
                logger.warning(f"[{req_id}] è¯·æ±‚çš„æ¸©åº¦ {requested_temp} è¶…å‡ºèŒƒå›´ [0, 2]ï¼Œå·²è°ƒæ•´ä¸º {clamped_temp}")
            
            temp_input_locator = page.locator(TEMPERATURE_INPUT_SELECTOR)
            try:
                await expect_async(temp_input_locator).to_be_visible(timeout=5000)
                check_client_disconnected("æ¸©åº¦è°ƒæ•´ - è¾“å…¥æ¡†å¯è§å: ")
                
                current_temp_str = await temp_input_locator.input_value(timeout=3000)
                check_client_disconnected("æ¸©åº¦è°ƒæ•´ - è¯»å–è¾“å…¥æ¡†å€¼å: ")
                
                current_temp_float = float(current_temp_str)
                logger.info(f"[{req_id}] é¡µé¢å½“å‰æ¸©åº¦: {current_temp_float}, è¯·æ±‚è°ƒæ•´åæ¸©åº¦: {clamped_temp}")

                # ä½¿ç”¨å®¹å·®æ¯”è¾ƒæµ®ç‚¹æ•°
                if abs(current_temp_float - clamped_temp) > 0.001: 
                    logger.info(f"[{req_id}] é¡µé¢æ¸©åº¦ ({current_temp_float}) ä¸è¯·æ±‚æ¸©åº¦ ({clamped_temp}) ä¸åŒï¼Œæ­£åœ¨æ›´æ–°...")
                    await temp_input_locator.fill(str(clamped_temp), timeout=5000)
                    check_client_disconnected("æ¸©åº¦è°ƒæ•´ - å¡«å……è¾“å…¥æ¡†å: ")
                    
                    # éªŒè¯æ›´æ”¹ (å¯é€‰ä½†æ¨è)
                    await asyncio.sleep(0.1) # çŸ­æš‚ç­‰å¾…å€¼æ›´æ–°
                    new_temp_str = await temp_input_locator.input_value(timeout=3000)
                    new_temp_float = float(new_temp_str)
                    if abs(new_temp_float - clamped_temp) < 0.001:
                        logger.info(f"[{req_id}] âœ… æ¸©åº¦å·²æˆåŠŸæ›´æ–°ä¸º: {new_temp_float}")
                    else:
                        logger.warning(f"[{req_id}] âš ï¸ æ¸©åº¦æ›´æ–°åéªŒè¯å¤±è´¥ã€‚é¡µé¢æ˜¾ç¤º: {new_temp_float}, æœŸæœ›: {clamped_temp}")
                else:
                    logger.info(f"[{req_id}] é¡µé¢æ¸©åº¦ ({current_temp_float}) ä¸è¯·æ±‚æ¸©åº¦ ({clamped_temp}) ä¸€è‡´æˆ–åœ¨å®¹å·®èŒƒå›´å†…ï¼Œæ— éœ€æ›´æ”¹ã€‚")

            except ValueError as ve:
                logger.error(f"[{req_id}] è½¬æ¢æ¸©åº¦å€¼ä¸ºæµ®ç‚¹æ•°æ—¶å‡ºé”™: '{current_temp_str if 'current_temp_str' in locals() else 'æœªçŸ¥å€¼'}'. é”™è¯¯: {ve}")
                await save_error_snapshot(f"temperature_value_error_{req_id}")
            except PlaywrightAsyncError as pw_err:
                logger.error(f"[{req_id}] âŒ æ“ä½œæ¸©åº¦è¾“å…¥æ¡†æ—¶å‘ç”ŸPlaywrighté”™è¯¯: {pw_err}")
                await save_error_snapshot(f"temperature_playwright_error_{req_id}")
                # æ­¤å¤„å¯ä»¥é€‰æ‹©æ˜¯å¦å°†æ­¤è§†ä¸ºè¯·æ±‚çš„è‡´å‘½é”™è¯¯å¹¶æŠ›å‡ºHTTPException
            except ClientDisconnectedError:
                logger.info(f"[{req_id}] å®¢æˆ·ç«¯åœ¨è°ƒæ•´æ¸©åº¦æ—¶æ–­å¼€è¿æ¥ã€‚")
                raise # é‡æ–°æŠ›å‡ºä»¥ç¡®ä¿è¢«å¤–éƒ¨æ•è·
            except Exception as e_temp:
                logger.exception(f"[{req_id}] âŒ è°ƒæ•´æ¸©åº¦æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯")
                await save_error_snapshot(f"temperature_unknown_error_{req_id}")
            
            check_client_disconnected("æ¸©åº¦è°ƒæ•´ - é€»è¾‘å®Œæˆå: ")
        # --- ç»“æŸè°ƒæ•´æ¸©åº¦è®¾ç½® ---

        # --- æ–°å¢: è°ƒæ•´æœ€å¤§è¾“å‡ºTokenè®¾ç½® ---
        if request.max_output_tokens is not None and page and not page.is_closed():
            logger.info(f"[{req_id}] (Refactored Process) æ£€æŸ¥å¹¶è°ƒæ•´æœ€å¤§è¾“å‡º Token è®¾ç½®...")
            requested_max_tokens = request.max_output_tokens
            
            min_val_for_tokens = 1
            # é»˜è®¤ä¸Šé™ï¼Œå¦‚æœæ¨¡å‹æ•°æ®ä¸­æ²¡æœ‰æä¾›
            max_val_for_tokens_from_model = 65536 # ä¸€ä¸ªè¾ƒé«˜çš„é€šç”¨å€¼

            # model_id_to_use åº”è¯¥åœ¨æ¨¡å‹åˆ‡æ¢é€»è¾‘åè¢«æ­£ç¡®è®¾ç½®
            if model_id_to_use and parsed_model_list:
                current_model_data = next((m for m in parsed_model_list if m.get("id") == model_id_to_use), None)
                if current_model_data and current_model_data.get("supported_max_output_tokens") is not None:
                    # ç¡®ä¿å–å‡ºçš„å€¼æ˜¯æœ‰æ•ˆçš„æ•°å­—
                    try:
                        supported_tokens = int(current_model_data["supported_max_output_tokens"])
                        if supported_tokens > 0:
                            max_val_for_tokens_from_model = supported_tokens
                            logger.info(f"[{req_id}] æ¨¡å‹ {model_id_to_use} æ”¯æŒçš„æœ€å¤§è¾“å‡ºTokens: {max_val_for_tokens_from_model}")
                        else:
                            logger.warning(f"[{req_id}] æ¨¡å‹ {model_id_to_use} çš„ supported_max_output_tokens å€¼ ({current_model_data['supported_max_output_tokens']}) æ— æ•ˆï¼Œå°†ä½¿ç”¨é»˜è®¤ä¸Šé™ {max_val_for_tokens_from_model}ã€‚")
                    except (ValueError, TypeError):
                        logger.warning(f"[{req_id}] æ¨¡å‹ {model_id_to_use} çš„ supported_max_output_tokens å€¼ ({current_model_data['supported_max_output_tokens']}) ä¸æ˜¯æœ‰æ•ˆæ•´æ•°ï¼Œå°†ä½¿ç”¨é»˜è®¤ä¸Šé™ {max_val_for_tokens_from_model}ã€‚")
                else:
                    logger.warning(f"[{req_id}] æœªåœ¨parsed_model_listä¸­æ‰¾åˆ°æ¨¡å‹ {model_id_to_use} çš„supported_max_output_tokensæ•°æ®ï¼Œæˆ–å€¼ä¸ºNoneï¼Œå°†ä½¿ç”¨é»˜è®¤ä¸Šé™ {max_val_for_tokens_from_model}ã€‚")
            else:
                logger.warning(f"[{req_id}] model_id_to_use ('{model_id_to_use}') æœªè®¾ç½®æˆ– parsed_model_list ä¸ºç©ºï¼Œæ— æ³•è·å–æ¨¡å‹ç‰¹å®šä¸Šé™ï¼Œå°†ä½¿ç”¨é»˜è®¤ä¸Šé™ {max_val_for_tokens_from_model}ã€‚")

            # ä½¿ç”¨ä»æ¨¡å‹æ•°æ®è·å–çš„ä¸Šé™ï¼ˆæˆ–åå¤‡å€¼ï¼‰è¿›è¡Œé’³åˆ¶
            clamped_max_tokens = max(min_val_for_tokens, min(max_val_for_tokens_from_model, requested_max_tokens))
            
            if clamped_max_tokens != requested_max_tokens:
                logger.warning(f"[{req_id}] è¯·æ±‚çš„æœ€å¤§è¾“å‡º Tokens {requested_max_tokens} è¶…å‡ºæ¨¡å‹èŒƒå›´ [{min_val_for_tokens}, {max_val_for_tokens_from_model}]ï¼Œå·²è°ƒæ•´ä¸º {clamped_max_tokens}")
            
            max_tokens_input_locator = page.locator(MAX_OUTPUT_TOKENS_SELECTOR)
            try:
                await expect_async(max_tokens_input_locator).to_be_visible(timeout=5000)
                check_client_disconnected("æœ€å¤§è¾“å‡ºTokenè°ƒæ•´ - è¾“å…¥æ¡†å¯è§å: ")
                
                current_max_tokens_str = await max_tokens_input_locator.input_value(timeout=3000)
                check_client_disconnected("æœ€å¤§è¾“å‡ºTokenè°ƒæ•´ - è¯»å–è¾“å…¥æ¡†å€¼å: ")
                
                current_max_tokens_int = int(current_max_tokens_str) # è½¬æ¢ä¸ºæ•´æ•°
                logger.info(f"[{req_id}] é¡µé¢å½“å‰æœ€å¤§è¾“å‡º Tokens: {current_max_tokens_int}, è¯·æ±‚è°ƒæ•´åæœ€å¤§è¾“å‡º Tokens: {clamped_max_tokens}")

                if current_max_tokens_int != clamped_max_tokens: 
                    logger.info(f"[{req_id}] é¡µé¢æœ€å¤§è¾“å‡º Tokens ({current_max_tokens_int}) ä¸è¯·æ±‚æœ€å¤§è¾“å‡º Tokens ({clamped_max_tokens}) ä¸åŒï¼Œæ­£åœ¨æ›´æ–°...")
                    await max_tokens_input_locator.fill(str(clamped_max_tokens), timeout=5000)
                    check_client_disconnected("æœ€å¤§è¾“å‡ºTokenè°ƒæ•´ - å¡«å……è¾“å…¥æ¡†å: ")
                    
                    # éªŒè¯æ›´æ”¹ (å¯é€‰ä½†æ¨è)
                    await asyncio.sleep(0.1) # çŸ­æš‚ç­‰å¾…å€¼æ›´æ–°
                    new_max_tokens_str = await max_tokens_input_locator.input_value(timeout=3000)
                    new_max_tokens_int = int(new_max_tokens_str)
                    if new_max_tokens_int == clamped_max_tokens:
                        logger.info(f"[{req_id}] âœ… æœ€å¤§è¾“å‡º Tokens å·²æˆåŠŸæ›´æ–°ä¸º: {new_max_tokens_int}")
                    else:
                        logger.warning(f"[{req_id}] âš ï¸ æœ€å¤§è¾“å‡º Tokens æ›´æ–°åéªŒè¯å¤±è´¥ã€‚é¡µé¢æ˜¾ç¤º: {new_max_tokens_int}, æœŸæœ›: {clamped_max_tokens}")
                else:
                    logger.info(f"[{req_id}] é¡µé¢æœ€å¤§è¾“å‡º Tokens ({current_max_tokens_int}) ä¸è¯·æ±‚æœ€å¤§è¾“å‡º Tokens ({clamped_max_tokens}) ä¸€è‡´ï¼Œæ— éœ€æ›´æ”¹ã€‚")

            except ValueError as ve:
                logger.error(f"[{req_id}] è½¬æ¢æœ€å¤§è¾“å‡º Tokens å€¼ä¸ºæ•´æ•°æ—¶å‡ºé”™: '{current_max_tokens_str if 'current_max_tokens_str' in locals() else 'æœªçŸ¥å€¼'}'. é”™è¯¯: {ve}")
                await save_error_snapshot(f"max_tokens_value_error_{req_id}")
            except PlaywrightAsyncError as pw_err:
                logger.error(f"[{req_id}] âŒ æ“ä½œæœ€å¤§è¾“å‡º Tokens è¾“å…¥æ¡†æ—¶å‘ç”ŸPlaywrighté”™è¯¯: {pw_err}")
                await save_error_snapshot(f"max_tokens_playwright_error_{req_id}")
            except ClientDisconnectedError:
                logger.info(f"[{req_id}] å®¢æˆ·ç«¯åœ¨è°ƒæ•´æœ€å¤§è¾“å‡º Tokens æ—¶æ–­å¼€è¿æ¥ã€‚")
                raise 
            except Exception as e_max_tokens:
                logger.exception(f"[{req_id}] âŒ è°ƒæ•´æœ€å¤§è¾“å‡º Tokens æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯")
                await save_error_snapshot(f"max_tokens_unknown_error_{req_id}")
            
            check_client_disconnected("æœ€å¤§è¾“å‡ºTokenè°ƒæ•´ - é€»è¾‘å®Œæˆå: ")
        # --- ç»“æŸè°ƒæ•´æœ€å¤§è¾“å‡ºToken ---

        # --- æ–°å¢: è®¾ç½®åœæ­¢åºåˆ— ---
        if request.stop is not None and page and not page.is_closed():
            logger.info(f"[{req_id}] (Refactored Process) æ£€æŸ¥å¹¶è®¾ç½®åœæ­¢åºåˆ—...")
            
            stop_sequences = []
            if isinstance(request.stop, str):
                stop_sequences = [request.stop]
            elif isinstance(request.stop, list):
                stop_sequences = [s for s in request.stop if isinstance(s, str) and s.strip()] # è¿‡æ»¤ç©ºå­—ç¬¦ä¸²

            if not stop_sequences and request.stop is not None: # å¦‚æœåŸå§‹ stop ä¸ä¸º None ä½†å¤„ç†åä¸ºç©ºåˆ—è¡¨
                 logger.info(f"[{req_id}] è¯·æ±‚çš„åœæ­¢åºåˆ—ä¸ºç©ºæˆ–åªåŒ…å«æ— æ•ˆæ¡ç›®ï¼Œå°†å°è¯•æ¸…ç©ºé¡µé¢ä¸Šçš„åœæ­¢åºåˆ—ã€‚")
            
            stop_input_locator = page.locator(STOP_SEQUENCE_INPUT_SELECTOR)
            remove_chip_buttons_locator = page.locator(MAT_CHIP_REMOVE_BUTTON_SELECTOR)

            try:
                # 1. æ¸…ç©ºå·²æœ‰çš„åœæ­¢åºåˆ—
                # ç‚¹å‡»é¡µé¢ä¸Šå·²æœ‰çš„ stop sequence chip çš„ç§»é™¤æŒ‰é’®
                # ä»æœ€åä¸€ä¸ªå¼€å§‹ç§»é™¤ï¼Œé¿å…å›  DOM å˜åŒ–å¯¼è‡´å®šä½é—®é¢˜
                logger.info(f"[{req_id}] å°è¯•æ¸…ç©ºå·²æœ‰çš„åœæ­¢åºåˆ—...")
                initial_chip_count = await remove_chip_buttons_locator.count()
                logger.debug(f"[{req_id}] å‘ç° {initial_chip_count} ä¸ªå¯ç§»é™¤çš„åœæ­¢åºåˆ—æ ‡ç­¾ã€‚")
                
                # å¢åŠ ä¸€ä¸ªå¾ªç¯è®¡æ•°å™¨å’Œæœ€å¤§ç§»é™¤æ¬¡æ•°ï¼Œé˜²æ­¢æ— é™å¾ªç¯
                removed_count = 0
                max_removals = initial_chip_count + 5 # å…è®¸ä¸€äº›åŠ¨æ€æ·»åŠ /ç§»é™¤çš„ä½™åœ°
                
                while await remove_chip_buttons_locator.count() > 0 and removed_count < max_removals:
                    check_client_disconnected("åœæ­¢åºåˆ—æ¸…é™¤ - å¾ªç¯å¼€å§‹: ")
                    try:
                        # æ€»æ˜¯ç‚¹å‡»ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„ç§»é™¤æŒ‰é’®ï¼Œå› ä¸º DOM ä¼šåœ¨ç‚¹å‡»åæ›´æ–°
                        await remove_chip_buttons_locator.first.click(timeout=2000)
                        removed_count += 1
                        logger.debug(f"[{req_id}] å·²ç§»é™¤ä¸€ä¸ªåœæ­¢åºåˆ—æ ‡ç­¾ (å·²ç§»é™¤ {removed_count} ä¸ª)ã€‚")
                        await asyncio.sleep(0.15) # çŸ­æš‚ç­‰å¾…UIæ›´æ–°
                    except PlaywrightAsyncError as pe_remove_inner:
                        logger.warning(f"[{req_id}] ç§»é™¤ä¸€ä¸ªåœæ­¢åºåˆ—æ ‡ç­¾æ—¶å‡ºé”™ (å¯èƒ½æ˜¯æœ€åä¸€ä¸ªæˆ–ä¸å¯è§): {pe_remove_inner}ã€‚é€€å‡ºæ¸…é™¤å¾ªç¯ã€‚")
                        break # å¦‚æœç‚¹å‡»å¤±è´¥ï¼Œå¯èƒ½å·²ç»æ²¡æœ‰å¯è§/å¯äº¤äº’çš„ç§»é™¤äº†
                    except Exception as e_remove_inner:
                        logger.error(f"[{req_id}] ç§»é™¤åœæ­¢åºåˆ—æ ‡ç­¾æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e_remove_inner}ã€‚é€€å‡ºæ¸…é™¤å¾ªç¯ã€‚")
                        break
                logger.info(f"[{req_id}] å·²æœ‰åœæ­¢åºåˆ—æ¸…ç©ºå®Œæˆ (æˆ–å°è¯•æ¸…ç©º)ã€‚å®é™…ç§»é™¤ {removed_count} ä¸ªã€‚")

                check_client_disconnected("åœæ­¢åºåˆ—æ¸…é™¤ - å®Œæˆå: ")

                # 2. æ·»åŠ æ–°çš„åœæ­¢åºåˆ—
                if stop_sequences: # åªæœ‰å½“æä¾›äº†æœ‰æ•ˆçš„åœæ­¢åºåˆ—æ—¶æ‰æ·»åŠ 
                    logger.info(f"[{req_id}] æ·»åŠ  {len(stop_sequences)} ä¸ªæ–°çš„åœæ­¢åºåˆ—: {stop_sequences}")
                    await expect_async(stop_input_locator).to_be_visible(timeout=5000)
                    check_client_disconnected("åœæ­¢åºåˆ—æ·»åŠ  - è¾“å…¥æ¡†å¯è§å: ")

                    for seq in stop_sequences:
                        if not seq.strip(): continue # å†æ¬¡ç¡®ä¿ä¸æ·»åŠ ç©ºå­—ç¬¦ä¸²
                        logger.debug(f"[{req_id}] æ­£åœ¨æ·»åŠ åœæ­¢åºåˆ—: '{seq}'")
                        await stop_input_locator.fill(seq, timeout=3000)
                        check_client_disconnected(f"åœæ­¢åºåˆ—æ·»åŠ  - è¾“å…¥æ¡†å¡«å…… '{seq}' å: ")
                        await stop_input_locator.press("Enter", timeout=3000)
                        check_client_disconnected(f"åœæ­¢åºåˆ—æ·»åŠ  - ä¸º '{seq}' æŒ‰ä¸‹ Enter å: ")
                        # ç­‰å¾…è¾“å…¥æ¡†æ¸…ç©ºæˆ– chip å‡ºç° (ç®€å•å»¶æ—¶ä½œä¸ºæ›¿ä»£)
                        await asyncio.sleep(0.2) 
                        # éªŒè¯è¾“å…¥æ¡†æ˜¯å¦æ¸…ç©º
                        current_input_value = await stop_input_locator.input_value(timeout=1000)
                        if current_input_value:
                            logger.warning(f"[{req_id}] æ·»åŠ åœæ­¢åºåˆ— '{seq}' åï¼Œè¾“å…¥æ¡†æœªå®Œå…¨æ¸…ç©º (å€¼ä¸º: '{current_input_value}')ã€‚å¯èƒ½æœªæˆåŠŸæ·»åŠ ä¸º chipã€‚")
                        else:
                            logger.debug(f"[{req_id}] åœæ­¢åºåˆ— '{seq}' å·²é€šè¿‡ Enter æäº¤ã€‚")
                    logger.info(f"[{req_id}] âœ… æ–°åœæ­¢åºåˆ—æ·»åŠ å®Œæˆã€‚")
                else:
                    logger.info(f"[{req_id}] æ²¡æœ‰æä¾›æ–°çš„æœ‰æ•ˆåœæ­¢åºåˆ—æ¥æ·»åŠ ã€‚")

            except PlaywrightAsyncError as pw_err:
                logger.error(f"[{req_id}] âŒ æ“ä½œåœæ­¢åºåˆ—æ—¶å‘ç”ŸPlaywrighté”™è¯¯: {pw_err}")
                await save_error_snapshot(f"stop_sequence_playwright_error_{req_id}")
            except ClientDisconnectedError:
                logger.info(f"[{req_id}] å®¢æˆ·ç«¯åœ¨è°ƒæ•´åœæ­¢åºåˆ—æ—¶æ–­å¼€è¿æ¥ã€‚")
                raise
            except Exception as e_stop_seq:
                logger.exception(f"[{req_id}] âŒ è®¾ç½®åœæ­¢åºåˆ—æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯")
                await save_error_snapshot(f"stop_sequence_unknown_error_{req_id}")
            
            check_client_disconnected("åœæ­¢åºåˆ—è°ƒæ•´ - é€»è¾‘å®Œæˆå: ")
        # --- ç»“æŸè®¾ç½®åœæ­¢åºåˆ— ---

        # --- æ–°å¢: è°ƒæ•´ Top P è®¾ç½® ---
        if request.top_p is not None and page and not page.is_closed():
            logger.info(f"[{req_id}] (Refactored Process) æ£€æŸ¥å¹¶è°ƒæ•´ Top P è®¾ç½®...")
            requested_top_p = request.top_p
            
            # æ ¹æ® HTML å±æ€§è¿›è¡ŒèŒƒå›´é™åˆ¶: min="0" max="1"
            clamped_top_p = max(0.0, min(1.0, requested_top_p))
            if abs(clamped_top_p - requested_top_p) > 1e-9: # æ¯”è¾ƒæµ®ç‚¹æ•°æ—¶ä½¿ç”¨å®¹å·®
                logger.warning(f"[{req_id}] è¯·æ±‚çš„ Top P {requested_top_p} è¶…å‡ºèŒƒå›´ [0, 1]ï¼Œå·²è°ƒæ•´ä¸º {clamped_top_p}")
            
            top_p_input_locator = page.locator(TOP_P_INPUT_SELECTOR)
            try:
                await expect_async(top_p_input_locator).to_be_visible(timeout=5000)
                check_client_disconnected("Top P è°ƒæ•´ - è¾“å…¥æ¡†å¯è§å: ")
                
                current_top_p_str = await top_p_input_locator.input_value(timeout=3000)
                check_client_disconnected("Top P è°ƒæ•´ - è¯»å–è¾“å…¥æ¡†å€¼å: ")
                
                current_top_p_float = float(current_top_p_str)
                logger.info(f"[{req_id}] é¡µé¢å½“å‰ Top P: {current_top_p_float}, è¯·æ±‚è°ƒæ•´å Top P: {clamped_top_p}")

                # ä½¿ç”¨å®¹å·®æ¯”è¾ƒæµ®ç‚¹æ•°
                if abs(current_top_p_float - clamped_top_p) > 1e-9: 
                    logger.info(f"[{req_id}] é¡µé¢ Top P ({current_top_p_float}) ä¸è¯·æ±‚ Top P ({clamped_top_p}) ä¸åŒï¼Œæ­£åœ¨æ›´æ–°...")
                    await top_p_input_locator.fill(str(clamped_top_p), timeout=5000)
                    check_client_disconnected("Top P è°ƒæ•´ - å¡«å……è¾“å…¥æ¡†å: ")
                    
                    # éªŒè¯æ›´æ”¹ (å¯é€‰ä½†æ¨è)
                    await asyncio.sleep(0.1) # çŸ­æš‚ç­‰å¾…å€¼æ›´æ–°
                    new_top_p_str = await top_p_input_locator.input_value(timeout=3000)
                    new_top_p_float = float(new_top_p_str)
                    if abs(new_top_p_float - clamped_top_p) < 1e-9:
                        logger.info(f"[{req_id}] âœ… Top P å·²æˆåŠŸæ›´æ–°ä¸º: {new_top_p_float}")
                    else:
                        logger.warning(f"[{req_id}] âš ï¸ Top P æ›´æ–°åéªŒè¯å¤±è´¥ã€‚é¡µé¢æ˜¾ç¤º: {new_top_p_float}, æœŸæœ›: {clamped_top_p}")
                else:
                    logger.info(f"[{req_id}] é¡µé¢ Top P ({current_top_p_float}) ä¸è¯·æ±‚ Top P ({clamped_top_p}) ä¸€è‡´æˆ–åœ¨å®¹å·®èŒƒå›´å†…ï¼Œæ— éœ€æ›´æ”¹ã€‚")

            except ValueError as ve:
                logger.error(f"[{req_id}] è½¬æ¢ Top P å€¼ä¸ºæµ®ç‚¹æ•°æ—¶å‡ºé”™: '{current_top_p_str if 'current_top_p_str' in locals() else 'æœªçŸ¥å€¼'}'. é”™è¯¯: {ve}")
                await save_error_snapshot(f"top_p_value_error_{req_id}")
            except PlaywrightAsyncError as pw_err:
                logger.error(f"[{req_id}] âŒ æ“ä½œ Top P è¾“å…¥æ¡†æ—¶å‘ç”ŸPlaywrighté”™è¯¯: {pw_err}")
                await save_error_snapshot(f"top_p_playwright_error_{req_id}")
            except ClientDisconnectedError:
                logger.info(f"[{req_id}] å®¢æˆ·ç«¯åœ¨è°ƒæ•´ Top P æ—¶æ–­å¼€è¿æ¥ã€‚")
                raise
            except Exception as e_top_p:
                logger.exception(f"[{req_id}] âŒ è°ƒæ•´ Top P æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯")
                await save_error_snapshot(f"top_p_unknown_error_{req_id}")
            
            check_client_disconnected("Top P è°ƒæ•´ - é€»è¾‘å®Œæˆå: ")
        # --- ç»“æŸè°ƒæ•´ Top P ---

        # --- 3. Fill & Submit Prompt --- (Use logger)
        logger.info(f"[{req_id}] (Refactored Process) å¡«å……å¹¶æäº¤æç¤º ({len(prepared_prompt)} chars)...") # logger
        input_field = page.locator(INPUT_SELECTOR)
        submit_button = page.locator(SUBMIT_BUTTON_SELECTOR)
        try:
            # Direct calls with timeout
            await expect_async(input_field).to_be_visible(timeout=5000)
            check_client_disconnected("After Input Visible: ")
            await input_field.fill(prepared_prompt, timeout=90000)
            check_client_disconnected("After Input Fill: ")
            await expect_async(submit_button).to_be_enabled(timeout=10000)
            check_client_disconnected("After Submit Enabled: ")
            await asyncio.sleep(0.2) # Use asyncio.sleep
            check_client_disconnected("After Submit Pre-Delay: ")

            # Try shortcut submit
            submitted_successfully = False
            try:
                navigator_platform = await page.evaluate("navigator.platform")
                is_mac = "mac" in navigator_platform.lower()
                shortcut_key = "Meta" if is_mac else "Control"
                await input_field.focus(timeout=5000)
                check_client_disconnected("After Input Focus (Shortcut): ")
                await page.keyboard.press(f'{shortcut_key}+Enter')
                check_client_disconnected("After Keyboard Press: ")
                # Check input cleared (direct call)
                await expect_async(input_field).to_have_value('', timeout=1000)
                submitted_successfully = True
                logger.info(f"[{req_id}]   - å¿«æ·é”®æäº¤æˆåŠŸã€‚") # logger
            except Exception as shortcut_err:
                logger.warning(f"[{req_id}]   - å¿«æ·é”®æäº¤å¤±è´¥æˆ–æœªç¡®è®¤: {shortcut_err}ã€‚å›é€€åˆ°ç‚¹å‡»ã€‚") # logger

            check_client_disconnected("After Shortcut Attempt Logic: ")

            # Fallback to click
            if not submitted_successfully:
                # Direct calls with timeout
                await submit_button.scroll_into_view_if_needed(timeout=5000)
                check_client_disconnected("After Scroll Fallback: ")
                await submit_button.click(timeout=10000, force=True)
                check_client_disconnected("After Click Fallback: ")
                await expect_async(input_field).to_have_value('', timeout=3000)
                submitted_successfully = True
                logger.info(f"[{req_id}]   - ç‚¹å‡»æäº¤æˆåŠŸã€‚") # logger

            if not submitted_successfully:
                 raise PlaywrightAsyncError("Failed to submit prompt via shortcut or click.")

        except (PlaywrightAsyncError, asyncio.TimeoutError, ClientDisconnectedError) as submit_err:
            if isinstance(submit_err, ClientDisconnectedError): raise
            logger.error(f"[{req_id}] âŒ é”™è¯¯: å¡«å……æˆ–æäº¤æç¤ºæ—¶å‡ºé”™: {submit_err}") # logger
            await save_error_snapshot(f"submit_prompt_error_{req_id}")
            raise HTTPException(status_code=502, detail=f"[{req_id}] Failed to submit prompt to AI Studio: {submit_err}")
        except Exception as submit_exc:
            logger.exception(f"[{req_id}] âŒ é”™è¯¯: å¡«å……æˆ–æäº¤æç¤ºæ—¶æ„å¤–é”™è¯¯") # logger
            await save_error_snapshot(f"submit_prompt_unexpected_{req_id}")
            raise HTTPException(status_code=500, detail=f"[{req_id}] Unexpected error during prompt submission: {submit_exc}")
        check_client_disconnected("After Submit Logic: ")

        # --- 4. Locate Response Element --- (Use logger)
        logger.info(f"[{req_id}] (Refactored Process) å®šä½å“åº”å…ƒç´ ...") # logger
        response_container = page.locator(RESPONSE_CONTAINER_SELECTOR).last
        response_element = response_container.locator(RESPONSE_TEXT_SELECTOR)
        try:
            # Direct calls with timeout
            await expect_async(response_container).to_be_attached(timeout=20000)
            check_client_disconnected("After Response Container Attached: ")
            await expect_async(response_element).to_be_attached(timeout=90000)
            logger.info(f"[{req_id}]   - å“åº”å…ƒç´ å·²å®šä½ã€‚") # logger
        except (PlaywrightAsyncError, asyncio.TimeoutError, ClientDisconnectedError) as locate_err:
            if isinstance(locate_err, ClientDisconnectedError): raise
            logger.error(f"[{req_id}] âŒ é”™è¯¯: å®šä½å“åº”å…ƒç´ å¤±è´¥æˆ–è¶…æ—¶: {locate_err}") # logger
            await save_error_snapshot(f"response_locate_error_{req_id}")
            raise HTTPException(status_code=502, detail=f"[{req_id}] Failed to locate AI Studio response element: {locate_err}")
        except Exception as locate_exc:
            logger.exception(f"[{req_id}] âŒ é”™è¯¯: å®šä½å“åº”å…ƒç´ æ—¶æ„å¤–é”™è¯¯") # logger
            await save_error_snapshot(f"response_locate_unexpected_{req_id}")
            raise HTTPException(status_code=500, detail=f"[{req_id}] Unexpected error locating response element: {locate_exc}")
        check_client_disconnected("After Locate Response: ")

        # --- 5. Wait for Completion --- (Uses helper, which was reverted internally)
        logger.info(f"[{req_id}] (Refactored Process) ç­‰å¾…å“åº”ç”Ÿæˆå®Œæˆ...") # logger
        completion_detected = await _wait_for_response_completion(
            page, req_id, response_element, None, check_client_disconnected, None # Pass None for unused helpers
        )
        if not completion_detected:
            raise HTTPException(status_code=504, detail=f"[{req_id}] AI Studio response generation timed out.")
        check_client_disconnected("After Wait Completion: ")

        # --- 6. Check for Page Errors --- (Use logger)
        logger.info(f"[{req_id}] (Refactored Process) æ£€æŸ¥é¡µé¢é”™è¯¯æç¤º...") # logger
        page_error = await detect_and_extract_page_error(page, req_id)
        if page_error:
            logger.error(f"[{req_id}] âŒ é”™è¯¯: AI Studio é¡µé¢è¿”å›é”™è¯¯: {page_error}") # logger
            await save_error_snapshot(f"page_error_detected_{req_id}")
            raise HTTPException(status_code=502, detail=f"[{req_id}] AI Studio Error: {page_error}")
        check_client_disconnected("After Page Error Check: ")

        # --- 7. Get Final Content --- (Uses helpers, which were reverted internally)
        logger.info(f"[{req_id}] (Refactored Process) è·å–æœ€ç»ˆå“åº”å†…å®¹...") # logger
        final_content = await _get_final_response_content(
            page, req_id, check_client_disconnected # Pass only needed args
        )
        if final_content is None:
            raise HTTPException(status_code=500, detail=f"[{req_id}] Failed to extract final response content from AI Studio.")
        check_client_disconnected("After Get Content: ")

        # --- 8. Format and Return Result --- (Use logger)
        logger.info(f"[{req_id}] (Refactored Process) æ ¼å¼åŒ–å¹¶è®¾ç½®ç»“æœ (æ¨¡å¼: {'æµå¼' if is_streaming else 'éæµå¼'})...") # logger
        if is_streaming:
            completion_event = Event() # Create event for streaming

            async def create_stream_generator(event_to_set: Event, content_to_stream: str) -> AsyncGenerator[str, None]:
                """Closure to generate SSE stream from final content."""
                logger.info(f"[{req_id}] (Stream Gen) å¼€å§‹ä¼ªæµå¼è¾“å‡º ({len(content_to_stream)} chars)...") # logger
                try:
                    char_count = 0
                    total_chars = len(content_to_stream)
                    for i in range(0, total_chars):
                        if client_disconnected_event.is_set():
                            logger.info(f"[{req_id}] (Stream Gen) æ–­å¼€è¿æ¥ï¼Œåœæ­¢ã€‚") # logger
                            break
                        delta = content_to_stream[i]
                        yield generate_sse_chunk(delta, req_id, MODEL_NAME)
                        char_count += 1
                        if char_count % 100 == 0 or char_count == total_chars:
                            if DEBUG_LOGS_ENABLED:
                                pass # Keep the structure, but no log needed here now
                        await asyncio.sleep(PSEUDO_STREAM_DELAY) # Use asyncio.sleep

                    yield generate_sse_stop_chunk(req_id, MODEL_NAME)
                    yield "data: [DONE]\n\n"
                    logger.info(f"[{req_id}] (Stream Gen) âœ… ä¼ªæµå¼å“åº”å‘é€å®Œæ¯•ã€‚") # logger
                except asyncio.CancelledError:
                    logger.info(f"[{req_id}] (Stream Gen) æµç”Ÿæˆå™¨è¢«å–æ¶ˆã€‚") # logger
                except Exception as e:
                    logger.exception(f"[{req_id}] (Stream Gen) âŒ ä¼ªæµå¼ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™") # logger
                    try: yield generate_sse_error_chunk(f"Stream generation error: {e}", req_id); yield "data: [DONE]\n\n"
                    except: pass
                finally:
                    logger.info(f"[{req_id}] (Stream Gen) è®¾ç½®å®Œæˆäº‹ä»¶ã€‚") # logger
                    if not event_to_set.is_set(): event_to_set.set()

            stream_generator_func = create_stream_generator(completion_event, final_content)
            if not result_future.done():
                result_future.set_result(StreamingResponse(stream_generator_func, media_type="text/event-stream"))
                logger.info(f"[{req_id}] (Refactored Process) æµå¼å“åº”ç”Ÿæˆå™¨å·²è®¾ç½®ã€‚") # logger
            else:
                logger.warning(f"[{req_id}] (Refactored Process) Future å·²å®Œæˆ/å–æ¶ˆï¼Œæ— æ³•è®¾ç½®æµå¼ç»“æœã€‚") # logger
                if not completion_event.is_set(): completion_event.set()
            return completion_event
        else: # Non-streaming
            response_payload = {
                "id": f"{CHAT_COMPLETION_ID_PREFIX}{req_id}-{int(time.time())}",
                "object": "chat.completion",
                "created": int(time.time()),
                "model": MODEL_NAME,
                "choices": [{
                    "index": 0,
                    "message": {"role": "assistant", "content": final_content},
                    "finish_reason": "stop"
                }],
                "usage": {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}
            }
            if not result_future.done():
                result_future.set_result(JSONResponse(content=response_payload))
                logger.info(f"[{req_id}] (Refactored Process) éæµå¼ JSON å“åº”å·²è®¾ç½®ã€‚") # logger
            else:
                logger.warning(f"[{req_id}] (Refactored Process) Future å·²å®Œæˆ/å–æ¶ˆï¼Œæ— æ³•è®¾ç½® JSON ç»“æœã€‚") # logger
            return None

    # --- Exception Handling --- (Use logger)
    except ClientDisconnectedError as disco_err:
        logger.info(f"[{req_id}] (Refactored Process) æ•è·åˆ°å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ä¿¡å·: {disco_err}") # logger
        if not result_future.done():
             result_future.set_exception(HTTPException(status_code=499, detail=f"[{req_id}] Client disconnected during processing."))
    except HTTPException as http_err:
        logger.warning(f"[{req_id}] (Refactored Process) æ•è·åˆ° HTTP å¼‚å¸¸: {http_err.status_code} - {http_err.detail}") # logger
        if not result_future.done(): result_future.set_exception(http_err)
    except PlaywrightAsyncError as pw_err:
        logger.error(f"[{req_id}] (Refactored Process) æ•è·åˆ° Playwright é”™è¯¯: {pw_err}") # logger
        await save_error_snapshot(f"process_playwright_error_{req_id}")
        if not result_future.done(): result_future.set_exception(HTTPException(status_code=502, detail=f"[{req_id}] Playwright interaction failed: {pw_err}"))
    except asyncio.TimeoutError as timeout_err:
        logger.error(f"[{req_id}] (Refactored Process) æ•è·åˆ°æ“ä½œè¶…æ—¶: {timeout_err}") # logger
        await save_error_snapshot(f"process_timeout_error_{req_id}")
        if not result_future.done(): result_future.set_exception(HTTPException(status_code=504, detail=f"[{req_id}] Operation timed out: {timeout_err}"))
    except asyncio.CancelledError:
        logger.info(f"[{req_id}] (Refactored Process) ä»»åŠ¡è¢«å–æ¶ˆã€‚") # logger
        if not result_future.done(): result_future.cancel("Processing task cancelled")
    except Exception as e:
        logger.exception(f"[{req_id}] (Refactored Process) æ•è·åˆ°æ„å¤–é”™è¯¯") # logger
        await save_error_snapshot(f"process_unexpected_error_{req_id}")
        if not result_future.done(): result_future.set_exception(HTTPException(status_code=500, detail=f"[{req_id}] Unexpected server error: {e}"))
    finally:
        # --- Cleanup Disconnect Task --- (Use logger)
        if disconnect_check_task and not disconnect_check_task.done():
            disconnect_check_task.cancel()
            try: await disconnect_check_task
            except asyncio.CancelledError: pass
            except Exception as task_clean_err: logger.error(f"[{req_id}] æ¸…ç†ä»»åŠ¡æ—¶å‡ºé”™: {task_clean_err}") # logger
        logger.info(f"[{req_id}] (Refactored Process) å¤„ç†å®Œæˆã€‚") # logger
        if is_streaming and completion_event and not completion_event.is_set() and (result_future.done() and result_future.exception() is not None):
             logger.warning(f"[{req_id}] (Refactored Process) æµå¼è¯·æ±‚å¼‚å¸¸ï¼Œç¡®ä¿å®Œæˆäº‹ä»¶å·²è®¾ç½®ã€‚") # logger
             completion_event.set()
        return completion_event

# --- Main Chat Endpoint --- (Enqueue request)
@app.post("/v1/chat/completions")
async def chat_completions(request: ChatCompletionRequest, http_request: Request):
    req_id = ''.join(random.choices('abcdefghijklmnopqrstuvwxyz0123456789', k=7))
    logger.info(f"[{req_id}] æ”¶åˆ° /v1/chat/completions è¯·æ±‚ (Stream={request.stream})")
    logger.debug(f"[{req_id}] å®Œæ•´è¯·æ±‚å‚æ•°: {request.model_dump_json(indent=2)}")

    launch_mode = os.environ.get('LAUNCH_MODE', 'unknown')
    browser_page_critical = launch_mode != "direct_debug_no_browser"
    
    # æ£€æŸ¥æ ¸å¿ƒæœåŠ¡æ˜¯å¦å°±ç»ª
    service_unavailable = is_initializing or \
                          not is_playwright_ready or \
                          (browser_page_critical and (not is_page_ready or not is_browser_connected)) or \
                          not worker_task or worker_task.done()

    if service_unavailable:
        status_code = 503
        # æ„å»ºæ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        error_details = []
        if is_initializing: error_details.append("åˆå§‹åŒ–è¿›è¡Œä¸­")
        if not is_playwright_ready: error_details.append("Playwright æœªå°±ç»ª")
        if browser_page_critical:
            if not is_browser_connected: error_details.append("æµè§ˆå™¨æœªè¿æ¥")
            if not is_page_ready: error_details.append("é¡µé¢æœªå°±ç»ª")
        if not worker_task or worker_task.done(): error_details.append("Worker æœªè¿è¡Œ")
        
        detail = f"[{req_id}] æœåŠ¡å½“å‰ä¸å¯ç”¨ ({', '.join(error_details)}). è¯·ç¨åé‡è¯•."
        logger.error(f"[{req_id}] æœåŠ¡ä¸å¯ç”¨è¯¦æƒ…: {detail}")
        raise HTTPException(status_code=status_code, detail=detail, headers={"Retry-After": "30"})

    result_future = Future()
    request_item = {
        "req_id": req_id, "request_data": request, "http_request": http_request,
        "result_future": result_future, "enqueue_time": time.time(), "cancelled": False
    }
    await request_queue.put(request_item)
    logger.info(f"[{req_id}] è¯·æ±‚å·²åŠ å…¥é˜Ÿåˆ— (å½“å‰é˜Ÿåˆ—é•¿åº¦: {request_queue.qsize()})")
    try:
        timeout_seconds = RESPONSE_COMPLETION_TIMEOUT / 1000 + 120
        result = await asyncio.wait_for(result_future, timeout=timeout_seconds)
        logger.info(f"[{req_id}] Worker å¤„ç†å®Œæˆï¼Œè¿”å›ç»“æœã€‚")
        return result
    except asyncio.TimeoutError:
        logger.error(f"[{req_id}] âŒ ç­‰å¾… Worker å“åº”è¶…æ—¶ ({timeout_seconds}s)ã€‚")
        raise HTTPException(status_code=504, detail=f"[{req_id}] Request processing timed out waiting for worker response.")
    except asyncio.CancelledError: # é€šå¸¸ç”±å®¢æˆ·ç«¯æ–­å¼€è¿æ¥è§¦å‘
        logger.info(f"[{req_id}] è¯·æ±‚ Future è¢«å–æ¶ˆ (å¯èƒ½ç”±å®¢æˆ·ç«¯æ–­å¼€è¿æ¥è§¦å‘)ã€‚")
        # Worker å†…éƒ¨çš„ check_disconnect_periodically åº”è¯¥å·²ç»è®¾ç½®äº† 499 å¼‚å¸¸
        # ä½†è¿™é‡Œä½œä¸ºåå¤‡ï¼Œå¦‚æœ Future è¢«ç›´æ¥å–æ¶ˆ
        if not result_future.done() or result_future.exception() is None:
             # å¦‚æœ future æ²¡æœ‰è¢« worker è®¾ç½®å¼‚å¸¸ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œè®¾ç½®ä¸€ä¸ª
             raise HTTPException(status_code=499, detail=f"[{req_id}] Request cancelled by client or server.")
        else: # å¦‚æœ future å·²ç»è¢« worker è®¾ç½®äº†å¼‚å¸¸ (ä¾‹å¦‚ HTTPException)ï¼Œé‡æ–°æŠ›å‡ºå®ƒ
             raise result_future.exception()
    except HTTPException as http_err: # ç”± worker æ˜ç¡®æŠ›å‡ºçš„ HTTP å¼‚å¸¸
        # logger.warning(f"[{req_id}] Worker æŠ›å‡º HTTP å¼‚å¸¸ {http_err.status_code}ï¼Œé‡æ–°æŠ›å‡ºã€‚") # Worker å†…éƒ¨å·²è®°å½•
        raise http_err
    except Exception as e: # å…¶ä»–æ„å¤–é”™è¯¯
        logger.exception(f"[{req_id}] âŒ ç­‰å¾… Worker å“åº”æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯")
        raise HTTPException(status_code=500, detail=f"[{req_id}] Unexpected error waiting for worker response: {e}")

# --- æ–°å¢ï¼šè¾…åŠ©å‡½æ•°ï¼Œæœç´¢é˜Ÿåˆ—ä¸­çš„è¯·æ±‚å¹¶æ ‡è®°ä¸ºå–æ¶ˆ --- (Helper from serveræœªé‡æ„.py)
async def cancel_queued_request(req_id: str) -> bool:
    """åœ¨é˜Ÿåˆ—ä¸­æŸ¥æ‰¾æŒ‡å®šreq_idçš„è¯·æ±‚å¹¶æ ‡è®°ä¸ºå–æ¶ˆã€‚

    è¿”å›:
        bool: å¦‚æœæ‰¾åˆ°å¹¶æ ‡è®°äº†è¯·æ±‚åˆ™è¿”å›Trueï¼Œå¦åˆ™è¿”å›False
    """
    cancelled = False
    # Create a temporary list to hold items while searching
    items_to_requeue = []
    found = False
    try:
        while True: # Process the whole queue or until found
            item = request_queue.get_nowait()
            if item.get("req_id") == req_id and not item.get("cancelled", False):
                # print(f"[{req_id}] åœ¨é˜Ÿåˆ—ä¸­æ‰¾åˆ°è¯·æ±‚ï¼Œæ ‡è®°ä¸ºå·²å–æ¶ˆã€‚", flush=True)
                logger.info(f"[{req_id}] åœ¨é˜Ÿåˆ—ä¸­æ‰¾åˆ°è¯·æ±‚ï¼Œæ ‡è®°ä¸ºå·²å–æ¶ˆã€‚") # logger
                item["cancelled"] = True
                # Set exception on future immediately if possible
                item_future = item.get("result_future")
                if item_future and not item_future.done():
                    item_future.set_exception(HTTPException(status_code=499, detail=f"[{req_id}] Request cancelled by API call."))
                items_to_requeue.append(item) # Requeue the cancelled item
                cancelled = True
                found = True
                # Don't break, process the rest of the queue to requeue items
            else:
                items_to_requeue.append(item)
    except asyncio.QueueEmpty:
        pass # Finished processing the queue
    finally:
        # Put all items back into the queue
        for item in items_to_requeue:
            await request_queue.put(item)
    return cancelled

# --- æ–°å¢ï¼šæ·»åŠ å–æ¶ˆè¯·æ±‚çš„APIç«¯ç‚¹ --- (Endpoint from serveræœªé‡æ„.py)
@app.post("/v1/cancel/{req_id}")
async def cancel_request(req_id: str):
    # (ä»£ç ä¸å˜)
    logger.info(f"[{req_id}] æ”¶åˆ°å–æ¶ˆè¯·æ±‚ã€‚")
    cancelled = await cancel_queued_request(req_id)
    if cancelled:
        return JSONResponse(content={"success": True, "message": f"Request {req_id} marked as cancelled in queue."})
    else:
        return JSONResponse(
            content={"success": False, "message": f"Request {req_id} not found in queue (it might be processing or already finished)."},
            status_code=404
        )

@app.get("/v1/queue")
async def get_queue_status():
    # (ä»£ç ä¸å˜)
    queue_items = []
    items_to_requeue = []
    try:
        while True:
            item = request_queue.get_nowait()
            items_to_requeue.append(item)
            req_id = item.get("req_id", "unknown")
            timestamp = item.get("enqueue_time", 0)
            is_streaming = item.get("request_data").stream if hasattr(item.get("request_data", {}), "stream") else False
            cancelled = item.get("cancelled", False)
            queue_items.append({
                "req_id": req_id, "enqueue_time": timestamp,
                "wait_time_seconds": round(time.time() - timestamp, 2) if timestamp else None,
                "is_streaming": is_streaming, "cancelled": cancelled
            })
    except asyncio.QueueEmpty:
        pass
    finally:
        for item in items_to_requeue:
            await request_queue.put(item)
    return JSONResponse(content={
        "queue_length": len(queue_items),
        "is_processing_locked": processing_lock.locked(),
        "items": sorted(queue_items, key=lambda x: x.get("enqueue_time", 0))
    })

@app.websocket("/ws/logs")
async def websocket_log_endpoint(websocket: WebSocket):
    if not log_ws_manager:
        try:
            await websocket.accept()
            await websocket.send_text(json.dumps({
                "type": "error", "status": "disconnected",
                "message": "æ—¥å¿—æœåŠ¡å†…éƒ¨é”™è¯¯ (ç®¡ç†å™¨æœªåˆå§‹åŒ–)ã€‚",
                "timestamp": datetime.datetime.now().isoformat()}))
            await websocket.close(code=1011)
        except Exception: pass
        return

    client_id = str(uuid.uuid4())
    try:
        await log_ws_manager.connect(client_id, websocket)
        while True:
            data = await websocket.receive_text()
            if data.lower() == "ping":
                 await websocket.send_text(json.dumps({"type": "pong", "timestamp": datetime.datetime.now().isoformat()}))
    except WebSocketDisconnect:
        # logger.info(f"æ—¥å¿—å®¢æˆ·ç«¯ {client_id} å·²æ–­å¼€ã€‚") # disconnect æ–¹æ³•ä¼šè®°å½•
        pass # disconnect æ–¹æ³•ä¼šå¤„ç†æ—¥å¿—è®°å½•
    except Exception as e:
        logger.error(f"æ—¥å¿— WebSocket (å®¢æˆ·ç«¯ {client_id}) å‘ç”Ÿå¼‚å¸¸: {e}", exc_info=True)
    finally:
        if log_ws_manager: # ç¡®ä¿ manager ä»ç„¶å­˜åœ¨
            log_ws_manager.disconnect(client_id)

# --- ç§»é™¤ç‹¬ç«‹çš„ __main__ Uvicorn å¯åŠ¨é€»è¾‘ ---
if __name__ == "__main__":
    print("é”™è¯¯: server.py ä¸åº”ç›´æ¥ä½œä¸ºä¸»è„šæœ¬è¿è¡Œã€‚", file=sys.stderr)
    print("è¯·ä½¿ç”¨ launch_camoufox.py (ç”¨äºè°ƒè¯•) æˆ– start.py (ç”¨äºåå°æœåŠ¡) æ¥å¯åŠ¨ã€‚", file=sys.stderr)
    print("\nå¦‚æœç¡®å®éœ€è¦ç›´æ¥è¿è¡Œ server.py è¿›è¡Œåº•å±‚æµ‹è¯• (ä¸æ¨è):", file=sys.stderr)
    print("  1. ç¡®ä¿å·²è®¾ç½®å¿…è¦çš„ç¯å¢ƒå˜é‡ï¼Œå¦‚ CAMOUFOX_WS_ENDPOINT, LAUNCH_MODE, SERVER_REDIRECT_PRINT, SERVER_LOG_LEVELã€‚", file=sys.stderr)
    print("  2. ç„¶åå¯ä»¥å°è¯•: python -m uvicorn server:app --host 0.0.0.0 --port <ç«¯å£å·>", file=sys.stderr)
    print("     ä¾‹å¦‚: LAUNCH_MODE=direct_debug_no_browser SERVER_REDIRECT_PRINT=false python -m uvicorn server:app --port 8000", file=sys.stderr)
    sys.exit(1)

# --- æ·»åŠ æ¨¡å‹åˆ‡æ¢çš„è¾…åŠ©å‡½æ•° ---
async def switch_ai_studio_model(page: AsyncPage, model_id: str, req_id: str) -> bool:
    """
    åœ¨AI Studioé¡µé¢ä¸Šåˆ‡æ¢æ¨¡å‹ã€‚
    
    Args:
        page: Playwrighté¡µé¢å¯¹è±¡
        model_id: ç›®æ ‡æ¨¡å‹ID (ä¾‹å¦‚ "gemini-1.5-pro")
        req_id: è¯·æ±‚IDï¼Œç”¨äºæ—¥å¿—è®°å½•
        
    Returns:
        bool: åˆ‡æ¢æ˜¯å¦æˆåŠŸ
    """
    logger.info(f"[{req_id}] å¼€å§‹åˆ‡æ¢æ¨¡å‹åˆ°: {model_id}")
    
    original_prefs_str: Optional[str] = None
    original_prompt_model: Optional[str] = None
    # å®šä¹‰å›ºå®šçš„æ–°èŠå¤© URL
    new_chat_url = f"https://{AI_STUDIO_URL_PATTERN}prompts/new_chat"

    try:
        # 1. è¯»å–å¹¶å¤‡ä»½å½“å‰è®¾ç½®
        original_prefs_str = await page.evaluate("() => localStorage.getItem('aiStudioUserPreference')")
        if original_prefs_str:
            try:
                original_prefs_obj = json.loads(original_prefs_str)
                original_prompt_model = original_prefs_obj.get("promptModel")
                logger.info(f"[{req_id}] åˆ‡æ¢å‰ localStorage.promptModel ä¸º: {original_prompt_model or 'æœªè®¾ç½®'}")
            except json.JSONDecodeError:
                logger.warning(f"[{req_id}] æ— æ³•è§£æåŸå§‹çš„ aiStudioUserPreference JSON å­—ç¬¦ä¸²ã€‚")
                original_prefs_str = None # è§†ä¸ºæ— æ•ˆ

        current_prefs_for_modification = json.loads(original_prefs_str) if original_prefs_str else {}
        
        # 2. ä¿®æ”¹æ¨¡å‹è®¾ç½®
        full_model_path = f"models/{model_id}"
        if current_prefs_for_modification.get("promptModel") == full_model_path:
            logger.info(f"[{req_id}] æ¨¡å‹å·²ç»è®¾ç½®ä¸º {model_id} (localStorage ä¸­å·²æ˜¯ç›®æ ‡å€¼)ï¼Œæ— éœ€åˆ‡æ¢")
            # å³ä½¿æ— éœ€åˆ‡æ¢localStorageï¼Œä¹Ÿç¡®ä¿å¯¼èˆªåˆ°new_chaté¡µé¢ï¼Œä»¥ç»Ÿä¸€è¡Œä¸º
            if page.url != new_chat_url:
                 logger.info(f"[{req_id}] å½“å‰ URL ä¸æ˜¯ new_chat ({page.url})ï¼Œå¯¼èˆªåˆ° {new_chat_url}")
                 await page.goto(new_chat_url, wait_until="domcontentloaded", timeout=30000)
                 await expect_async(page.locator(INPUT_SELECTOR)).to_be_visible(timeout=30000)
            return True
            
        logger.info(f"[{req_id}] ä» {current_prefs_for_modification.get('promptModel', 'æœªçŸ¥')} æ›´æ–° localStorage.promptModel ä¸º {full_model_path}")
        current_prefs_for_modification["promptModel"] = full_model_path
        
        # 3. ä¿å­˜ä¿®æ”¹åçš„è®¾ç½®åˆ° localStorage
        await page.evaluate("(prefsStr) => localStorage.setItem('aiStudioUserPreference', prefsStr)", json.dumps(current_prefs_for_modification))
        
        # 4. å¯¼èˆªåˆ°æ–°èŠå¤©é¡µé¢åº”ç”¨æ–°è®¾ç½®
        logger.info(f"[{req_id}] localStorage å·²æ›´æ–°ï¼Œå¯¼èˆªåˆ° '{new_chat_url}' åº”ç”¨æ–°æ¨¡å‹...")
        await page.goto(new_chat_url, wait_until="domcontentloaded", timeout=30000)
        
        # 5. ç­‰å¾…é¡µé¢é‡æ–°åŠ è½½å®Œæˆ (æ ¸å¿ƒå…ƒç´ å¯è§)
        input_field = page.locator(INPUT_SELECTOR)
        await expect_async(input_field).to_be_visible(timeout=30000)
        logger.info(f"[{req_id}] é¡µé¢å·²å¯¼èˆªåˆ°æ–°èŠå¤©å¹¶åŠ è½½å®Œæˆï¼Œè¾“å…¥æ¡†å¯è§")
        
        # 6. éªŒè¯ AI Studio æ˜¯å¦æ¥å—äº†æ¨¡å‹æ›´æ”¹ (æ£€æŸ¥ localStorage çš„æœ€ç»ˆçŠ¶æ€)
        final_prefs_str = await page.evaluate("() => localStorage.getItem('aiStudioUserPreference')")
        final_prompt_model_in_storage: Optional[str] = None
        if final_prefs_str:
            try:
                final_prefs_obj = json.loads(final_prefs_str)
                final_prompt_model_in_storage = final_prefs_obj.get("promptModel")
            except json.JSONDecodeError:
                logger.warning(f"[{req_id}] æ— æ³•è§£æåˆ·æ–°åçš„ aiStudioUserPreference JSON å­—ç¬¦ä¸²ã€‚")

        if final_prompt_model_in_storage == full_model_path:
            logger.info(f"[{req_id}] âœ… AI Studio localStorage ä¸­æ¨¡å‹å·²æˆåŠŸè®¾ç½®ä¸º: {full_model_path}")
            
            page_display_match = False
            expected_display_name_for_target_id = None
            actual_displayed_model_name_on_page = "æ— æ³•è¯»å–" # Default value

            if parsed_model_list:
                for m_obj in parsed_model_list:
                    if m_obj.get("id") == model_id:
                        expected_display_name_for_target_id = m_obj.get("display_name")
                        break
            
            if not expected_display_name_for_target_id:
                logger.warning(f"[{req_id}] æ— æ³•åœ¨parsed_model_listä¸­æ‰¾åˆ°ç›®æ ‡ID '{model_id}' çš„æ˜¾ç¤ºåç§°ï¼Œè·³è¿‡é¡µé¢æ˜¾ç¤ºåç§°éªŒè¯ã€‚è¿™å¯èƒ½ä¸å‡†ç¡®ã€‚")
                page_display_match = True 
            else:
                try:
                    model_wrapper_locator = page.locator('#mat-select-value-0 mat-select-trigger').first
                    actual_displayed_model_name_on_page_raw = await model_wrapper_locator.inner_text(timeout=5000)
                    actual_displayed_model_name_on_page = actual_displayed_model_name_on_page_raw.strip()

                    normalized_actual_display = actual_displayed_model_name_on_page.lower()
                    normalized_expected_display = expected_display_name_for_target_id.strip().lower()
                    
                    if normalized_actual_display == normalized_expected_display:
                        page_display_match = True
                        logger.info(f"[{req_id}] âœ… é¡µé¢æ˜¾ç¤ºæ¨¡å‹ ('{actual_displayed_model_name_on_page}') ä¸æœŸæœ› ('{expected_display_name_for_target_id}') ä¸€è‡´ã€‚")
                    else:
                        logger.error(f"[{req_id}] âŒ é¡µé¢æ˜¾ç¤ºæ¨¡å‹ ('{actual_displayed_model_name_on_page}') ä¸æœŸæœ› ('{expected_display_name_for_target_id}') ä¸ä¸€è‡´ã€‚(Raw page: '{actual_displayed_model_name_on_page_raw}')")
                except Exception as e_disp:
                    logger.warning(f"[{req_id}] è¯»å–é¡µé¢æ˜¾ç¤ºçš„å½“å‰æ¨¡å‹åç§°æ—¶å‡ºé”™: {e_disp}ã€‚å°†æ— æ³•éªŒè¯é¡µé¢æ˜¾ç¤ºã€‚")
            
            if page_display_match:
                return True
            else:
                logger.error(f"[{req_id}] âŒ æ¨¡å‹åˆ‡æ¢å¤±è´¥ï¼Œå› ä¸ºé¡µé¢æ˜¾ç¤ºçš„æ¨¡å‹ä¸æœŸæœ›ä¸ç¬¦ (å³ä½¿localStorageå¯èƒ½å·²æ›´æ”¹)ã€‚")
        else:
            logger.error(f"[{req_id}] âŒ AI Studio æœªæ¥å—æ¨¡å‹æ›´æ”¹ (localStorage)ã€‚æœŸæœ›='{full_model_path}', å®é™…='{final_prompt_model_in_storage or 'æœªè®¾ç½®æˆ–æ— æ•ˆ'}'.")

        logger.info(f"[{req_id}] æ¨¡å‹åˆ‡æ¢å¤±è´¥ã€‚å°è¯•æ¢å¤åˆ°é¡µé¢å½“å‰å®é™…æ˜¾ç¤ºçš„æ¨¡å‹çš„çŠ¶æ€...")

        current_displayed_name_for_revert_raw = "æ— æ³•è¯»å–"
        current_displayed_name_for_revert_stripped = "æ— æ³•è¯»å–"
        try:
            model_wrapper_locator_for_revert = page.locator('#mat-select-value-0 mat-select-trigger').first
            current_displayed_name_for_revert_raw = await model_wrapper_locator_for_revert.inner_text(timeout=5000)
            current_displayed_name_for_revert_stripped = current_displayed_name_for_revert_raw.strip()
            logger.info(f"[{req_id}] æ¢å¤ï¼šé¡µé¢å½“å‰æ˜¾ç¤ºçš„æ¨¡å‹åç§° (åŸå§‹: '{current_displayed_name_for_revert_raw}', æ¸…ç†å: '{current_displayed_name_for_revert_stripped}')")
        except Exception as e_read_disp_revert:
            logger.warning(f"[{req_id}] æ¢å¤ï¼šè¯»å–é¡µé¢å½“å‰æ˜¾ç¤ºæ¨¡å‹åç§°å¤±è´¥: {e_read_disp_revert}ã€‚å°†å°è¯•å›é€€åˆ°åŸå§‹localStorageã€‚")
            if original_prefs_str:
                logger.info(f"[{req_id}] æ¢å¤ï¼šç”±äºæ— æ³•è¯»å–å½“å‰é¡µé¢æ˜¾ç¤ºï¼Œå°è¯•å°† localStorage æ¢å¤åˆ°åŸå§‹çŠ¶æ€: '{original_prompt_model or 'æœªè®¾ç½®'}'")
                await page.evaluate("(origPrefs) => localStorage.setItem('aiStudioUserPreference', origPrefs)", original_prefs_str)
                logger.info(f"[{req_id}] æ¢å¤ï¼šå¯¼èˆªåˆ° '{new_chat_url}' ä»¥åº”ç”¨æ¢å¤çš„åŸå§‹ localStorage è®¾ç½®...")
                await page.goto(new_chat_url, wait_until="domcontentloaded", timeout=20000)
                await expect_async(page.locator(INPUT_SELECTOR)).to_be_visible(timeout=20000)
                logger.info(f"[{req_id}] æ¢å¤ï¼šé¡µé¢å·²å¯¼èˆªåˆ°æ–°èŠå¤©å¹¶åŠ è½½ï¼Œå·²å°è¯•åº”ç”¨åŸå§‹ localStorageã€‚")
            else:
                logger.warning(f"[{req_id}] æ¢å¤ï¼šæ— æœ‰æ•ˆçš„åŸå§‹ localStorage çŠ¶æ€å¯æ¢å¤ï¼Œä¹Ÿæ— æ³•è¯»å–å½“å‰é¡µé¢æ˜¾ç¤ºã€‚")
            return False

        model_id_to_revert_to = None
        if parsed_model_list and current_displayed_name_for_revert_stripped != "æ— æ³•è¯»å–":
            normalized_current_display_for_revert = current_displayed_name_for_revert_stripped.lower()
            for m_obj in parsed_model_list:
                parsed_list_display_name = m_obj.get("display_name", "").strip().lower()
                if parsed_list_display_name == normalized_current_display_for_revert:
                    model_id_to_revert_to = m_obj.get("id")
                    logger.info(f"[{req_id}] æ¢å¤ï¼šé¡µé¢æ˜¾ç¤ºåç§° '{current_displayed_name_for_revert_stripped}' å¯¹åº”æ¨¡å‹ID: {model_id_to_revert_to}")
                    break
            if not model_id_to_revert_to:
                logger.warning(f"[{req_id}] æ¢å¤ï¼šæ— æ³•åœ¨ parsed_model_list ä¸­æ‰¾åˆ°ä¸é¡µé¢æ˜¾ç¤ºåç§° '{current_displayed_name_for_revert_stripped}' åŒ¹é…çš„æ¨¡å‹IDã€‚")
        else:
            if current_displayed_name_for_revert_stripped == "æ— æ³•è¯»å–":
                 logger.warning(f"[{req_id}] æ¢å¤ï¼šå› æ— æ³•è¯»å–é¡µé¢æ˜¾ç¤ºåç§°ï¼Œæ•…ä¸èƒ½ä» parsed_model_list è½¬æ¢IDã€‚")
            else:
                 logger.warning(f"[{req_id}] æ¢å¤ï¼šparsed_model_list ä¸ºç©ºï¼Œæ— æ³•ä»æ˜¾ç¤ºåç§° '{current_displayed_name_for_revert_stripped}' è½¬æ¢æ¨¡å‹IDã€‚")

        if model_id_to_revert_to:
            base_prefs_for_final_revert = {}
            try:
                current_ls_content_str = await page.evaluate("() => localStorage.getItem('aiStudioUserPreference')")
                if current_ls_content_str:
                    base_prefs_for_final_revert = json.loads(current_ls_content_str)
                elif original_prefs_str:
                    base_prefs_for_final_revert = json.loads(original_prefs_str)
            except json.JSONDecodeError:
                logger.warning(f"[{req_id}] æ¢å¤ï¼šè§£æç°æœ‰ localStorage ä»¥æ„å»ºæ¢å¤åå¥½å¤±è´¥ã€‚")
            
            path_to_revert_to = f"models/{model_id_to_revert_to}"
            base_prefs_for_final_revert["promptModel"] = path_to_revert_to
            
            logger.info(f"[{req_id}] æ¢å¤ï¼šå‡†å¤‡å°† localStorage.promptModel è®¾ç½®å›é¡µé¢å®é™…æ˜¾ç¤ºçš„æ¨¡å‹çš„è·¯å¾„: '{path_to_revert_to}'")
            await page.evaluate("(prefsStr) => localStorage.setItem('aiStudioUserPreference', prefsStr)", json.dumps(base_prefs_for_final_revert))
            
            logger.info(f"[{req_id}] æ¢å¤ï¼šå¯¼èˆªåˆ° '{new_chat_url}' ä»¥åº”ç”¨æ¢å¤åˆ° '{model_id_to_revert_to}' çš„ localStorage è®¾ç½®...")
            await page.goto(new_chat_url, wait_until="domcontentloaded", timeout=30000)
            await expect_async(page.locator(INPUT_SELECTOR)).to_be_visible(timeout=30000)
            logger.info(f"[{req_id}] æ¢å¤ï¼šé¡µé¢å·²å¯¼èˆªåˆ°æ–°èŠå¤©å¹¶åŠ è½½ã€‚localStorage åº”å·²è®¾ç½®ä¸ºåæ˜ æ¨¡å‹ '{model_id_to_revert_to}'ã€‚")
        else:
            logger.error(f"[{req_id}] æ¢å¤ï¼šæ— æ³•å°†æ¨¡å‹æ¢å¤åˆ°é¡µé¢æ˜¾ç¤ºçš„çŠ¶æ€ï¼Œå› ä¸ºæœªèƒ½ä»æ˜¾ç¤ºåç§° '{current_displayed_name_for_revert_stripped}' ç¡®å®šæœ‰æ•ˆæ¨¡å‹IDã€‚")
            if original_prefs_str:
                logger.warning(f"[{req_id}] æ¢å¤ï¼šä½œä¸ºæœ€ç»ˆåå¤‡ï¼Œå°è¯•æ¢å¤åˆ°åŸå§‹ localStorage: '{original_prompt_model or 'æœªè®¾ç½®'}'")
                await page.evaluate("(origPrefs) => localStorage.setItem('aiStudioUserPreference', origPrefs)", original_prefs_str)
                logger.info(f"[{req_id}] æ¢å¤ï¼šå¯¼èˆªåˆ° '{new_chat_url}' ä»¥åº”ç”¨æœ€ç»ˆåå¤‡çš„åŸå§‹ localStorageã€‚")
                await page.goto(new_chat_url, wait_until="domcontentloaded", timeout=20000)
                await expect_async(page.locator(INPUT_SELECTOR)).to_be_visible(timeout=20000)
                logger.info(f"[{req_id}] æ¢å¤ï¼šé¡µé¢å·²å¯¼èˆªåˆ°æ–°èŠå¤©å¹¶åŠ è½½ï¼Œå·²åº”ç”¨æœ€ç»ˆåå¤‡çš„åŸå§‹ localStorageã€‚")
            else:
                logger.warning(f"[{req_id}] æ¢å¤ï¼šæ— æœ‰æ•ˆçš„åŸå§‹ localStorage çŠ¶æ€å¯ä½œä¸ºæœ€ç»ˆåå¤‡ã€‚")
                
        return False
            
    except Exception as e:
        logger.exception(f"[{req_id}] âŒ åˆ‡æ¢æ¨¡å‹è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯")
        await save_error_snapshot(f"model_switch_error_{req_id}")
        try:
            if original_prefs_str:
                logger.info(f"[{req_id}] å‘ç”Ÿå¼‚å¸¸ï¼Œå°è¯•æ¢å¤ localStorage è‡³: {original_prompt_model or 'æœªè®¾ç½®'}")
                await page.evaluate("(origPrefs) => localStorage.setItem('aiStudioUserPreference', origPrefs)", original_prefs_str)
                logger.info(f"[{req_id}] å¼‚å¸¸æ¢å¤ï¼šå¯¼èˆªåˆ° '{new_chat_url}' ä»¥åº”ç”¨æ¢å¤çš„ localStorageã€‚")
                await page.goto(new_chat_url, wait_until="domcontentloaded", timeout=15000)
                await expect_async(page.locator(INPUT_SELECTOR)).to_be_visible(timeout=15000)
        except Exception as recovery_err:
            logger.error(f"[{req_id}] å¼‚å¸¸åæ¢å¤ localStorage å¤±è´¥: {recovery_err}")
        return False

# æ–°å¢: åŠ è½½æ’é™¤æ¨¡å‹åˆ—è¡¨çš„å‡½æ•°
def load_excluded_models(filename: str):
    """ä»æŒ‡å®šæ–‡ä»¶åŠ è½½æ¨¡å‹IDåˆ°æ’é™¤åˆ—è¡¨ã€‚"""
    global excluded_model_ids, logger
    excluded_file_path = os.path.join(os.path.dirname(__file__), filename)
    try:
        if os.path.exists(excluded_file_path):
            with open(excluded_file_path, 'r', encoding='utf-8') as f:
                loaded_ids = {line.strip() for line in f if line.strip()}
            if loaded_ids:
                excluded_model_ids.update(loaded_ids)
                logger.info(f"âœ… ä» '{filename}' åŠ è½½äº† {len(loaded_ids)} ä¸ªæ¨¡å‹åˆ°æ’é™¤åˆ—è¡¨: {excluded_model_ids}")
            else:
                logger.info(f"'{filename}' æ–‡ä»¶ä¸ºç©ºæˆ–ä¸åŒ…å«æœ‰æ•ˆçš„æ¨¡å‹ IDï¼Œæ’é™¤åˆ—è¡¨æœªæ›´æ”¹ã€‚")
        else:
            logger.info(f"æ¨¡å‹æ’é™¤åˆ—è¡¨æ–‡ä»¶ '{filename}' æœªæ‰¾åˆ°ï¼Œæ’é™¤åˆ—è¡¨ä¸ºç©ºã€‚")
    except Exception as e:
        logger.error(f"âŒ ä» '{filename}' åŠ è½½æ’é™¤æ¨¡å‹åˆ—è¡¨æ—¶å‡ºé”™: {e}", exc_info=True)

# æ–°å¢: å¤„ç†åˆå§‹æ¨¡å‹çŠ¶æ€å’Œ localStorage çš„å‡½æ•°
async def _handle_initial_model_state_and_storage(page: AsyncPage):
    """æ£€æŸ¥åˆå§‹ localStorageï¼Œå¦‚æœä¸ºç©ºæˆ– isAdvancedOpen ä¸ä¸º trueï¼Œåˆ™å°è¯•æ ¹æ®é¡µé¢æ˜¾ç¤ºè®¾ç½®ï¼Œ
       å¼ºåˆ¶ isAdvancedOpen=true, å¹¶é‡æ–°åŠ è½½é¡µé¢ï¼Œç„¶åå†æ¬¡åŒæ­¥å…¨å±€æ¨¡å‹çŠ¶æ€ã€‚
    """
    global current_ai_studio_model_id, logger, parsed_model_list, model_list_fetch_event, INPUT_SELECTOR # ç¡®ä¿ INPUT_SELECTOR åœ¨æ­¤ä½œç”¨åŸŸå¯ç”¨
    
    logger.info("--- (æ–°) å¤„ç†åˆå§‹æ¨¡å‹çŠ¶æ€, localStorage å’Œ isAdvancedOpen ---")
    needs_reload_and_storage_update = False
    reason_for_reload = ""

    try:
        initial_prefs_str = await page.evaluate("() => localStorage.getItem('aiStudioUserPreference')")
        
        if not initial_prefs_str:
            needs_reload_and_storage_update = True
            reason_for_reload = "localStorage.aiStudioUserPreference æœªæ‰¾åˆ°ã€‚"
            logger.info(f"   åˆ¤å®šéœ€è¦åˆ·æ–°å’Œå­˜å‚¨æ›´æ–°: {reason_for_reload}")
        else:
            logger.info("   localStorage ä¸­æ‰¾åˆ° 'aiStudioUserPreference'ã€‚æ­£åœ¨è§£æ...")
            try:
                pref_obj = json.loads(initial_prefs_str)
                prompt_model_path = pref_obj.get("promptModel")
                is_advanced_open_in_storage = pref_obj.get("isAdvancedOpen")

                # æ£€æŸ¥ promptModel æ˜¯å¦æœ‰æ•ˆ (éç©ºå­—ç¬¦ä¸²)
                is_prompt_model_valid = isinstance(prompt_model_path, str) and prompt_model_path.strip()

                if not is_prompt_model_valid:
                    needs_reload_and_storage_update = True
                    reason_for_reload = "localStorage.promptModel æ— æ•ˆæˆ–æœªè®¾ç½®ã€‚"
                    logger.info(f"   åˆ¤å®šéœ€è¦åˆ·æ–°å’Œå­˜å‚¨æ›´æ–°: {reason_for_reload}")
                elif is_advanced_open_in_storage is not True: # ä¸¥æ ¼æ£€æŸ¥å¸ƒå°”å€¼ True
                    needs_reload_and_storage_update = True
                    reason_for_reload = f"localStorage.isAdvancedOpen ({is_advanced_open_in_storage}) ä¸ä¸º Trueã€‚"
                    logger.info(f"   åˆ¤å®šéœ€è¦åˆ·æ–°å’Œå­˜å‚¨æ›´æ–°: {reason_for_reload}")
                else:
                    # localStorage æœ‰æ•ˆ, isAdvancedOpen ä¸º true, promptModel æœ‰æ•ˆ
                    current_ai_studio_model_id = prompt_model_path.split('/')[-1]
                    logger.info(f"   âœ… localStorage æœ‰æ•ˆä¸” isAdvancedOpen=trueã€‚åˆå§‹æ¨¡å‹ ID ä» localStorage è®¾ç½®ä¸º: {current_ai_studio_model_id}")
            except json.JSONDecodeError:
                needs_reload_and_storage_update = True
                reason_for_reload = "è§£æ localStorage.aiStudioUserPreference JSON å¤±è´¥ã€‚"
                logger.error(f"   åˆ¤å®šéœ€è¦åˆ·æ–°å’Œå­˜å‚¨æ›´æ–°: {reason_for_reload}")

        if needs_reload_and_storage_update:
            logger.info(f"   æ‰§è¡Œåˆ·æ–°å’Œå­˜å‚¨æ›´æ–°æµç¨‹ï¼ŒåŸå› : {reason_for_reload}")
            
            logger.info("   æ­¥éª¤ 1: è°ƒç”¨ _set_model_from_page_display(set_storage=True) æ›´æ–° localStorage å’Œå…¨å±€æ¨¡å‹ ID...")
            await _set_model_from_page_display(page, set_storage=True)
            
            current_page_url = page.url
            logger.info(f"   æ­¥éª¤ 2: é‡æ–°åŠ è½½é¡µé¢ ({current_page_url}) ä»¥åº”ç”¨ isAdvancedOpen=true...")
            try:
                await page.goto(current_page_url, wait_until="domcontentloaded", timeout=30000)
                await expect_async(page.locator(INPUT_SELECTOR)).to_be_visible(timeout=30000) # ç¡®ä¿é¡µé¢å¯ç”¨
                logger.info(f"   âœ… é¡µé¢å·²æˆåŠŸé‡æ–°åŠ è½½åˆ°: {page.url}")
            except Exception as reload_err:
                logger.error(f"   âŒ é¡µé¢é‡æ–°åŠ è½½å¤±è´¥: {reload_err}. åç»­æ¨¡å‹çŠ¶æ€å¯èƒ½ä¸å‡†ç¡®ã€‚", exc_info=True)
                await save_error_snapshot("initial_storage_reload_fail")
                # å¦‚æœé‡æ–°åŠ è½½å¤±è´¥ï¼Œåç»­çš„ _set_model_from_page_display ä»ç„¶ä¼šå°è¯•è¿è¡Œï¼Œä½†å¯èƒ½åŸºäºä¸€ä¸ªæœªå®Œå…¨åŠ è½½çš„é¡µé¢

            logger.info("   æ­¥éª¤ 3: é‡æ–°åŠ è½½åï¼Œå†æ¬¡è°ƒç”¨ _set_model_from_page_display(set_storage=False) ä»¥åŒæ­¥å…¨å±€æ¨¡å‹ ID...")
            await _set_model_from_page_display(page, set_storage=False)
            
            logger.info(f"   âœ… åˆ·æ–°å’Œå­˜å‚¨æ›´æ–°æµç¨‹å®Œæˆã€‚æœ€ç»ˆå…¨å±€æ¨¡å‹ ID: {current_ai_studio_model_id}")
        else:
            logger.info("   localStorage çŠ¶æ€è‰¯å¥½ (isAdvancedOpen=true, promptModelæœ‰æ•ˆ)ï¼Œæ— éœ€åˆ·æ–°é¡µé¢ã€‚")

    except Exception as e:
        logger.error(f"âŒ (æ–°) å¤„ç†åˆå§‹æ¨¡å‹çŠ¶æ€å’Œ localStorage æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)
        try:
            logger.warning("   ç”±äºå‘ç”Ÿé”™è¯¯ï¼Œå°è¯•å›é€€ä»…ä»é¡µé¢æ˜¾ç¤ºè®¾ç½®å…¨å±€æ¨¡å‹ ID (ä¸å†™å…¥localStorage)...")
            await _set_model_from_page_display(page, set_storage=False)
        except Exception as fallback_err:
            logger.error(f"   å›é€€è®¾ç½®æ¨¡å‹IDä¹Ÿå¤±è´¥: {fallback_err}")

async def _set_model_from_page_display(page: AsyncPage, set_storage: bool = False):
    """å°è¯•ä»é¡µé¢æ˜¾ç¤ºçš„å…ƒç´ è¯»å–æ¨¡å‹ï¼Œæ›´æ–°å…¨å±€çŠ¶æ€ï¼Œå¹¶å¯é€‰åœ°è®¾ç½® localStorageã€‚"""
    global current_ai_studio_model_id, logger, parsed_model_list, model_list_fetch_event
    try:
        logger.info("   å°è¯•ä»é¡µé¢æ˜¾ç¤ºå…ƒç´ è¯»å–å½“å‰æ¨¡å‹åç§°...")
        model_wrapper_locator = page.locator('#mat-select-value-0 mat-select-trigger').first
        displayed_model_name_from_page_raw = await model_wrapper_locator.inner_text(timeout=7000)
        
        # æ–°å¢ï¼šå»é™¤é¦–å°¾ç©ºæ ¼
        displayed_model_name = displayed_model_name_from_page_raw.strip()

        logger.info(f"   é¡µé¢å½“å‰æ˜¾ç¤ºæ¨¡å‹åç§° (åŸå§‹: '{displayed_model_name_from_page_raw}', æ¸…ç†å: '{displayed_model_name}')")

        # å°è¯•å°†æ˜¾ç¤ºåç§°è½¬æ¢ä¸ºæ¨¡å‹ID
        found_model_id_from_display = None
        if not model_list_fetch_event.is_set():
            logger.info("   ç­‰å¾…æ¨¡å‹åˆ—è¡¨æ•°æ® (æœ€å¤š5ç§’) ä»¥ä¾¿è½¬æ¢æ˜¾ç¤ºåç§°...")
            try: await asyncio.wait_for(model_list_fetch_event.wait(), timeout=5.0)
            except asyncio.TimeoutError: logger.warning("   ç­‰å¾…æ¨¡å‹åˆ—è¡¨è¶…æ—¶ï¼Œå¯èƒ½æ— æ³•å‡†ç¡®è½¬æ¢æ˜¾ç¤ºåç§°ä¸ºIDã€‚")

        if parsed_model_list:
            for model_obj in parsed_model_list:
                # ç¡®ä¿æ¯”è¾ƒæ—¶åŒæ–¹éƒ½æ˜¯æ¸…ç†è¿‡çš„ï¼Œæˆ–å‡è®¾ parsed_model_list ä¸­çš„ display_name æ˜¯å¹²å‡€çš„
                if model_obj.get("display_name") and model_obj.get("display_name").strip() == displayed_model_name:
                    found_model_id_from_display = model_obj.get("id")
                    logger.info(f"   æ˜¾ç¤ºåç§° '{displayed_model_name}' å¯¹åº”æ¨¡å‹ ID: {found_model_id_from_display}")
                    break
            if not found_model_id_from_display:
                 logger.warning(f"   æœªåœ¨å·²çŸ¥æ¨¡å‹åˆ—è¡¨ä¸­æ‰¾åˆ°ä¸æ˜¾ç¤ºåç§° '{displayed_model_name}' åŒ¹é…çš„ IDã€‚")
        else:
            logger.warning("   æ¨¡å‹åˆ—è¡¨å°šä¸å¯ç”¨ï¼Œæ— æ³•å°†æ˜¾ç¤ºåç§°è½¬æ¢ä¸ºIDã€‚")

        # æ›´æ–°å…¨å±€ current_ai_studio_model_id
        # ä¼˜å…ˆä½¿ç”¨è½¬æ¢å¾—åˆ°çš„ IDï¼Œå…¶æ¬¡æ˜¯åŸå§‹æ˜¾ç¤ºåç§° (å¦‚æœè½¬æ¢å¤±è´¥)
        new_model_value = found_model_id_from_display if found_model_id_from_display else displayed_model_name
        if current_ai_studio_model_id != new_model_value:
            current_ai_studio_model_id = new_model_value
            logger.info(f"   å…¨å±€ current_ai_studio_model_id å·²æ›´æ–°ä¸º: {current_ai_studio_model_id}")
        else:
            logger.info(f"   å…¨å±€ current_ai_studio_model_id ('{current_ai_studio_model_id}') ä¸ä»é¡µé¢è·å–çš„å€¼ä¸€è‡´ï¼Œæœªæ›´æ”¹ã€‚")

        if set_storage:
            logger.info(f"   å‡†å¤‡ä¸ºé¡µé¢çŠ¶æ€è®¾ç½® localStorage (ç¡®ä¿ isAdvancedOpen=true)...")
            
            # å°è¯•è·å–ç°æœ‰åå¥½ä»¥è¿›è¡Œæ›´æ–°ï¼Œæˆ–ä»æ–°çš„ç©ºå­—å…¸å¼€å§‹
            existing_prefs_for_update_str = await page.evaluate("() => localStorage.getItem('aiStudioUserPreference')")
            prefs_to_set = {}
            if existing_prefs_for_update_str:
                try:
                    prefs_to_set = json.loads(existing_prefs_for_update_str)
                except json.JSONDecodeError:
                    logger.warning("   è§£æç°æœ‰ localStorage.aiStudioUserPreference å¤±è´¥ï¼Œå°†åˆ›å»ºæ–°çš„åå¥½è®¾ç½®ã€‚")
            
            # å¼ºåˆ¶ isAdvancedOpen ä¸º true
            prefs_to_set["isAdvancedOpen"] = True
            logger.info(f"     å¼ºåˆ¶ isAdvancedOpen: true")
            # æ–°å¢ï¼šå¼ºåˆ¶ areToolsOpen ä¸º false
            prefs_to_set["areToolsOpen"] = False
            logger.info(f"     å¼ºåˆ¶ areToolsOpen: false")

            if found_model_id_from_display:
                new_prompt_model_path = f"models/{found_model_id_from_display}"
                prefs_to_set["promptModel"] = new_prompt_model_path
                logger.info(f"     è®¾ç½® promptModel ä¸º: {new_prompt_model_path} (åŸºäºæ‰¾åˆ°çš„ID)")
            elif "promptModel" not in prefs_to_set: 
                # å¦‚æœæ— æ³•ä»é¡µé¢æ˜¾ç¤ºä¸­æ‰¾åˆ°æ¨¡å‹IDï¼Œå¹¶ä¸”localStorageä¸­ä¹Ÿæ²¡æœ‰ç°æœ‰çš„promptModelï¼Œ
                # åˆ™ä¸ä¸»åŠ¨è®¾ç½®promptModelï¼Œä»¥é¿å…å†™å…¥AI Studioæ— æ³•è¯†åˆ«çš„å€¼ã€‚
                # ä¸»è¦ç›®æ ‡æ˜¯ä¿®å¤isAdvancedOpenã€‚
                logger.warning(f"     æ— æ³•ä»é¡µé¢æ˜¾ç¤º '{displayed_model_name}' æ‰¾åˆ°æ¨¡å‹IDï¼Œä¸” localStorage ä¸­æ— ç°æœ‰ promptModelã€‚promptModel å°†ä¸ä¼šè¢«ä¸»åŠ¨è®¾ç½®ä»¥é¿å…æ½œåœ¨é—®é¢˜ã€‚")

            # ç¡®ä¿å…¶ä»–å¿…è¦çš„é»˜è®¤é”®å­˜åœ¨ï¼Œä»¥é˜² prefs_to_set æ˜¯ä¸€ä¸ªç©ºå¯¹è±¡æˆ–ä¸å®Œæ•´çš„å¯¹è±¡
            default_keys_if_missing = {
                "bidiModel": "models/gemini-1.0-pro-001", # ä¸€ä¸ªåˆç†çš„é»˜è®¤å€¼
                "isSafetySettingsOpen": False, 
                # "areToolsOpen": True, # ç°åœ¨ä¼šåœ¨ä¸Šé¢æ˜¾å¼è®¾ç½®ä¸º False
                "hasShownSearchGroundingTos": False, 
                "autosaveEnabled": True, 
                "theme": "system",
                "bidiOutputFormat": 3, 
                "isSystemInstructionsOpen": False, 
                "warmWelcomeDisplayed": True,
                "getCodeLanguage": "Node.js", 
                "getCodeHistoryToggle": False, 
                "fileCopyrightAcknowledged": True
            }
            for key, val_default in default_keys_if_missing.items():
                if key not in prefs_to_set:
                    prefs_to_set[key] = val_default
            
            await page.evaluate("(prefsStr) => localStorage.setItem('aiStudioUserPreference', prefsStr)", json.dumps(prefs_to_set))
            logger.info(f"   âœ… localStorage.aiStudioUserPreference å·²æ›´æ–°ã€‚isAdvancedOpen: {prefs_to_set.get('isAdvancedOpen')}, areToolsOpen: {prefs_to_set.get('areToolsOpen')}, promptModel: '{prefs_to_set.get('promptModel', 'æœªè®¾ç½®/ä¿ç•™åŸæ ·')}'ã€‚")
        # åŸæœ¬çš„ elif set_storage and not found_model_id_from_display åˆ†æ”¯å·²è¢«åˆå¹¶åˆ°ä¸Šé¢çš„ if set_storage é€»è¾‘ä¸­

    except Exception as e_set_disp:
        logger.error(f"   å°è¯•ä»é¡µé¢æ˜¾ç¤ºè®¾ç½®æ¨¡å‹æ—¶å‡ºé”™: {e_set_disp}", exc_info=True)
